{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OYMQHV8ESWxF",
        "outputId": "2a24f97c-3891-41d8-9df1-2c82c16a76d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.2615\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.0454\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.8827\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7697\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6956\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6482\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6177\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5978\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5846\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5755\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5691\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5646\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5613\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5588\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5570\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5556\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5544\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5535\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5528\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5522\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5517\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5512\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5508\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5504\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5500\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5497\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5494\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5491\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5488\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5485\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5482\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5479\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5477\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5474\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5471\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5469\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5466\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5463\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5461\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5458\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5456\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5453\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5450\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5448\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5445\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5443\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5440\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5437\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5435\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5432\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5430\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5427\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5425\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5422\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5419\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5417\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5414\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5412\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5409\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5407\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5404\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5401\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5399\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5396\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5394\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5391\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5389\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5386\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5384\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5381\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5379\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5376\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5374\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5371\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5368\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5366\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5363\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5361\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5358\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5356\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5353\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5351\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5348\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5346\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5343\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5341\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5338\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5336\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5333\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5331\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5328\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5326\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5323\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5321\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5318\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5316\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5313\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5311\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5308\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5306\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5304\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5301\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5299\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5296\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5294\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5291\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5289\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5286\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5284\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5281\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5279\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5277\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5274\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5272\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5269\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5267\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5264\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5262\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5259\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5257\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5255\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5252\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5250\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5247\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5245\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5242\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5240\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5238\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5235\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5233\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5230\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5228\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5226\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5223\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5221\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5218\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5216\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5214\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5211\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5209\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5206\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5204\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5202\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5199\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5197\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5195\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5192\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5190\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5187\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5185\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5183\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5180\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5178\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5176\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5173\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5171\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5168\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5166\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5164\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5161\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5159\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5157\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5154\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5152\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5150\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5147\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5145\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5143\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5140\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5138\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5136\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5133\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5131\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5129\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5126\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5124\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5122\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5119\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5117\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5115\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5113\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5110\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5108\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5106\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5103\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5101\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5099\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5096\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5094\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5092\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5090\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5087\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5085\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5083\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5080\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5078\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5076\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5074\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5071\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5069\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5067\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5065\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5062\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5060\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5058\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5055\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5053\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5051\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5049\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5046\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5044\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5042\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5040\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5037\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5035\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5033\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5031\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5029\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5026\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5024\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5022\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5020\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5017\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5015\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5013\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5011\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5008\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5006\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5004\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5002\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5000\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4997\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4995\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4993\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4991\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4989\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4986\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4984\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4982\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4980\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4978\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4975\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4973\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4971\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4969\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4967\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4964\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4962\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4960\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4958\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4956\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4954\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4951\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4949\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4947\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4945\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4943\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4941\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4938\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4936\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4934\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4932\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4930\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4928\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4925\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4923\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4921\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4919\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4917\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4915\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4913\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4910\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4908\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4906\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4904\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4902\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4900\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4898\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4896\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4893\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4891\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4889\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4887\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4885\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4883\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4881\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4879\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4877\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4874\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4872\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4870\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4868\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4866\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4864\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4862\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4860\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4858\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4856\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4853\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4851\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4849\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4847\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4845\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4843\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4841\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4839\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4837\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4835\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4833\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4831\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4829\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4826\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4824\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4822\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4820\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4818\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4816\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4814\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4812\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4810\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4808\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4806\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4804\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4802\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4800\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4798\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4796\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4794\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4792\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4790\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4788\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4785\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4783\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4781\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4779\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4777\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4775\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4773\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4771\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4769\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4767\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4765\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4763\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4761\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4759\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4757\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4755\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4753\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4751\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4749\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4747\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4745\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4743\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4741\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4739\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4737\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4735\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4733\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4731\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4729\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4727\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4725\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4723\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4721\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4719\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4717\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4715\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4713\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4711\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4710\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4708\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4706\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4704\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4702\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4700\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4698\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4696\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4694\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4692\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4690\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4688\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4686\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4684\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4682\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4680\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4678\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4676\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4674\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4672\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4671\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4669\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4667\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4665\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4663\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4661\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4659\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4657\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4655\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4653\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4651\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4649\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4647\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4646\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4644\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4642\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4640\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4638\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4636\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4634\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4632\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4630\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4628\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4626\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4625\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4623\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4621\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4619\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4617\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4615\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4613\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4611\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4609\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4608\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4606\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4604\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4602\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4600\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4598\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4596\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4594\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4593\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4591\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4589\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4587\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4585\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4583\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4581\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4579\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4578\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4576\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4574\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4572\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4570\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4568\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4567\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4565\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4563\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4561\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4559\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4557\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4555\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4554\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4552\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4550\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4548\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4546\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4544\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4543\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4541\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4539\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4537\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4535\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4534\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4532\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4530\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4528\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4526\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4524\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4523\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4521\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4519\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4517\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4515\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4514\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4512\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4510\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4508\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4506\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4505\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4503\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4501\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4499\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4497\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4496\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4494\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4492\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4490\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4488\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4487\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4485\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4483\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4481\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4480\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4478\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4476\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4474\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4472\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4471\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4469\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4467\n",
            "1/1 [==============================] - 0s 152ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 61ms/step\n",
            "[[0.6884495]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "x = np.array([2,4,6,8,10,12,14])\n",
        "y = np.array([0,0,0,1,1,1,1])\n",
        "\n",
        "# Sequential(순차적으로 층을 쌓는 모델)은 모델을 만들기 위한 기본 구조 정의 add를 사용해 순차적으로 층을 쌓아감\n",
        "model = Sequential()\n",
        "model.add(Dense(1,input_dim=1,activation='sigmoid'))#dense는 층간 거리 뺵빽함 정도\n",
        "\n",
        "\n",
        "# 교차 엔트로피 오차 함수를 이용하기 위해 binary_crossentropy로 설정\n",
        "model.compile(optimizer='sgd',loss='binary_crossentropy')\n",
        "model.fit(x,y,epochs=500)\n",
        "\n",
        "# 그래프로 확인해보기\n",
        "plt.scatter(x,y)\n",
        "plt.plot(x,model.predict(x),'r')\n",
        "plt.show()\n",
        "\n",
        "# 임의의 x값을 넣어 y값 구해보기\n",
        "hour = 7\n",
        "prediction =model.predict([hour])\n",
        "print(prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "N1GFkAbzW1it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/taehojo/data.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGeNaDYDnMcW",
        "outputId": "a5a0548e-1d68-479f-b5b4-d6b305802e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'data'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 21 (delta 3), reused 20 (delta 2), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (21/21), 460.95 KiB | 1.94 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data_set = np.loadtxt(\"./data/ThoraricSurgery3.csv\",delimiter=\",\")"
      ],
      "metadata": {
        "id": "bGb9RJRwnqJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "X = Data_set[:,0:16]\n",
        "y = Data_set[:,16]\n",
        "#add를 두번 층이 2개인 모델\n",
        "model = Sequential()\n",
        "model.add(Dense(30,input_dim=16,activation='relu'))# 입력층 및 은닉층\n",
        "# 30개의 노드를 사용하고 data를 16개를 받는다.\n",
        "model.add(Dense(1,activation='sigmoid'))# 출력층\n",
        "# 출력층은 결과값이 1개가 나와야 하므로 1로 설정\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'adam',metrics = ['accuracy'])\n",
        "history = model.fit(X,y,epochs = 5,batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N31peFkYny1G",
        "outputId": "42547456-10c8-4088-b096-87c0dac9ceb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "30/30 [==============================] - 1s 3ms/step - loss: 2.1763\n",
            "Epoch 2/5\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.5351\n",
            "Epoch 3/5\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4702\n",
            "Epoch 4/5\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4615\n",
            "Epoch 5/5\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.4589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "GOZF6PuGxmdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/taehojo/data.git\n",
        "Data_set = pd.read_csv(\"./data/pima-indians-diabetes3.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9bWTETen56I",
        "outputId": "8749c554-10ab-45ed-e364-56c57b28570d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'data' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data_set.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wUlFf9Snx6ea",
        "outputId": "24a1cde5-7d65-4174-958a-c9cb1e205769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   pregnant  plasma  pressure  thickness  insulin   bmi  pedigree  age  \\\n",
              "0         6     148        72         35        0  33.6     0.627   50   \n",
              "1         1      85        66         29        0  26.6     0.351   31   \n",
              "2         8     183        64          0        0  23.3     0.672   32   \n",
              "3         1      89        66         23       94  28.1     0.167   21   \n",
              "4         0     137        40         35      168  43.1     2.288   33   \n",
              "\n",
              "   diabetes  \n",
              "0         1  \n",
              "1         0  \n",
              "2         1  \n",
              "3         0  \n",
              "4         1  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-f4f27a96-ef8c-4407-9198-5131461fe3a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pregnant</th>\n",
              "      <th>plasma</th>\n",
              "      <th>pressure</th>\n",
              "      <th>thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree</th>\n",
              "      <th>age</th>\n",
              "      <th>diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4f27a96-ef8c-4407-9198-5131461fe3a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-98396779-d018-44a9-a845-dbd05db98d9c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-98396779-d018-44a9-a845-dbd05db98d9c')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-98396779-d018-44a9-a845-dbd05db98d9c button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f4f27a96-ef8c-4407-9198-5131461fe3a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f4f27a96-ef8c-4407-9198-5131461fe3a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = Data_set.iloc[:,0:8]\n",
        "y = Data_set.iloc[:,8]"
      ],
      "metadata": {
        "id": "BrAmlYRdxbmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(12,input_dim=8,activation='relu',name = 'Dense_1'))\n",
        "model.add(Dense(8,activation='relu',name = 'Dense_2'))\n",
        "model.add(Dense(1,activation='sigmoid',name='Dense_3'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp1oSZImx45J",
        "outputId": "8b5cd546-a926-4267-ae33-eb42178cfd0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Dense_1 (Dense)             (None, 12)                108       \n",
            "                                                                 \n",
            " Dense_2 (Dense)             (None, 8)                 104       \n",
            "                                                                 \n",
            " Dense_3 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 221\n",
            "Trainable params: 221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics= ['accuracy'])\n",
        "history = model.fit(X,y,epochs=100 , batch_size = 5)"
      ],
      "metadata": {
        "id": "hLCJj-dvx9gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as pt"
      ],
      "metadata": {
        "id": "sl3s_ZYRzr48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/taehojo/data.git\n",
        "df = pd.read_csv(\"./data/iris3.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DSDkEU_5QGr",
        "outputId": "7a053152-4a70-4c83-8de6-05a4a6c74517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'data' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XPpyAmjk5V9H",
        "outputId": "7b409412-ed8d-49ea-990c-e9239bfe3dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width      species\n",
              "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
              "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
              "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
              "4           5.0          3.6           1.4          0.2  Iris-setosa"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-99972986-dd96-42be-9706-511e5cbdf4fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99972986-dd96-42be-9706-511e5cbdf4fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-c7ea9b5d-1121-4886-b618-f179460dbe68\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c7ea9b5d-1121-4886-b618-f179460dbe68')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-c7ea9b5d-1121-4886-b618-f179460dbe68 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-99972986-dd96-42be-9706-511e5cbdf4fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-99972986-dd96-42be-9706-511e5cbdf4fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,0:4]\n",
        "y = df.iloc[:,4]\n",
        "\n",
        "# one-hot 인코딩 범주형 값을 수치형으로 바꿔줌\n",
        "y = pd.get_dummies(y)"
      ],
      "metadata": {
        "id": "xleCQ_dI5WvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= Sequential()\n",
        "model.add(Dense(12,input_dim=4,activation='relu'))\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dense(3,activation='softmax'))#y값이 3개의 정답이 있으므로 relu는 ox만 판별할때 사용\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpFBX-Jn5oN8",
        "outputId": "a8850dd7-2743-4d59-9466-83ff4a6f2d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 12)                60        \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 191\n",
            "Trainable params: 191\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])# 다항함수 이므로 categorical_crossentropy를 사용\n",
        "history = model.fit(X,y,epochs = 50, batch_size=5)"
      ],
      "metadata": {
        "id": "0xxfA9wu5uff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# k-fold를 이용해 교차 검증\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as pt\n"
      ],
      "metadata": {
        "id": "atW-nuyg5ub-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/taehojo/data.git\n",
        "df = pd.read_csv(\"./data/sonar3.csv\", header = None)"
      ],
      "metadata": {
        "id": "5XUgjdLU5uZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "282ae842-cb70-4a87-9317-32ad8198a7a4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'data'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 21 (delta 3), reused 20 (delta 2), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (21/21), 460.95 KiB | 1.83 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "clOc-3VPti17",
        "outputId": "40b9f72f-2ad9-4929-fecf-f83598f4ef93"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0       1       2       3       4       5       6       7       8   \\\n",
              "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
              "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
              "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
              "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
              "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
              "\n",
              "       9   ...      51      52      53      54      55      56      57  \\\n",
              "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
              "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
              "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
              "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
              "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
              "\n",
              "       58      59  60  \n",
              "0  0.0090  0.0032   0  \n",
              "1  0.0052  0.0044   0  \n",
              "2  0.0095  0.0078   0  \n",
              "3  0.0040  0.0117   0  \n",
              "4  0.0107  0.0094   0  \n",
              "\n",
              "[5 rows x 61 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-de654754-4498-4abe-b2d6-e608c6fa596b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 61 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de654754-4498-4abe-b2d6-e608c6fa596b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-02ed8c24-cbd2-40c8-8a29-9c7244f5dbdf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-02ed8c24-cbd2-40c8-8a29-9c7244f5dbdf')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-02ed8c24-cbd2-40c8-8a29-9c7244f5dbdf button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de654754-4498-4abe-b2d6-e608c6fa596b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de654754-4498-4abe-b2d6-e608c6fa596b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,0:60]\n",
        "y = df.iloc[:,60]\n",
        "\n",
        "# 몇겹으로 나눌지 정하기\n",
        "k=5\n",
        "#kfold함수를 호출하고 샘플들을 섞어 한쪽으로 치우치는 경향을 줄임\n",
        "kfold = KFold(n_splits=k,shuffle=True)\n",
        "\n",
        "#정확도가 채워질 빈 리스트 선언\n",
        "acc_score=[]\n",
        "\n",
        "def model_fn():\n",
        "  model=Sequential()\n",
        "  model.add(Dense(24,input_dim = 60,activation='relu'))\n",
        "  model.add(Dense(10,activation='relu'))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  return model\n",
        "\n",
        "# k-fold겸증을 이용해 k번 실행 for문 사용\n",
        "# split()에 의해 k개의 학습셋,테스트셋으로 분리\n",
        "for train_index, test_index in kfold.split(X):# train과 test를 나누기\n",
        "  X_train,X_test = X.iloc[train_index,:],X.iloc[test_index,:]#행 단위로 데이터를 나누기\n",
        "  y_train,y_test = y.iloc[train_index],y.iloc[test_index]# 열이 1개이기 떄문에 ,:안씀\n",
        "\n",
        "  model = model_fn()\n",
        "  model.compile(loss='binary_crossentropy',optimizer = 'adam',metrics=['accuracy']) # 모델에서 손실함수는 binary_crossentropy로 최적화는 adam으로 진행\n",
        "  history=model.fit(X_train,y_train,epochs=200,batch_size=10,verbose=0)# verbose 학습과정 생략 0 X_train,y_train으로 학습 학습횟수는 200 학습 batch_size는 10개\n",
        "  #정확도 구하기\n",
        "  accuracy = model.evaluate(X_test,y_test)[1]\n",
        "  acc_score.append(accuracy)\n",
        "\n",
        "  #k번 실시된 정확도의 평균을 구하기\n",
        "  avg_acc_score=sum(acc_score)/k\n",
        "  #결과 출력\n",
        "  print('정확도:',acc_score)\n",
        "  print('정확도 평균',avg_acc_score)\n",
        "\n"
      ],
      "metadata": {
        "id": "vs08qpmo5uXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01135630-92d6-48d8-ee05-84bd9adac0b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1115 - accuracy: 0.8333\n",
            "정확도: [0.8333333134651184]\n",
            "정확도 평균 0.1666666626930237\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5293 - accuracy: 0.8095\n",
            "정확도: [0.8333333134651184, 0.8095238208770752]\n",
            "정확도 평균 0.3285714268684387\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6962 - accuracy: 0.8333\n",
            "정확도: [0.8333333134651184, 0.8095238208770752, 0.8333333134651184]\n",
            "정확도 평균 0.4952380895614624\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5304 - accuracy: 0.8049\n",
            "정확도: [0.8333333134651184, 0.8095238208770752, 0.8333333134651184, 0.8048780560493469]\n",
            "정확도 평균 0.6562137007713318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7e851f1a6320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5707 - accuracy: 0.8293\n",
            "정확도: [0.8333333134651184, 0.8095238208770752, 0.8333333134651184, 0.8048780560493469, 0.8292682766914368]\n",
            "정확도 평균 0.8220673561096191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 검증데이터 셋을 추가해 모델의 성능 향상 시키기"
      ],
      "metadata": {
        "id": "q_yumeQg4MeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df = pd.read_csv('./data/wine.csv',header = None)\n",
        "\n",
        "X = df.iloc[:,0:12]\n",
        "y = df.iloc[:,12]\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,shuffle = True)\n",
        "#모델 선언\n",
        "model = Sequential()\n",
        "model.add(Dense(30,input_dim = 12, activation='relu'))\n",
        "model.add(Dense(12,activation='relu'))\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "history = model.fit(X_train,y_train,epochs = 50, batch_size=500,validation_split=0.25) # 검증셋 20 훈련 60 테스트 20\n",
        "\n",
        "score = model.evaluate(X_test,y_test)\n",
        "print(score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tvm6HeZe2Blz",
        "outputId": "ea9d52ce-e8cc-4f19-9f98-0695f8cce118"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_22 (Dense)            (None, 30)                390       \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 12)                372       \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 875\n",
            "Trainable params: 875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - 1s 32ms/step - loss: 2.6983 - accuracy: 0.2484 - val_loss: 0.5684 - val_accuracy: 0.6385\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4098 - accuracy: 0.7747 - val_loss: 0.3666 - val_accuracy: 0.8323\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4169 - accuracy: 0.8296 - val_loss: 0.3740 - val_accuracy: 0.8677\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3827 - accuracy: 0.8668 - val_loss: 0.2992 - val_accuracy: 0.9054\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2819 - accuracy: 0.9017 - val_loss: 0.2323 - val_accuracy: 0.9185\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2518 - accuracy: 0.9012 - val_loss: 0.2492 - val_accuracy: 0.9023\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2430 - accuracy: 0.9086 - val_loss: 0.2275 - val_accuracy: 0.9223\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2398 - accuracy: 0.9171 - val_loss: 0.2252 - val_accuracy: 0.9231\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2342 - accuracy: 0.9156 - val_loss: 0.2236 - val_accuracy: 0.9223\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2318 - accuracy: 0.9161 - val_loss: 0.2208 - val_accuracy: 0.9269\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2270 - accuracy: 0.9217 - val_loss: 0.2147 - val_accuracy: 0.9308\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2252 - accuracy: 0.9256 - val_loss: 0.2122 - val_accuracy: 0.9354\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2234 - accuracy: 0.9248 - val_loss: 0.2115 - val_accuracy: 0.9308\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2215 - accuracy: 0.9258 - val_loss: 0.2093 - val_accuracy: 0.9346\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2196 - accuracy: 0.9279 - val_loss: 0.2071 - val_accuracy: 0.9354\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2170 - accuracy: 0.9281 - val_loss: 0.2046 - val_accuracy: 0.9338\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2143 - accuracy: 0.9299 - val_loss: 0.2009 - val_accuracy: 0.9369\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2108 - accuracy: 0.9305 - val_loss: 0.1963 - val_accuracy: 0.9400\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2072 - accuracy: 0.9302 - val_loss: 0.1925 - val_accuracy: 0.9385\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2028 - accuracy: 0.9317 - val_loss: 0.1889 - val_accuracy: 0.9408\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1996 - accuracy: 0.9317 - val_loss: 0.1860 - val_accuracy: 0.9408\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1974 - accuracy: 0.9323 - val_loss: 0.1852 - val_accuracy: 0.9408\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1957 - accuracy: 0.9328 - val_loss: 0.1831 - val_accuracy: 0.9415\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1943 - accuracy: 0.9330 - val_loss: 0.1818 - val_accuracy: 0.9415\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1928 - accuracy: 0.9335 - val_loss: 0.1806 - val_accuracy: 0.9423\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1917 - accuracy: 0.9341 - val_loss: 0.1795 - val_accuracy: 0.9423\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1905 - accuracy: 0.9341 - val_loss: 0.1783 - val_accuracy: 0.9431\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1894 - accuracy: 0.9348 - val_loss: 0.1774 - val_accuracy: 0.9438\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1885 - accuracy: 0.9351 - val_loss: 0.1769 - val_accuracy: 0.9415\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1874 - accuracy: 0.9348 - val_loss: 0.1760 - val_accuracy: 0.9438\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.1865 - accuracy: 0.9346 - val_loss: 0.1754 - val_accuracy: 0.9438\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1856 - accuracy: 0.9343 - val_loss: 0.1746 - val_accuracy: 0.9462\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1849 - accuracy: 0.9351 - val_loss: 0.1741 - val_accuracy: 0.9438\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1839 - accuracy: 0.9361 - val_loss: 0.1732 - val_accuracy: 0.9454\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1830 - accuracy: 0.9353 - val_loss: 0.1727 - val_accuracy: 0.9446\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1821 - accuracy: 0.9364 - val_loss: 0.1722 - val_accuracy: 0.9454\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1814 - accuracy: 0.9361 - val_loss: 0.1713 - val_accuracy: 0.9454\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1807 - accuracy: 0.9369 - val_loss: 0.1708 - val_accuracy: 0.9454\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1799 - accuracy: 0.9364 - val_loss: 0.1703 - val_accuracy: 0.9454\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1792 - accuracy: 0.9371 - val_loss: 0.1696 - val_accuracy: 0.9454\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1785 - accuracy: 0.9371 - val_loss: 0.1689 - val_accuracy: 0.9446\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1775 - accuracy: 0.9382 - val_loss: 0.1683 - val_accuracy: 0.9454\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1770 - accuracy: 0.9376 - val_loss: 0.1677 - val_accuracy: 0.9454\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1763 - accuracy: 0.9379 - val_loss: 0.1671 - val_accuracy: 0.9462\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1755 - accuracy: 0.9382 - val_loss: 0.1668 - val_accuracy: 0.9462\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1746 - accuracy: 0.9387 - val_loss: 0.1660 - val_accuracy: 0.9469\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1740 - accuracy: 0.9387 - val_loss: 0.1652 - val_accuracy: 0.9469\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1734 - accuracy: 0.9394 - val_loss: 0.1645 - val_accuracy: 0.9477\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1724 - accuracy: 0.9397 - val_loss: 0.1639 - val_accuracy: 0.9469\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1718 - accuracy: 0.9394 - val_loss: 0.1634 - val_accuracy: 0.9477\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9292\n",
            "0.9292307496070862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 업데이트 하기\n",
        "# 학습중간에 성능이 좋은 모델이 있을수도 있기때문\n",
        "modelpath = \"./data/model/all/{epoch:20d}-{val_accuracy:.4f}.hdf5\""
      ],
      "metadata": {
        "id": "iZzBCiHJ9vTr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath,verbose=1)"
      ],
      "metadata": {
        "id": "dfgs2TZy-2Su"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 실행\n",
        "history = model.fit(X_train,y_train,epochs = 50,batch_size = 500, validation_split = 0.25,verbose=0,callbacks = [checkpointer])\n",
        "# test결과 출력\n",
        "score = model.evaluate(X_test,y_test)\n",
        "print('Test accuracy:',score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqIaHei4_IbC",
        "outputId": "54c6b23d-09e2-4310-b9e5-c494464f4fde"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: saving model to ./data/model/all/                   1-0.9477.hdf5\n",
            "\n",
            "Epoch 2: saving model to ./data/model/all/                   2-0.9477.hdf5\n",
            "\n",
            "Epoch 3: saving model to ./data/model/all/                   3-0.9477.hdf5\n",
            "\n",
            "Epoch 4: saving model to ./data/model/all/                   4-0.9485.hdf5\n",
            "\n",
            "Epoch 5: saving model to ./data/model/all/                   5-0.9485.hdf5\n",
            "\n",
            "Epoch 6: saving model to ./data/model/all/                   6-0.9485.hdf5\n",
            "\n",
            "Epoch 7: saving model to ./data/model/all/                   7-0.9477.hdf5\n",
            "\n",
            "Epoch 8: saving model to ./data/model/all/                   8-0.9485.hdf5\n",
            "\n",
            "Epoch 9: saving model to ./data/model/all/                   9-0.9492.hdf5\n",
            "\n",
            "Epoch 10: saving model to ./data/model/all/                  10-0.9492.hdf5\n",
            "\n",
            "Epoch 11: saving model to ./data/model/all/                  11-0.9500.hdf5\n",
            "\n",
            "Epoch 12: saving model to ./data/model/all/                  12-0.9500.hdf5\n",
            "\n",
            "Epoch 13: saving model to ./data/model/all/                  13-0.9500.hdf5\n",
            "\n",
            "Epoch 14: saving model to ./data/model/all/                  14-0.9500.hdf5\n",
            "\n",
            "Epoch 15: saving model to ./data/model/all/                  15-0.9508.hdf5\n",
            "\n",
            "Epoch 16: saving model to ./data/model/all/                  16-0.9515.hdf5\n",
            "\n",
            "Epoch 17: saving model to ./data/model/all/                  17-0.9508.hdf5\n",
            "\n",
            "Epoch 18: saving model to ./data/model/all/                  18-0.9523.hdf5\n",
            "\n",
            "Epoch 19: saving model to ./data/model/all/                  19-0.9531.hdf5\n",
            "\n",
            "Epoch 20: saving model to ./data/model/all/                  20-0.9523.hdf5\n",
            "\n",
            "Epoch 21: saving model to ./data/model/all/                  21-0.9546.hdf5\n",
            "\n",
            "Epoch 22: saving model to ./data/model/all/                  22-0.9538.hdf5\n",
            "\n",
            "Epoch 23: saving model to ./data/model/all/                  23-0.9538.hdf5\n",
            "\n",
            "Epoch 24: saving model to ./data/model/all/                  24-0.9531.hdf5\n",
            "\n",
            "Epoch 25: saving model to ./data/model/all/                  25-0.9538.hdf5\n",
            "\n",
            "Epoch 26: saving model to ./data/model/all/                  26-0.9531.hdf5\n",
            "\n",
            "Epoch 27: saving model to ./data/model/all/                  27-0.9523.hdf5\n",
            "\n",
            "Epoch 28: saving model to ./data/model/all/                  28-0.9523.hdf5\n",
            "\n",
            "Epoch 29: saving model to ./data/model/all/                  29-0.9531.hdf5\n",
            "\n",
            "Epoch 30: saving model to ./data/model/all/                  30-0.9546.hdf5\n",
            "\n",
            "Epoch 31: saving model to ./data/model/all/                  31-0.9531.hdf5\n",
            "\n",
            "Epoch 32: saving model to ./data/model/all/                  32-0.9546.hdf5\n",
            "\n",
            "Epoch 33: saving model to ./data/model/all/                  33-0.9531.hdf5\n",
            "\n",
            "Epoch 34: saving model to ./data/model/all/                  34-0.9546.hdf5\n",
            "\n",
            "Epoch 35: saving model to ./data/model/all/                  35-0.9546.hdf5\n",
            "\n",
            "Epoch 36: saving model to ./data/model/all/                  36-0.9538.hdf5\n",
            "\n",
            "Epoch 37: saving model to ./data/model/all/                  37-0.9538.hdf5\n",
            "\n",
            "Epoch 38: saving model to ./data/model/all/                  38-0.9546.hdf5\n",
            "\n",
            "Epoch 39: saving model to ./data/model/all/                  39-0.9554.hdf5\n",
            "\n",
            "Epoch 40: saving model to ./data/model/all/                  40-0.9546.hdf5\n",
            "\n",
            "Epoch 41: saving model to ./data/model/all/                  41-0.9569.hdf5\n",
            "\n",
            "Epoch 42: saving model to ./data/model/all/                  42-0.9569.hdf5\n",
            "\n",
            "Epoch 43: saving model to ./data/model/all/                  43-0.9562.hdf5\n",
            "\n",
            "Epoch 44: saving model to ./data/model/all/                  44-0.9585.hdf5\n",
            "\n",
            "Epoch 45: saving model to ./data/model/all/                  45-0.9585.hdf5\n",
            "\n",
            "Epoch 46: saving model to ./data/model/all/                  46-0.9569.hdf5\n",
            "\n",
            "Epoch 47: saving model to ./data/model/all/                  47-0.9577.hdf5\n",
            "\n",
            "Epoch 48: saving model to ./data/model/all/                  48-0.9592.hdf5\n",
            "\n",
            "Epoch 49: saving model to ./data/model/all/                  49-0.9600.hdf5\n",
            "\n",
            "Epoch 50: saving model to ./data/model/all/                  50-0.9600.hdf5\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.1436 - accuracy: 0.9446\n",
            "Test accuracy: 0.944615364074707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 성능이 좋은 epoch값 찾기\n",
        "best_epoch = max(range(1, len(history.history['accuracy']) + 1), key=lambda x: history.history['accuracy'][x - 1])\n",
        "best_accuracy = history.history['accuracy'][best_epoch - 1]\n",
        "\n",
        "print('Best epoch:', best_epoch)\n",
        "print('Best accuracy:', best_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uALcgb6_rTB",
        "outputId": "c0f84431-d506-452f-95c7-26fd1652b96e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best epoch: 49\n",
            "Best accuracy: 0.9550936818122864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 그래프로 과적합 확인하기"
      ],
      "metadata": {
        "id": "tI8733hdCS2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# epoch를 2000으로 설정하고 과적합 확인하기\n",
        "history = model.fit(X_train,y_train,epochs = 2000,batch_size = 500, validation_split = 0.25)\n",
        "hist_df = pd.DataFrame(history.history)\n",
        "hist_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IH9mHT3QANXf",
        "outputId": "1f23ad8f-b855-4eba-98e0-d4f5b02ff4cf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.1216 - accuracy: 0.9546 - val_loss: 0.1238 - val_accuracy: 0.9608\n",
            "Epoch 2/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1211 - accuracy: 0.9546 - val_loss: 0.1230 - val_accuracy: 0.9608\n",
            "Epoch 3/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.1201 - accuracy: 0.9548 - val_loss: 0.1229 - val_accuracy: 0.9608\n",
            "Epoch 4/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.1191 - accuracy: 0.9543 - val_loss: 0.1214 - val_accuracy: 0.9608\n",
            "Epoch 5/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.1186 - accuracy: 0.9554 - val_loss: 0.1216 - val_accuracy: 0.9600\n",
            "Epoch 6/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.1178 - accuracy: 0.9561 - val_loss: 0.1206 - val_accuracy: 0.9608\n",
            "Epoch 7/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1171 - accuracy: 0.9559 - val_loss: 0.1201 - val_accuracy: 0.9608\n",
            "Epoch 8/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1160 - accuracy: 0.9569 - val_loss: 0.1200 - val_accuracy: 0.9615\n",
            "Epoch 9/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1153 - accuracy: 0.9566 - val_loss: 0.1191 - val_accuracy: 0.9608\n",
            "Epoch 10/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1156 - accuracy: 0.9579 - val_loss: 0.1187 - val_accuracy: 0.9615\n",
            "Epoch 11/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1148 - accuracy: 0.9556 - val_loss: 0.1177 - val_accuracy: 0.9600\n",
            "Epoch 12/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1143 - accuracy: 0.9587 - val_loss: 0.1170 - val_accuracy: 0.9608\n",
            "Epoch 13/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1127 - accuracy: 0.9582 - val_loss: 0.1170 - val_accuracy: 0.9615\n",
            "Epoch 14/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1119 - accuracy: 0.9574 - val_loss: 0.1161 - val_accuracy: 0.9615\n",
            "Epoch 15/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1111 - accuracy: 0.9584 - val_loss: 0.1154 - val_accuracy: 0.9615\n",
            "Epoch 16/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1106 - accuracy: 0.9579 - val_loss: 0.1146 - val_accuracy: 0.9631\n",
            "Epoch 17/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1100 - accuracy: 0.9592 - val_loss: 0.1140 - val_accuracy: 0.9623\n",
            "Epoch 18/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1094 - accuracy: 0.9574 - val_loss: 0.1138 - val_accuracy: 0.9638\n",
            "Epoch 19/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1087 - accuracy: 0.9605 - val_loss: 0.1121 - val_accuracy: 0.9608\n",
            "Epoch 20/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1077 - accuracy: 0.9582 - val_loss: 0.1124 - val_accuracy: 0.9654\n",
            "Epoch 21/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1074 - accuracy: 0.9592 - val_loss: 0.1114 - val_accuracy: 0.9654\n",
            "Epoch 22/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1067 - accuracy: 0.9633 - val_loss: 0.1103 - val_accuracy: 0.9623\n",
            "Epoch 23/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1058 - accuracy: 0.9592 - val_loss: 0.1087 - val_accuracy: 0.9631\n",
            "Epoch 24/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1045 - accuracy: 0.9610 - val_loss: 0.1079 - val_accuracy: 0.9631\n",
            "Epoch 25/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.1035 - accuracy: 0.9605 - val_loss: 0.1072 - val_accuracy: 0.9631\n",
            "Epoch 26/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1030 - accuracy: 0.9602 - val_loss: 0.1059 - val_accuracy: 0.9631\n",
            "Epoch 27/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1020 - accuracy: 0.9628 - val_loss: 0.1055 - val_accuracy: 0.9631\n",
            "Epoch 28/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1012 - accuracy: 0.9630 - val_loss: 0.1051 - val_accuracy: 0.9631\n",
            "Epoch 29/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1002 - accuracy: 0.9625 - val_loss: 0.1044 - val_accuracy: 0.9654\n",
            "Epoch 30/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0992 - accuracy: 0.9625 - val_loss: 0.1038 - val_accuracy: 0.9654\n",
            "Epoch 31/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0985 - accuracy: 0.9646 - val_loss: 0.1034 - val_accuracy: 0.9623\n",
            "Epoch 32/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0985 - accuracy: 0.9620 - val_loss: 0.1057 - val_accuracy: 0.9715\n",
            "Epoch 33/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0975 - accuracy: 0.9659 - val_loss: 0.1026 - val_accuracy: 0.9623\n",
            "Epoch 34/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0968 - accuracy: 0.9666 - val_loss: 0.1018 - val_accuracy: 0.9631\n",
            "Epoch 35/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0954 - accuracy: 0.9646 - val_loss: 0.1016 - val_accuracy: 0.9677\n",
            "Epoch 36/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0946 - accuracy: 0.9666 - val_loss: 0.1011 - val_accuracy: 0.9677\n",
            "Epoch 37/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0935 - accuracy: 0.9659 - val_loss: 0.1012 - val_accuracy: 0.9700\n",
            "Epoch 38/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0939 - accuracy: 0.9664 - val_loss: 0.1012 - val_accuracy: 0.9646\n",
            "Epoch 39/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0923 - accuracy: 0.9687 - val_loss: 0.1008 - val_accuracy: 0.9692\n",
            "Epoch 40/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0916 - accuracy: 0.9674 - val_loss: 0.1007 - val_accuracy: 0.9700\n",
            "Epoch 41/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0911 - accuracy: 0.9692 - val_loss: 0.0996 - val_accuracy: 0.9685\n",
            "Epoch 42/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0902 - accuracy: 0.9682 - val_loss: 0.0999 - val_accuracy: 0.9708\n",
            "Epoch 43/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0896 - accuracy: 0.9679 - val_loss: 0.0986 - val_accuracy: 0.9700\n",
            "Epoch 44/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0882 - accuracy: 0.9705 - val_loss: 0.0983 - val_accuracy: 0.9685\n",
            "Epoch 45/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0876 - accuracy: 0.9707 - val_loss: 0.0980 - val_accuracy: 0.9700\n",
            "Epoch 46/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0869 - accuracy: 0.9700 - val_loss: 0.0976 - val_accuracy: 0.9685\n",
            "Epoch 47/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0864 - accuracy: 0.9723 - val_loss: 0.0973 - val_accuracy: 0.9692\n",
            "Epoch 48/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0857 - accuracy: 0.9720 - val_loss: 0.0971 - val_accuracy: 0.9692\n",
            "Epoch 49/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0851 - accuracy: 0.9710 - val_loss: 0.0978 - val_accuracy: 0.9738\n",
            "Epoch 50/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0841 - accuracy: 0.9720 - val_loss: 0.0979 - val_accuracy: 0.9677\n",
            "Epoch 51/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0839 - accuracy: 0.9710 - val_loss: 0.0970 - val_accuracy: 0.9731\n",
            "Epoch 52/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0826 - accuracy: 0.9725 - val_loss: 0.0959 - val_accuracy: 0.9731\n",
            "Epoch 53/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0820 - accuracy: 0.9736 - val_loss: 0.0956 - val_accuracy: 0.9731\n",
            "Epoch 54/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0814 - accuracy: 0.9749 - val_loss: 0.0954 - val_accuracy: 0.9723\n",
            "Epoch 55/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0815 - accuracy: 0.9725 - val_loss: 0.0987 - val_accuracy: 0.9708\n",
            "Epoch 56/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0825 - accuracy: 0.9705 - val_loss: 0.0950 - val_accuracy: 0.9715\n",
            "Epoch 57/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0802 - accuracy: 0.9746 - val_loss: 0.0974 - val_accuracy: 0.9677\n",
            "Epoch 58/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0815 - accuracy: 0.9746 - val_loss: 0.0948 - val_accuracy: 0.9746\n",
            "Epoch 59/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0786 - accuracy: 0.9746 - val_loss: 0.0941 - val_accuracy: 0.9738\n",
            "Epoch 60/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0785 - accuracy: 0.9746 - val_loss: 0.0949 - val_accuracy: 0.9708\n",
            "Epoch 61/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0776 - accuracy: 0.9746 - val_loss: 0.0936 - val_accuracy: 0.9746\n",
            "Epoch 62/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0766 - accuracy: 0.9754 - val_loss: 0.0934 - val_accuracy: 0.9746\n",
            "Epoch 63/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0762 - accuracy: 0.9759 - val_loss: 0.0946 - val_accuracy: 0.9708\n",
            "Epoch 64/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0759 - accuracy: 0.9759 - val_loss: 0.0934 - val_accuracy: 0.9754\n",
            "Epoch 65/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0754 - accuracy: 0.9761 - val_loss: 0.0927 - val_accuracy: 0.9754\n",
            "Epoch 66/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0754 - accuracy: 0.9759 - val_loss: 0.0926 - val_accuracy: 0.9746\n",
            "Epoch 67/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0746 - accuracy: 0.9764 - val_loss: 0.0922 - val_accuracy: 0.9738\n",
            "Epoch 68/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0752 - accuracy: 0.9751 - val_loss: 0.0946 - val_accuracy: 0.9708\n",
            "Epoch 69/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0742 - accuracy: 0.9759 - val_loss: 0.0911 - val_accuracy: 0.9754\n",
            "Epoch 70/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0730 - accuracy: 0.9769 - val_loss: 0.0947 - val_accuracy: 0.9708\n",
            "Epoch 71/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0739 - accuracy: 0.9759 - val_loss: 0.0912 - val_accuracy: 0.9731\n",
            "Epoch 72/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0718 - accuracy: 0.9759 - val_loss: 0.0907 - val_accuracy: 0.9762\n",
            "Epoch 73/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0709 - accuracy: 0.9759 - val_loss: 0.0912 - val_accuracy: 0.9746\n",
            "Epoch 74/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0717 - accuracy: 0.9772 - val_loss: 0.0898 - val_accuracy: 0.9754\n",
            "Epoch 75/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0706 - accuracy: 0.9766 - val_loss: 0.0895 - val_accuracy: 0.9754\n",
            "Epoch 76/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0697 - accuracy: 0.9774 - val_loss: 0.0908 - val_accuracy: 0.9731\n",
            "Epoch 77/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0694 - accuracy: 0.9769 - val_loss: 0.0893 - val_accuracy: 0.9762\n",
            "Epoch 78/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0689 - accuracy: 0.9774 - val_loss: 0.0884 - val_accuracy: 0.9762\n",
            "Epoch 79/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0684 - accuracy: 0.9774 - val_loss: 0.0888 - val_accuracy: 0.9777\n",
            "Epoch 80/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0692 - accuracy: 0.9772 - val_loss: 0.0877 - val_accuracy: 0.9769\n",
            "Epoch 81/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0673 - accuracy: 0.9782 - val_loss: 0.0871 - val_accuracy: 0.9785\n",
            "Epoch 82/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0667 - accuracy: 0.9779 - val_loss: 0.0877 - val_accuracy: 0.9785\n",
            "Epoch 83/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0667 - accuracy: 0.9777 - val_loss: 0.0869 - val_accuracy: 0.9785\n",
            "Epoch 84/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0667 - accuracy: 0.9777 - val_loss: 0.0874 - val_accuracy: 0.9800\n",
            "Epoch 85/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0656 - accuracy: 0.9782 - val_loss: 0.0870 - val_accuracy: 0.9785\n",
            "Epoch 86/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0652 - accuracy: 0.9787 - val_loss: 0.0866 - val_accuracy: 0.9785\n",
            "Epoch 87/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0647 - accuracy: 0.9784 - val_loss: 0.0860 - val_accuracy: 0.9785\n",
            "Epoch 88/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0646 - accuracy: 0.9784 - val_loss: 0.0859 - val_accuracy: 0.9785\n",
            "Epoch 89/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0660 - accuracy: 0.9784 - val_loss: 0.0917 - val_accuracy: 0.9731\n",
            "Epoch 90/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0665 - accuracy: 0.9790 - val_loss: 0.0860 - val_accuracy: 0.9777\n",
            "Epoch 91/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0637 - accuracy: 0.9782 - val_loss: 0.0853 - val_accuracy: 0.9785\n",
            "Epoch 92/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0644 - accuracy: 0.9787 - val_loss: 0.0893 - val_accuracy: 0.9731\n",
            "Epoch 93/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0663 - accuracy: 0.9787 - val_loss: 0.0846 - val_accuracy: 0.9785\n",
            "Epoch 94/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0631 - accuracy: 0.9790 - val_loss: 0.0851 - val_accuracy: 0.9800\n",
            "Epoch 95/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0620 - accuracy: 0.9787 - val_loss: 0.0856 - val_accuracy: 0.9792\n",
            "Epoch 96/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0621 - accuracy: 0.9784 - val_loss: 0.0876 - val_accuracy: 0.9746\n",
            "Epoch 97/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0624 - accuracy: 0.9774 - val_loss: 0.0840 - val_accuracy: 0.9785\n",
            "Epoch 98/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0622 - accuracy: 0.9787 - val_loss: 0.0850 - val_accuracy: 0.9800\n",
            "Epoch 99/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0605 - accuracy: 0.9813 - val_loss: 0.0843 - val_accuracy: 0.9777\n",
            "Epoch 100/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0605 - accuracy: 0.9797 - val_loss: 0.0834 - val_accuracy: 0.9777\n",
            "Epoch 101/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0604 - accuracy: 0.9784 - val_loss: 0.0840 - val_accuracy: 0.9800\n",
            "Epoch 102/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0593 - accuracy: 0.9805 - val_loss: 0.0831 - val_accuracy: 0.9777\n",
            "Epoch 103/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0589 - accuracy: 0.9797 - val_loss: 0.0840 - val_accuracy: 0.9800\n",
            "Epoch 104/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0591 - accuracy: 0.9797 - val_loss: 0.0851 - val_accuracy: 0.9800\n",
            "Epoch 105/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0587 - accuracy: 0.9792 - val_loss: 0.0843 - val_accuracy: 0.9762\n",
            "Epoch 106/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0595 - accuracy: 0.9802 - val_loss: 0.0827 - val_accuracy: 0.9800\n",
            "Epoch 107/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0576 - accuracy: 0.9800 - val_loss: 0.0821 - val_accuracy: 0.9785\n",
            "Epoch 108/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0575 - accuracy: 0.9802 - val_loss: 0.0848 - val_accuracy: 0.9792\n",
            "Epoch 109/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0595 - accuracy: 0.9790 - val_loss: 0.0821 - val_accuracy: 0.9792\n",
            "Epoch 110/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0572 - accuracy: 0.9800 - val_loss: 0.0830 - val_accuracy: 0.9792\n",
            "Epoch 111/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0574 - accuracy: 0.9800 - val_loss: 0.0830 - val_accuracy: 0.9800\n",
            "Epoch 112/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0566 - accuracy: 0.9823 - val_loss: 0.0822 - val_accuracy: 0.9762\n",
            "Epoch 113/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0568 - accuracy: 0.9813 - val_loss: 0.0815 - val_accuracy: 0.9777\n",
            "Epoch 114/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0573 - accuracy: 0.9820 - val_loss: 0.0910 - val_accuracy: 0.9777\n",
            "Epoch 115/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0585 - accuracy: 0.9818 - val_loss: 0.0822 - val_accuracy: 0.9800\n",
            "Epoch 116/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0570 - accuracy: 0.9810 - val_loss: 0.0812 - val_accuracy: 0.9777\n",
            "Epoch 117/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0558 - accuracy: 0.9815 - val_loss: 0.0809 - val_accuracy: 0.9777\n",
            "Epoch 118/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0549 - accuracy: 0.9818 - val_loss: 0.0810 - val_accuracy: 0.9808\n",
            "Epoch 119/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0558 - accuracy: 0.9813 - val_loss: 0.0808 - val_accuracy: 0.9777\n",
            "Epoch 120/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0542 - accuracy: 0.9815 - val_loss: 0.0802 - val_accuracy: 0.9808\n",
            "Epoch 121/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0541 - accuracy: 0.9815 - val_loss: 0.0811 - val_accuracy: 0.9808\n",
            "Epoch 122/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0552 - accuracy: 0.9815 - val_loss: 0.0802 - val_accuracy: 0.9792\n",
            "Epoch 123/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0541 - accuracy: 0.9802 - val_loss: 0.0797 - val_accuracy: 0.9792\n",
            "Epoch 124/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0535 - accuracy: 0.9818 - val_loss: 0.0795 - val_accuracy: 0.9792\n",
            "Epoch 125/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0532 - accuracy: 0.9818 - val_loss: 0.0795 - val_accuracy: 0.9777\n",
            "Epoch 126/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0526 - accuracy: 0.9815 - val_loss: 0.0826 - val_accuracy: 0.9808\n",
            "Epoch 127/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0525 - accuracy: 0.9813 - val_loss: 0.0803 - val_accuracy: 0.9769\n",
            "Epoch 128/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0522 - accuracy: 0.9818 - val_loss: 0.0799 - val_accuracy: 0.9808\n",
            "Epoch 129/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0528 - accuracy: 0.9815 - val_loss: 0.0844 - val_accuracy: 0.9815\n",
            "Epoch 130/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0546 - accuracy: 0.9813 - val_loss: 0.0804 - val_accuracy: 0.9815\n",
            "Epoch 131/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0518 - accuracy: 0.9823 - val_loss: 0.0789 - val_accuracy: 0.9792\n",
            "Epoch 132/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0529 - accuracy: 0.9823 - val_loss: 0.0787 - val_accuracy: 0.9792\n",
            "Epoch 133/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0504 - accuracy: 0.9826 - val_loss: 0.0821 - val_accuracy: 0.9808\n",
            "Epoch 134/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0513 - accuracy: 0.9831 - val_loss: 0.0800 - val_accuracy: 0.9769\n",
            "Epoch 135/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0517 - accuracy: 0.9826 - val_loss: 0.0786 - val_accuracy: 0.9777\n",
            "Epoch 136/2000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0527 - accuracy: 0.9820 - val_loss: 0.0784 - val_accuracy: 0.9792\n",
            "Epoch 137/2000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0511 - accuracy: 0.9833 - val_loss: 0.0795 - val_accuracy: 0.9823\n",
            "Epoch 138/2000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.0496 - accuracy: 0.9828 - val_loss: 0.0783 - val_accuracy: 0.9800\n",
            "Epoch 139/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0527 - accuracy: 0.9818 - val_loss: 0.0788 - val_accuracy: 0.9769\n",
            "Epoch 140/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0499 - accuracy: 0.9828 - val_loss: 0.0820 - val_accuracy: 0.9808\n",
            "Epoch 141/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0507 - accuracy: 0.9836 - val_loss: 0.0791 - val_accuracy: 0.9823\n",
            "Epoch 142/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0492 - accuracy: 0.9828 - val_loss: 0.0775 - val_accuracy: 0.9808\n",
            "Epoch 143/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0503 - accuracy: 0.9831 - val_loss: 0.0795 - val_accuracy: 0.9823\n",
            "Epoch 144/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0512 - accuracy: 0.9828 - val_loss: 0.0805 - val_accuracy: 0.9823\n",
            "Epoch 145/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0485 - accuracy: 0.9836 - val_loss: 0.0782 - val_accuracy: 0.9808\n",
            "Epoch 146/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0484 - accuracy: 0.9836 - val_loss: 0.0781 - val_accuracy: 0.9815\n",
            "Epoch 147/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0486 - accuracy: 0.9831 - val_loss: 0.0775 - val_accuracy: 0.9785\n",
            "Epoch 148/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0484 - accuracy: 0.9833 - val_loss: 0.0781 - val_accuracy: 0.9823\n",
            "Epoch 149/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0478 - accuracy: 0.9838 - val_loss: 0.0812 - val_accuracy: 0.9815\n",
            "Epoch 150/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0482 - accuracy: 0.9838 - val_loss: 0.0779 - val_accuracy: 0.9777\n",
            "Epoch 151/2000\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0477 - accuracy: 0.9831 - val_loss: 0.0839 - val_accuracy: 0.9815\n",
            "Epoch 152/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0504 - accuracy: 0.9836 - val_loss: 0.0879 - val_accuracy: 0.9785\n",
            "Epoch 153/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0504 - accuracy: 0.9823 - val_loss: 0.0773 - val_accuracy: 0.9815\n",
            "Epoch 154/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0496 - accuracy: 0.9836 - val_loss: 0.0802 - val_accuracy: 0.9762\n",
            "Epoch 155/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0489 - accuracy: 0.9833 - val_loss: 0.0786 - val_accuracy: 0.9815\n",
            "Epoch 156/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0473 - accuracy: 0.9838 - val_loss: 0.0774 - val_accuracy: 0.9800\n",
            "Epoch 157/2000\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0473 - accuracy: 0.9831 - val_loss: 0.0849 - val_accuracy: 0.9800\n",
            "Epoch 158/2000\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0484 - accuracy: 0.9828 - val_loss: 0.0784 - val_accuracy: 0.9823\n",
            "Epoch 159/2000\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.0474 - accuracy: 0.9836 - val_loss: 0.0764 - val_accuracy: 0.9785\n",
            "Epoch 160/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0465 - accuracy: 0.9838 - val_loss: 0.0765 - val_accuracy: 0.9823\n",
            "Epoch 161/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0493 - accuracy: 0.9836 - val_loss: 0.0781 - val_accuracy: 0.9823\n",
            "Epoch 162/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0460 - accuracy: 0.9836 - val_loss: 0.0807 - val_accuracy: 0.9815\n",
            "Epoch 163/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0470 - accuracy: 0.9833 - val_loss: 0.0783 - val_accuracy: 0.9823\n",
            "Epoch 164/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0461 - accuracy: 0.9841 - val_loss: 0.0760 - val_accuracy: 0.9808\n",
            "Epoch 165/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0465 - accuracy: 0.9849 - val_loss: 0.0759 - val_accuracy: 0.9823\n",
            "Epoch 166/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0457 - accuracy: 0.9836 - val_loss: 0.0811 - val_accuracy: 0.9808\n",
            "Epoch 167/2000\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0455 - accuracy: 0.9854 - val_loss: 0.0762 - val_accuracy: 0.9815\n",
            "Epoch 168/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0455 - accuracy: 0.9846 - val_loss: 0.0764 - val_accuracy: 0.9823\n",
            "Epoch 169/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0454 - accuracy: 0.9838 - val_loss: 0.0778 - val_accuracy: 0.9823\n",
            "Epoch 170/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0441 - accuracy: 0.9854 - val_loss: 0.0756 - val_accuracy: 0.9815\n",
            "Epoch 171/2000\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0444 - accuracy: 0.9851 - val_loss: 0.0770 - val_accuracy: 0.9823\n",
            "Epoch 172/2000\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0446 - accuracy: 0.9849 - val_loss: 0.0794 - val_accuracy: 0.9815\n",
            "Epoch 173/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0444 - accuracy: 0.9841 - val_loss: 0.0759 - val_accuracy: 0.9815\n",
            "Epoch 174/2000\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0450 - accuracy: 0.9861 - val_loss: 0.0766 - val_accuracy: 0.9823\n",
            "Epoch 175/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0443 - accuracy: 0.9849 - val_loss: 0.0750 - val_accuracy: 0.9815\n",
            "Epoch 176/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0456 - accuracy: 0.9841 - val_loss: 0.0757 - val_accuracy: 0.9808\n",
            "Epoch 177/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0464 - accuracy: 0.9841 - val_loss: 0.0765 - val_accuracy: 0.9815\n",
            "Epoch 178/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0448 - accuracy: 0.9851 - val_loss: 0.0790 - val_accuracy: 0.9823\n",
            "Epoch 179/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0435 - accuracy: 0.9856 - val_loss: 0.0780 - val_accuracy: 0.9815\n",
            "Epoch 180/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0446 - accuracy: 0.9851 - val_loss: 0.0777 - val_accuracy: 0.9823\n",
            "Epoch 181/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0445 - accuracy: 0.9867 - val_loss: 0.0753 - val_accuracy: 0.9815\n",
            "Epoch 182/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0434 - accuracy: 0.9843 - val_loss: 0.0763 - val_accuracy: 0.9831\n",
            "Epoch 183/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0429 - accuracy: 0.9849 - val_loss: 0.0755 - val_accuracy: 0.9815\n",
            "Epoch 184/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0422 - accuracy: 0.9859 - val_loss: 0.0817 - val_accuracy: 0.9808\n",
            "Epoch 185/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0442 - accuracy: 0.9851 - val_loss: 0.0786 - val_accuracy: 0.9823\n",
            "Epoch 186/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0439 - accuracy: 0.9851 - val_loss: 0.0841 - val_accuracy: 0.9808\n",
            "Epoch 187/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0448 - accuracy: 0.9849 - val_loss: 0.0805 - val_accuracy: 0.9815\n",
            "Epoch 188/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0442 - accuracy: 0.9859 - val_loss: 0.0757 - val_accuracy: 0.9815\n",
            "Epoch 189/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0434 - accuracy: 0.9849 - val_loss: 0.0760 - val_accuracy: 0.9808\n",
            "Epoch 190/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0447 - accuracy: 0.9849 - val_loss: 0.0758 - val_accuracy: 0.9823\n",
            "Epoch 191/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0421 - accuracy: 0.9864 - val_loss: 0.0777 - val_accuracy: 0.9823\n",
            "Epoch 192/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0425 - accuracy: 0.9843 - val_loss: 0.0846 - val_accuracy: 0.9808\n",
            "Epoch 193/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0457 - accuracy: 0.9843 - val_loss: 0.0804 - val_accuracy: 0.9815\n",
            "Epoch 194/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0435 - accuracy: 0.9849 - val_loss: 0.0789 - val_accuracy: 0.9823\n",
            "Epoch 195/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0422 - accuracy: 0.9861 - val_loss: 0.0780 - val_accuracy: 0.9792\n",
            "Epoch 196/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0426 - accuracy: 0.9849 - val_loss: 0.0787 - val_accuracy: 0.9823\n",
            "Epoch 197/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0418 - accuracy: 0.9864 - val_loss: 0.0763 - val_accuracy: 0.9815\n",
            "Epoch 198/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0421 - accuracy: 0.9859 - val_loss: 0.0752 - val_accuracy: 0.9815\n",
            "Epoch 199/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0452 - accuracy: 0.9843 - val_loss: 0.0752 - val_accuracy: 0.9831\n",
            "Epoch 200/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0431 - accuracy: 0.9849 - val_loss: 0.0761 - val_accuracy: 0.9823\n",
            "Epoch 201/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0424 - accuracy: 0.9854 - val_loss: 0.0867 - val_accuracy: 0.9800\n",
            "Epoch 202/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0431 - accuracy: 0.9856 - val_loss: 0.0751 - val_accuracy: 0.9823\n",
            "Epoch 203/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0411 - accuracy: 0.9864 - val_loss: 0.0750 - val_accuracy: 0.9815\n",
            "Epoch 204/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0409 - accuracy: 0.9854 - val_loss: 0.0749 - val_accuracy: 0.9831\n",
            "Epoch 205/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0403 - accuracy: 0.9867 - val_loss: 0.0809 - val_accuracy: 0.9815\n",
            "Epoch 206/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0424 - accuracy: 0.9872 - val_loss: 0.0785 - val_accuracy: 0.9823\n",
            "Epoch 207/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0417 - accuracy: 0.9854 - val_loss: 0.0744 - val_accuracy: 0.9831\n",
            "Epoch 208/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0396 - accuracy: 0.9874 - val_loss: 0.0889 - val_accuracy: 0.9792\n",
            "Epoch 209/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0447 - accuracy: 0.9841 - val_loss: 0.0796 - val_accuracy: 0.9823\n",
            "Epoch 210/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0413 - accuracy: 0.9859 - val_loss: 0.0758 - val_accuracy: 0.9815\n",
            "Epoch 211/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0401 - accuracy: 0.9867 - val_loss: 0.0749 - val_accuracy: 0.9831\n",
            "Epoch 212/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0400 - accuracy: 0.9867 - val_loss: 0.0778 - val_accuracy: 0.9815\n",
            "Epoch 213/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0407 - accuracy: 0.9872 - val_loss: 0.0761 - val_accuracy: 0.9823\n",
            "Epoch 214/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0408 - accuracy: 0.9864 - val_loss: 0.0744 - val_accuracy: 0.9831\n",
            "Epoch 215/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0396 - accuracy: 0.9859 - val_loss: 0.0743 - val_accuracy: 0.9831\n",
            "Epoch 216/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0407 - accuracy: 0.9867 - val_loss: 0.0734 - val_accuracy: 0.9846\n",
            "Epoch 217/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0407 - accuracy: 0.9867 - val_loss: 0.0757 - val_accuracy: 0.9823\n",
            "Epoch 218/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0437 - accuracy: 0.9846 - val_loss: 0.0815 - val_accuracy: 0.9815\n",
            "Epoch 219/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0422 - accuracy: 0.9859 - val_loss: 0.0910 - val_accuracy: 0.9792\n",
            "Epoch 220/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0446 - accuracy: 0.9854 - val_loss: 0.0744 - val_accuracy: 0.9838\n",
            "Epoch 221/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0407 - accuracy: 0.9859 - val_loss: 0.0736 - val_accuracy: 0.9846\n",
            "Epoch 222/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0401 - accuracy: 0.9854 - val_loss: 0.0738 - val_accuracy: 0.9831\n",
            "Epoch 223/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0387 - accuracy: 0.9867 - val_loss: 0.0764 - val_accuracy: 0.9823\n",
            "Epoch 224/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0393 - accuracy: 0.9879 - val_loss: 0.0747 - val_accuracy: 0.9831\n",
            "Epoch 225/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0389 - accuracy: 0.9869 - val_loss: 0.0739 - val_accuracy: 0.9831\n",
            "Epoch 226/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0390 - accuracy: 0.9869 - val_loss: 0.0732 - val_accuracy: 0.9846\n",
            "Epoch 227/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0401 - accuracy: 0.9859 - val_loss: 0.0728 - val_accuracy: 0.9854\n",
            "Epoch 228/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0394 - accuracy: 0.9879 - val_loss: 0.0759 - val_accuracy: 0.9823\n",
            "Epoch 229/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.0751 - val_accuracy: 0.9831\n",
            "Epoch 230/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0412 - accuracy: 0.9861 - val_loss: 0.0759 - val_accuracy: 0.9823\n",
            "Epoch 231/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0392 - accuracy: 0.9864 - val_loss: 0.0732 - val_accuracy: 0.9846\n",
            "Epoch 232/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0397 - accuracy: 0.9859 - val_loss: 0.0736 - val_accuracy: 0.9846\n",
            "Epoch 233/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0402 - accuracy: 0.9861 - val_loss: 0.0769 - val_accuracy: 0.9823\n",
            "Epoch 234/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0384 - accuracy: 0.9867 - val_loss: 0.0765 - val_accuracy: 0.9823\n",
            "Epoch 235/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0404 - accuracy: 0.9869 - val_loss: 0.0766 - val_accuracy: 0.9815\n",
            "Epoch 236/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0386 - accuracy: 0.9856 - val_loss: 0.0810 - val_accuracy: 0.9823\n",
            "Epoch 237/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0407 - accuracy: 0.9874 - val_loss: 0.0761 - val_accuracy: 0.9831\n",
            "Epoch 238/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0408 - accuracy: 0.9869 - val_loss: 0.0733 - val_accuracy: 0.9846\n",
            "Epoch 239/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0383 - accuracy: 0.9872 - val_loss: 0.0736 - val_accuracy: 0.9854\n",
            "Epoch 240/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0375 - accuracy: 0.9877 - val_loss: 0.0739 - val_accuracy: 0.9846\n",
            "Epoch 241/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0375 - accuracy: 0.9872 - val_loss: 0.0733 - val_accuracy: 0.9846\n",
            "Epoch 242/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0384 - accuracy: 0.9872 - val_loss: 0.0715 - val_accuracy: 0.9862\n",
            "Epoch 243/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0400 - accuracy: 0.9864 - val_loss: 0.0724 - val_accuracy: 0.9854\n",
            "Epoch 244/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0385 - accuracy: 0.9861 - val_loss: 0.0853 - val_accuracy: 0.9792\n",
            "Epoch 245/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0396 - accuracy: 0.9872 - val_loss: 0.0742 - val_accuracy: 0.9838\n",
            "Epoch 246/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0377 - accuracy: 0.9874 - val_loss: 0.0716 - val_accuracy: 0.9854\n",
            "Epoch 247/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0384 - accuracy: 0.9877 - val_loss: 0.0723 - val_accuracy: 0.9854\n",
            "Epoch 248/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0369 - accuracy: 0.9879 - val_loss: 0.0770 - val_accuracy: 0.9823\n",
            "Epoch 249/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0378 - accuracy: 0.9877 - val_loss: 0.0724 - val_accuracy: 0.9854\n",
            "Epoch 250/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0376 - accuracy: 0.9874 - val_loss: 0.0735 - val_accuracy: 0.9854\n",
            "Epoch 251/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0401 - accuracy: 0.9864 - val_loss: 0.0717 - val_accuracy: 0.9854\n",
            "Epoch 252/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0375 - accuracy: 0.9885 - val_loss: 0.0813 - val_accuracy: 0.9808\n",
            "Epoch 253/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0383 - accuracy: 0.9869 - val_loss: 0.0751 - val_accuracy: 0.9846\n",
            "Epoch 254/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0375 - accuracy: 0.9887 - val_loss: 0.0781 - val_accuracy: 0.9823\n",
            "Epoch 255/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0388 - accuracy: 0.9859 - val_loss: 0.0723 - val_accuracy: 0.9854\n",
            "Epoch 256/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0367 - accuracy: 0.9864 - val_loss: 0.0709 - val_accuracy: 0.9846\n",
            "Epoch 257/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0378 - accuracy: 0.9885 - val_loss: 0.0721 - val_accuracy: 0.9854\n",
            "Epoch 258/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0374 - accuracy: 0.9867 - val_loss: 0.0729 - val_accuracy: 0.9854\n",
            "Epoch 259/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0366 - accuracy: 0.9877 - val_loss: 0.0816 - val_accuracy: 0.9808\n",
            "Epoch 260/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0380 - accuracy: 0.9879 - val_loss: 0.0731 - val_accuracy: 0.9854\n",
            "Epoch 261/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0369 - accuracy: 0.9885 - val_loss: 0.0731 - val_accuracy: 0.9854\n",
            "Epoch 262/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0369 - accuracy: 0.9882 - val_loss: 0.0711 - val_accuracy: 0.9862\n",
            "Epoch 263/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0363 - accuracy: 0.9872 - val_loss: 0.0714 - val_accuracy: 0.9854\n",
            "Epoch 264/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0365 - accuracy: 0.9882 - val_loss: 0.0854 - val_accuracy: 0.9792\n",
            "Epoch 265/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0398 - accuracy: 0.9867 - val_loss: 0.0708 - val_accuracy: 0.9854\n",
            "Epoch 266/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0359 - accuracy: 0.9892 - val_loss: 0.0731 - val_accuracy: 0.9854\n",
            "Epoch 267/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0368 - accuracy: 0.9882 - val_loss: 0.0801 - val_accuracy: 0.9823\n",
            "Epoch 268/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0381 - accuracy: 0.9874 - val_loss: 0.0772 - val_accuracy: 0.9838\n",
            "Epoch 269/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0376 - accuracy: 0.9867 - val_loss: 0.0770 - val_accuracy: 0.9831\n",
            "Epoch 270/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0378 - accuracy: 0.9872 - val_loss: 0.0820 - val_accuracy: 0.9808\n",
            "Epoch 271/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0394 - accuracy: 0.9872 - val_loss: 0.0707 - val_accuracy: 0.9862\n",
            "Epoch 272/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0355 - accuracy: 0.9879 - val_loss: 0.0724 - val_accuracy: 0.9854\n",
            "Epoch 273/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0361 - accuracy: 0.9882 - val_loss: 0.0765 - val_accuracy: 0.9846\n",
            "Epoch 274/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0364 - accuracy: 0.9892 - val_loss: 0.0721 - val_accuracy: 0.9854\n",
            "Epoch 275/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0365 - accuracy: 0.9879 - val_loss: 0.0740 - val_accuracy: 0.9854\n",
            "Epoch 276/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0391 - accuracy: 0.9869 - val_loss: 0.0740 - val_accuracy: 0.9862\n",
            "Epoch 277/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0379 - accuracy: 0.9874 - val_loss: 0.0712 - val_accuracy: 0.9846\n",
            "Epoch 278/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0367 - accuracy: 0.9887 - val_loss: 0.0724 - val_accuracy: 0.9854\n",
            "Epoch 279/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0362 - accuracy: 0.9869 - val_loss: 0.0826 - val_accuracy: 0.9815\n",
            "Epoch 280/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0385 - accuracy: 0.9864 - val_loss: 0.0821 - val_accuracy: 0.9815\n",
            "Epoch 281/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0394 - accuracy: 0.9872 - val_loss: 0.0715 - val_accuracy: 0.9854\n",
            "Epoch 282/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0367 - accuracy: 0.9861 - val_loss: 0.0721 - val_accuracy: 0.9862\n",
            "Epoch 283/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0349 - accuracy: 0.9890 - val_loss: 0.0821 - val_accuracy: 0.9808\n",
            "Epoch 284/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0367 - accuracy: 0.9887 - val_loss: 0.0718 - val_accuracy: 0.9862\n",
            "Epoch 285/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0380 - accuracy: 0.9861 - val_loss: 0.0712 - val_accuracy: 0.9854\n",
            "Epoch 286/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0366 - accuracy: 0.9882 - val_loss: 0.0717 - val_accuracy: 0.9846\n",
            "Epoch 287/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0368 - accuracy: 0.9874 - val_loss: 0.0754 - val_accuracy: 0.9862\n",
            "Epoch 288/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0358 - accuracy: 0.9882 - val_loss: 0.0774 - val_accuracy: 0.9854\n",
            "Epoch 289/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0355 - accuracy: 0.9872 - val_loss: 0.0716 - val_accuracy: 0.9846\n",
            "Epoch 290/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0376 - accuracy: 0.9872 - val_loss: 0.0727 - val_accuracy: 0.9846\n",
            "Epoch 291/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0393 - accuracy: 0.9867 - val_loss: 0.0724 - val_accuracy: 0.9854\n",
            "Epoch 292/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 0.0781 - val_accuracy: 0.9838\n",
            "Epoch 293/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0360 - accuracy: 0.9869 - val_loss: 0.0748 - val_accuracy: 0.9846\n",
            "Epoch 294/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0345 - accuracy: 0.9885 - val_loss: 0.0711 - val_accuracy: 0.9846\n",
            "Epoch 295/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0358 - accuracy: 0.9887 - val_loss: 0.0710 - val_accuracy: 0.9862\n",
            "Epoch 296/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0344 - accuracy: 0.9892 - val_loss: 0.0705 - val_accuracy: 0.9862\n",
            "Epoch 297/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0356 - accuracy: 0.9885 - val_loss: 0.0711 - val_accuracy: 0.9854\n",
            "Epoch 298/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0362 - accuracy: 0.9874 - val_loss: 0.0710 - val_accuracy: 0.9854\n",
            "Epoch 299/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0397 - accuracy: 0.9861 - val_loss: 0.0725 - val_accuracy: 0.9862\n",
            "Epoch 300/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 0.9895 - val_loss: 0.0767 - val_accuracy: 0.9838\n",
            "Epoch 301/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0368 - accuracy: 0.9874 - val_loss: 0.0858 - val_accuracy: 0.9792\n",
            "Epoch 302/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0358 - accuracy: 0.9890 - val_loss: 0.0711 - val_accuracy: 0.9838\n",
            "Epoch 303/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0370 - accuracy: 0.9867 - val_loss: 0.0721 - val_accuracy: 0.9846\n",
            "Epoch 304/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0386 - accuracy: 0.9874 - val_loss: 0.0713 - val_accuracy: 0.9862\n",
            "Epoch 305/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0422 - accuracy: 0.9856 - val_loss: 0.0720 - val_accuracy: 0.9854\n",
            "Epoch 306/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0366 - accuracy: 0.9885 - val_loss: 0.0737 - val_accuracy: 0.9854\n",
            "Epoch 307/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0361 - accuracy: 0.9879 - val_loss: 0.0788 - val_accuracy: 0.9846\n",
            "Epoch 308/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0343 - accuracy: 0.9885 - val_loss: 0.0722 - val_accuracy: 0.9862\n",
            "Epoch 309/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0347 - accuracy: 0.9879 - val_loss: 0.0703 - val_accuracy: 0.9854\n",
            "Epoch 310/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0377 - accuracy: 0.9877 - val_loss: 0.0745 - val_accuracy: 0.9846\n",
            "Epoch 311/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0428 - accuracy: 0.9867 - val_loss: 0.0739 - val_accuracy: 0.9854\n",
            "Epoch 312/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0406 - accuracy: 0.9867 - val_loss: 0.0874 - val_accuracy: 0.9792\n",
            "Epoch 313/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0398 - accuracy: 0.9874 - val_loss: 0.0881 - val_accuracy: 0.9792\n",
            "Epoch 314/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0366 - accuracy: 0.9885 - val_loss: 0.0719 - val_accuracy: 0.9862\n",
            "Epoch 315/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0343 - accuracy: 0.9887 - val_loss: 0.0763 - val_accuracy: 0.9846\n",
            "Epoch 316/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 0.0740 - val_accuracy: 0.9862\n",
            "Epoch 317/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0340 - accuracy: 0.9897 - val_loss: 0.0716 - val_accuracy: 0.9862\n",
            "Epoch 318/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0351 - accuracy: 0.9890 - val_loss: 0.0713 - val_accuracy: 0.9862\n",
            "Epoch 319/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0356 - accuracy: 0.9892 - val_loss: 0.0708 - val_accuracy: 0.9854\n",
            "Epoch 320/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0341 - accuracy: 0.9885 - val_loss: 0.0724 - val_accuracy: 0.9854\n",
            "Epoch 321/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0339 - accuracy: 0.9890 - val_loss: 0.0743 - val_accuracy: 0.9854\n",
            "Epoch 322/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0338 - accuracy: 0.9902 - val_loss: 0.0762 - val_accuracy: 0.9846\n",
            "Epoch 323/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0346 - accuracy: 0.9890 - val_loss: 0.0792 - val_accuracy: 0.9838\n",
            "Epoch 324/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0349 - accuracy: 0.9885 - val_loss: 0.0732 - val_accuracy: 0.9854\n",
            "Epoch 325/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0351 - accuracy: 0.9879 - val_loss: 0.0711 - val_accuracy: 0.9846\n",
            "Epoch 326/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0362 - accuracy: 0.9877 - val_loss: 0.0742 - val_accuracy: 0.9831\n",
            "Epoch 327/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0429 - accuracy: 0.9869 - val_loss: 0.0718 - val_accuracy: 0.9854\n",
            "Epoch 328/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0398 - accuracy: 0.9874 - val_loss: 0.0730 - val_accuracy: 0.9854\n",
            "Epoch 329/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0339 - accuracy: 0.9892 - val_loss: 0.0754 - val_accuracy: 0.9854\n",
            "Epoch 330/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0365 - accuracy: 0.9874 - val_loss: 0.0713 - val_accuracy: 0.9862\n",
            "Epoch 331/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0350 - accuracy: 0.9892 - val_loss: 0.0709 - val_accuracy: 0.9862\n",
            "Epoch 332/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0335 - accuracy: 0.9897 - val_loss: 0.0733 - val_accuracy: 0.9862\n",
            "Epoch 333/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 0.9892 - val_loss: 0.0723 - val_accuracy: 0.9869\n",
            "Epoch 334/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0334 - accuracy: 0.9900 - val_loss: 0.0710 - val_accuracy: 0.9854\n",
            "Epoch 335/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0361 - accuracy: 0.9885 - val_loss: 0.0713 - val_accuracy: 0.9846\n",
            "Epoch 336/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0344 - accuracy: 0.9897 - val_loss: 0.0755 - val_accuracy: 0.9854\n",
            "Epoch 337/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0328 - accuracy: 0.9892 - val_loss: 0.0729 - val_accuracy: 0.9869\n",
            "Epoch 338/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0332 - accuracy: 0.9900 - val_loss: 0.0749 - val_accuracy: 0.9854\n",
            "Epoch 339/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0336 - accuracy: 0.9892 - val_loss: 0.0743 - val_accuracy: 0.9854\n",
            "Epoch 340/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0328 - accuracy: 0.9900 - val_loss: 0.0703 - val_accuracy: 0.9862\n",
            "Epoch 341/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0338 - accuracy: 0.9892 - val_loss: 0.0714 - val_accuracy: 0.9869\n",
            "Epoch 342/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0330 - accuracy: 0.9900 - val_loss: 0.0711 - val_accuracy: 0.9869\n",
            "Epoch 343/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0329 - accuracy: 0.9897 - val_loss: 0.0702 - val_accuracy: 0.9854\n",
            "Epoch 344/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0347 - accuracy: 0.9887 - val_loss: 0.0710 - val_accuracy: 0.9854\n",
            "Epoch 345/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0336 - accuracy: 0.9895 - val_loss: 0.0864 - val_accuracy: 0.9808\n",
            "Epoch 346/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0358 - accuracy: 0.9890 - val_loss: 0.0765 - val_accuracy: 0.9846\n",
            "Epoch 347/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0354 - accuracy: 0.9879 - val_loss: 0.0707 - val_accuracy: 0.9862\n",
            "Epoch 348/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0345 - accuracy: 0.9895 - val_loss: 0.0697 - val_accuracy: 0.9854\n",
            "Epoch 349/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0338 - accuracy: 0.9900 - val_loss: 0.0705 - val_accuracy: 0.9854\n",
            "Epoch 350/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 0.9902 - val_loss: 0.0743 - val_accuracy: 0.9854\n",
            "Epoch 351/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0322 - accuracy: 0.9902 - val_loss: 0.0718 - val_accuracy: 0.9862\n",
            "Epoch 352/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0334 - accuracy: 0.9897 - val_loss: 0.0708 - val_accuracy: 0.9846\n",
            "Epoch 353/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0356 - accuracy: 0.9885 - val_loss: 0.0708 - val_accuracy: 0.9846\n",
            "Epoch 354/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0402 - accuracy: 0.9856 - val_loss: 0.0740 - val_accuracy: 0.9846\n",
            "Epoch 355/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0353 - accuracy: 0.9890 - val_loss: 0.0790 - val_accuracy: 0.9854\n",
            "Epoch 356/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.0788 - val_accuracy: 0.9846\n",
            "Epoch 357/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0337 - accuracy: 0.9890 - val_loss: 0.0763 - val_accuracy: 0.9838\n",
            "Epoch 358/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0330 - accuracy: 0.9897 - val_loss: 0.0715 - val_accuracy: 0.9854\n",
            "Epoch 359/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0323 - accuracy: 0.9908 - val_loss: 0.0730 - val_accuracy: 0.9854\n",
            "Epoch 360/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0326 - accuracy: 0.9895 - val_loss: 0.0723 - val_accuracy: 0.9862\n",
            "Epoch 361/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 0.0723 - val_accuracy: 0.9862\n",
            "Epoch 362/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0324 - accuracy: 0.9900 - val_loss: 0.0717 - val_accuracy: 0.9846\n",
            "Epoch 363/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0344 - accuracy: 0.9887 - val_loss: 0.0726 - val_accuracy: 0.9838\n",
            "Epoch 364/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0359 - accuracy: 0.9879 - val_loss: 0.0706 - val_accuracy: 0.9846\n",
            "Epoch 365/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0335 - accuracy: 0.9897 - val_loss: 0.0794 - val_accuracy: 0.9838\n",
            "Epoch 366/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0349 - accuracy: 0.9879 - val_loss: 0.0872 - val_accuracy: 0.9800\n",
            "Epoch 367/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0378 - accuracy: 0.9861 - val_loss: 0.0731 - val_accuracy: 0.9854\n",
            "Epoch 368/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0333 - accuracy: 0.9900 - val_loss: 0.0720 - val_accuracy: 0.9862\n",
            "Epoch 369/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0338 - accuracy: 0.9902 - val_loss: 0.0711 - val_accuracy: 0.9838\n",
            "Epoch 370/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0334 - accuracy: 0.9900 - val_loss: 0.0738 - val_accuracy: 0.9854\n",
            "Epoch 371/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0336 - accuracy: 0.9887 - val_loss: 0.0711 - val_accuracy: 0.9846\n",
            "Epoch 372/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0338 - accuracy: 0.9885 - val_loss: 0.0713 - val_accuracy: 0.9846\n",
            "Epoch 373/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0328 - accuracy: 0.9892 - val_loss: 0.0711 - val_accuracy: 0.9854\n",
            "Epoch 374/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0330 - accuracy: 0.9890 - val_loss: 0.0714 - val_accuracy: 0.9838\n",
            "Epoch 375/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0322 - accuracy: 0.9908 - val_loss: 0.0762 - val_accuracy: 0.9846\n",
            "Epoch 376/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0338 - accuracy: 0.9887 - val_loss: 0.0785 - val_accuracy: 0.9846\n",
            "Epoch 377/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0327 - accuracy: 0.9897 - val_loss: 0.0733 - val_accuracy: 0.9854\n",
            "Epoch 378/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 0.0790 - val_accuracy: 0.9831\n",
            "Epoch 379/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0363 - accuracy: 0.9887 - val_loss: 0.0718 - val_accuracy: 0.9838\n",
            "Epoch 380/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0347 - accuracy: 0.9879 - val_loss: 0.0726 - val_accuracy: 0.9854\n",
            "Epoch 381/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0368 - accuracy: 0.9872 - val_loss: 0.0758 - val_accuracy: 0.9846\n",
            "Epoch 382/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0329 - accuracy: 0.9902 - val_loss: 0.0855 - val_accuracy: 0.9815\n",
            "Epoch 383/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0356 - accuracy: 0.9882 - val_loss: 0.0748 - val_accuracy: 0.9854\n",
            "Epoch 384/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 0.9887 - val_loss: 0.0704 - val_accuracy: 0.9846\n",
            "Epoch 385/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 0.0709 - val_accuracy: 0.9854\n",
            "Epoch 386/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0339 - accuracy: 0.9885 - val_loss: 0.0753 - val_accuracy: 0.9846\n",
            "Epoch 387/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0321 - accuracy: 0.9897 - val_loss: 0.0761 - val_accuracy: 0.9846\n",
            "Epoch 388/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0327 - accuracy: 0.9900 - val_loss: 0.0791 - val_accuracy: 0.9838\n",
            "Epoch 389/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0340 - accuracy: 0.9877 - val_loss: 0.0742 - val_accuracy: 0.9854\n",
            "Epoch 390/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0337 - accuracy: 0.9882 - val_loss: 0.0760 - val_accuracy: 0.9846\n",
            "Epoch 391/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0347 - accuracy: 0.9887 - val_loss: 0.0724 - val_accuracy: 0.9862\n",
            "Epoch 392/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0321 - accuracy: 0.9902 - val_loss: 0.0727 - val_accuracy: 0.9862\n",
            "Epoch 393/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0326 - accuracy: 0.9892 - val_loss: 0.0716 - val_accuracy: 0.9838\n",
            "Epoch 394/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 0.0728 - val_accuracy: 0.9854\n",
            "Epoch 395/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0332 - accuracy: 0.9890 - val_loss: 0.0804 - val_accuracy: 0.9831\n",
            "Epoch 396/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0365 - accuracy: 0.9882 - val_loss: 0.0953 - val_accuracy: 0.9792\n",
            "Epoch 397/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0374 - accuracy: 0.9890 - val_loss: 0.0718 - val_accuracy: 0.9846\n",
            "Epoch 398/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0368 - accuracy: 0.9885 - val_loss: 0.0755 - val_accuracy: 0.9854\n",
            "Epoch 399/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0369 - accuracy: 0.9877 - val_loss: 0.0735 - val_accuracy: 0.9846\n",
            "Epoch 400/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0320 - accuracy: 0.9897 - val_loss: 0.0730 - val_accuracy: 0.9846\n",
            "Epoch 401/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0316 - accuracy: 0.9902 - val_loss: 0.0709 - val_accuracy: 0.9846\n",
            "Epoch 402/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0321 - accuracy: 0.9913 - val_loss: 0.0716 - val_accuracy: 0.9854\n",
            "Epoch 403/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 0.0714 - val_accuracy: 0.9854\n",
            "Epoch 404/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0321 - accuracy: 0.9910 - val_loss: 0.0698 - val_accuracy: 0.9846\n",
            "Epoch 405/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.0707 - val_accuracy: 0.9854\n",
            "Epoch 406/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 0.0759 - val_accuracy: 0.9846\n",
            "Epoch 407/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 0.9882 - val_loss: 0.0710 - val_accuracy: 0.9846\n",
            "Epoch 408/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0359 - accuracy: 0.9879 - val_loss: 0.0708 - val_accuracy: 0.9846\n",
            "Epoch 409/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 0.9897 - val_loss: 0.0743 - val_accuracy: 0.9854\n",
            "Epoch 410/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 0.0740 - val_accuracy: 0.9854\n",
            "Epoch 411/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0312 - accuracy: 0.9905 - val_loss: 0.0703 - val_accuracy: 0.9838\n",
            "Epoch 412/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0328 - accuracy: 0.9890 - val_loss: 0.0699 - val_accuracy: 0.9854\n",
            "Epoch 413/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0347 - accuracy: 0.9890 - val_loss: 0.0696 - val_accuracy: 0.9854\n",
            "Epoch 414/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0324 - accuracy: 0.9885 - val_loss: 0.0732 - val_accuracy: 0.9854\n",
            "Epoch 415/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0309 - accuracy: 0.9892 - val_loss: 0.0806 - val_accuracy: 0.9831\n",
            "Epoch 416/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0328 - accuracy: 0.9887 - val_loss: 0.0705 - val_accuracy: 0.9846\n",
            "Epoch 417/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0318 - accuracy: 0.9900 - val_loss: 0.0694 - val_accuracy: 0.9846\n",
            "Epoch 418/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0352 - accuracy: 0.9892 - val_loss: 0.0787 - val_accuracy: 0.9838\n",
            "Epoch 419/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.0819 - val_accuracy: 0.9831\n",
            "Epoch 420/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0345 - accuracy: 0.9887 - val_loss: 0.0756 - val_accuracy: 0.9846\n",
            "Epoch 421/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0342 - accuracy: 0.9890 - val_loss: 0.0698 - val_accuracy: 0.9846\n",
            "Epoch 422/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0356 - accuracy: 0.9895 - val_loss: 0.0751 - val_accuracy: 0.9854\n",
            "Epoch 423/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0374 - accuracy: 0.9874 - val_loss: 0.0721 - val_accuracy: 0.9862\n",
            "Epoch 424/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 0.0701 - val_accuracy: 0.9854\n",
            "Epoch 425/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0341 - accuracy: 0.9882 - val_loss: 0.0809 - val_accuracy: 0.9831\n",
            "Epoch 426/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0330 - accuracy: 0.9895 - val_loss: 0.0816 - val_accuracy: 0.9831\n",
            "Epoch 427/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0337 - accuracy: 0.9897 - val_loss: 0.0720 - val_accuracy: 0.9854\n",
            "Epoch 428/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0360 - accuracy: 0.9859 - val_loss: 0.0691 - val_accuracy: 0.9854\n",
            "Epoch 429/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0323 - accuracy: 0.9895 - val_loss: 0.0775 - val_accuracy: 0.9846\n",
            "Epoch 430/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0319 - accuracy: 0.9892 - val_loss: 0.0755 - val_accuracy: 0.9846\n",
            "Epoch 431/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 0.9895 - val_loss: 0.0764 - val_accuracy: 0.9838\n",
            "Epoch 432/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0330 - accuracy: 0.9879 - val_loss: 0.0705 - val_accuracy: 0.9854\n",
            "Epoch 433/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0332 - accuracy: 0.9885 - val_loss: 0.0693 - val_accuracy: 0.9846\n",
            "Epoch 434/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0318 - accuracy: 0.9890 - val_loss: 0.0707 - val_accuracy: 0.9862\n",
            "Epoch 435/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0301 - accuracy: 0.9910 - val_loss: 0.0691 - val_accuracy: 0.9854\n",
            "Epoch 436/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0307 - accuracy: 0.9892 - val_loss: 0.0693 - val_accuracy: 0.9854\n",
            "Epoch 437/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0304 - accuracy: 0.9908 - val_loss: 0.0725 - val_accuracy: 0.9854\n",
            "Epoch 438/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0310 - accuracy: 0.9890 - val_loss: 0.0694 - val_accuracy: 0.9854\n",
            "Epoch 439/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0300 - accuracy: 0.9905 - val_loss: 0.0716 - val_accuracy: 0.9854\n",
            "Epoch 440/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0307 - accuracy: 0.9895 - val_loss: 0.0761 - val_accuracy: 0.9846\n",
            "Epoch 441/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0319 - accuracy: 0.9895 - val_loss: 0.0714 - val_accuracy: 0.9862\n",
            "Epoch 442/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0308 - accuracy: 0.9887 - val_loss: 0.0688 - val_accuracy: 0.9838\n",
            "Epoch 443/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0320 - accuracy: 0.9902 - val_loss: 0.0728 - val_accuracy: 0.9862\n",
            "Epoch 444/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0333 - accuracy: 0.9900 - val_loss: 0.0864 - val_accuracy: 0.9831\n",
            "Epoch 445/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0357 - accuracy: 0.9877 - val_loss: 0.0866 - val_accuracy: 0.9831\n",
            "Epoch 446/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 0.0747 - val_accuracy: 0.9854\n",
            "Epoch 447/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0356 - accuracy: 0.9877 - val_loss: 0.0691 - val_accuracy: 0.9854\n",
            "Epoch 448/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0311 - accuracy: 0.9900 - val_loss: 0.0774 - val_accuracy: 0.9854\n",
            "Epoch 449/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0320 - accuracy: 0.9892 - val_loss: 0.0699 - val_accuracy: 0.9854\n",
            "Epoch 450/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0297 - accuracy: 0.9902 - val_loss: 0.0756 - val_accuracy: 0.9846\n",
            "Epoch 451/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0311 - accuracy: 0.9902 - val_loss: 0.0730 - val_accuracy: 0.9862\n",
            "Epoch 452/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0317 - accuracy: 0.9900 - val_loss: 0.0761 - val_accuracy: 0.9846\n",
            "Epoch 453/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0313 - accuracy: 0.9887 - val_loss: 0.0714 - val_accuracy: 0.9854\n",
            "Epoch 454/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0309 - accuracy: 0.9895 - val_loss: 0.0684 - val_accuracy: 0.9846\n",
            "Epoch 455/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0305 - accuracy: 0.9900 - val_loss: 0.0702 - val_accuracy: 0.9862\n",
            "Epoch 456/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0297 - accuracy: 0.9910 - val_loss: 0.0696 - val_accuracy: 0.9862\n",
            "Epoch 457/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0295 - accuracy: 0.9910 - val_loss: 0.0741 - val_accuracy: 0.9862\n",
            "Epoch 458/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0322 - accuracy: 0.9897 - val_loss: 0.0802 - val_accuracy: 0.9831\n",
            "Epoch 459/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 0.0693 - val_accuracy: 0.9838\n",
            "Epoch 460/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0304 - accuracy: 0.9897 - val_loss: 0.0721 - val_accuracy: 0.9862\n",
            "Epoch 461/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0298 - accuracy: 0.9905 - val_loss: 0.0684 - val_accuracy: 0.9854\n",
            "Epoch 462/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.0690 - val_accuracy: 0.9838\n",
            "Epoch 463/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0307 - accuracy: 0.9902 - val_loss: 0.0698 - val_accuracy: 0.9838\n",
            "Epoch 464/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0301 - accuracy: 0.9900 - val_loss: 0.0728 - val_accuracy: 0.9862\n",
            "Epoch 465/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0293 - accuracy: 0.9910 - val_loss: 0.0696 - val_accuracy: 0.9838\n",
            "Epoch 466/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0306 - accuracy: 0.9897 - val_loss: 0.0688 - val_accuracy: 0.9846\n",
            "Epoch 467/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0310 - accuracy: 0.9887 - val_loss: 0.0773 - val_accuracy: 0.9846\n",
            "Epoch 468/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0325 - accuracy: 0.9908 - val_loss: 0.0842 - val_accuracy: 0.9831\n",
            "Epoch 469/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0320 - accuracy: 0.9885 - val_loss: 0.0704 - val_accuracy: 0.9854\n",
            "Epoch 470/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0334 - accuracy: 0.9892 - val_loss: 0.0714 - val_accuracy: 0.9854\n",
            "Epoch 471/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0329 - accuracy: 0.9895 - val_loss: 0.0712 - val_accuracy: 0.9854\n",
            "Epoch 472/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0345 - accuracy: 0.9887 - val_loss: 0.0827 - val_accuracy: 0.9838\n",
            "Epoch 473/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0313 - accuracy: 0.9897 - val_loss: 0.0749 - val_accuracy: 0.9846\n",
            "Epoch 474/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0304 - accuracy: 0.9900 - val_loss: 0.0710 - val_accuracy: 0.9854\n",
            "Epoch 475/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 0.0720 - val_accuracy: 0.9862\n",
            "Epoch 476/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.0820 - val_accuracy: 0.9838\n",
            "Epoch 477/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0326 - accuracy: 0.9895 - val_loss: 0.0800 - val_accuracy: 0.9838\n",
            "Epoch 478/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0328 - accuracy: 0.9879 - val_loss: 0.0694 - val_accuracy: 0.9846\n",
            "Epoch 479/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0304 - accuracy: 0.9882 - val_loss: 0.0710 - val_accuracy: 0.9846\n",
            "Epoch 480/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0722 - val_accuracy: 0.9862\n",
            "Epoch 481/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0293 - accuracy: 0.9905 - val_loss: 0.0728 - val_accuracy: 0.9854\n",
            "Epoch 482/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0313 - accuracy: 0.9902 - val_loss: 0.0716 - val_accuracy: 0.9862\n",
            "Epoch 483/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0305 - accuracy: 0.9900 - val_loss: 0.0754 - val_accuracy: 0.9846\n",
            "Epoch 484/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0306 - accuracy: 0.9900 - val_loss: 0.0740 - val_accuracy: 0.9846\n",
            "Epoch 485/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0298 - accuracy: 0.9908 - val_loss: 0.0725 - val_accuracy: 0.9854\n",
            "Epoch 486/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0310 - accuracy: 0.9887 - val_loss: 0.0696 - val_accuracy: 0.9862\n",
            "Epoch 487/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0309 - accuracy: 0.9908 - val_loss: 0.0703 - val_accuracy: 0.9854\n",
            "Epoch 488/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0309 - accuracy: 0.9895 - val_loss: 0.0740 - val_accuracy: 0.9846\n",
            "Epoch 489/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0302 - accuracy: 0.9897 - val_loss: 0.0807 - val_accuracy: 0.9838\n",
            "Epoch 490/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0325 - accuracy: 0.9892 - val_loss: 0.0709 - val_accuracy: 0.9862\n",
            "Epoch 491/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0322 - accuracy: 0.9892 - val_loss: 0.0737 - val_accuracy: 0.9862\n",
            "Epoch 492/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0335 - accuracy: 0.9879 - val_loss: 0.0746 - val_accuracy: 0.9854\n",
            "Epoch 493/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0317 - accuracy: 0.9897 - val_loss: 0.0828 - val_accuracy: 0.9838\n",
            "Epoch 494/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0312 - accuracy: 0.9882 - val_loss: 0.0744 - val_accuracy: 0.9854\n",
            "Epoch 495/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0304 - accuracy: 0.9897 - val_loss: 0.0700 - val_accuracy: 0.9846\n",
            "Epoch 496/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0309 - accuracy: 0.9892 - val_loss: 0.0707 - val_accuracy: 0.9854\n",
            "Epoch 497/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0326 - accuracy: 0.9892 - val_loss: 0.0769 - val_accuracy: 0.9838\n",
            "Epoch 498/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0293 - accuracy: 0.9895 - val_loss: 0.0713 - val_accuracy: 0.9854\n",
            "Epoch 499/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0303 - accuracy: 0.9900 - val_loss: 0.0703 - val_accuracy: 0.9846\n",
            "Epoch 500/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0294 - accuracy: 0.9902 - val_loss: 0.0712 - val_accuracy: 0.9854\n",
            "Epoch 501/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0298 - accuracy: 0.9902 - val_loss: 0.0711 - val_accuracy: 0.9846\n",
            "Epoch 502/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0296 - accuracy: 0.9895 - val_loss: 0.0704 - val_accuracy: 0.9846\n",
            "Epoch 503/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 0.0730 - val_accuracy: 0.9854\n",
            "Epoch 504/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0290 - accuracy: 0.9897 - val_loss: 0.0772 - val_accuracy: 0.9846\n",
            "Epoch 505/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0301 - accuracy: 0.9910 - val_loss: 0.0726 - val_accuracy: 0.9854\n",
            "Epoch 506/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0302 - accuracy: 0.9900 - val_loss: 0.0696 - val_accuracy: 0.9838\n",
            "Epoch 507/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0293 - accuracy: 0.9910 - val_loss: 0.0706 - val_accuracy: 0.9854\n",
            "Epoch 508/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0293 - accuracy: 0.9905 - val_loss: 0.0698 - val_accuracy: 0.9854\n",
            "Epoch 509/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0293 - accuracy: 0.9908 - val_loss: 0.0719 - val_accuracy: 0.9854\n",
            "Epoch 510/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0293 - accuracy: 0.9905 - val_loss: 0.0925 - val_accuracy: 0.9815\n",
            "Epoch 511/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0350 - accuracy: 0.9887 - val_loss: 0.0755 - val_accuracy: 0.9846\n",
            "Epoch 512/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0310 - accuracy: 0.9892 - val_loss: 0.0706 - val_accuracy: 0.9862\n",
            "Epoch 513/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0319 - accuracy: 0.9902 - val_loss: 0.0711 - val_accuracy: 0.9846\n",
            "Epoch 514/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0295 - accuracy: 0.9897 - val_loss: 0.0712 - val_accuracy: 0.9838\n",
            "Epoch 515/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0286 - accuracy: 0.9913 - val_loss: 0.0727 - val_accuracy: 0.9854\n",
            "Epoch 516/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 0.0758 - val_accuracy: 0.9846\n",
            "Epoch 517/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0304 - accuracy: 0.9915 - val_loss: 0.0703 - val_accuracy: 0.9854\n",
            "Epoch 518/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 0.9892 - val_loss: 0.0719 - val_accuracy: 0.9862\n",
            "Epoch 519/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0342 - accuracy: 0.9882 - val_loss: 0.0718 - val_accuracy: 0.9854\n",
            "Epoch 520/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0336 - accuracy: 0.9892 - val_loss: 0.0871 - val_accuracy: 0.9846\n",
            "Epoch 521/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0320 - accuracy: 0.9890 - val_loss: 0.0754 - val_accuracy: 0.9846\n",
            "Epoch 522/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0290 - accuracy: 0.9905 - val_loss: 0.0702 - val_accuracy: 0.9831\n",
            "Epoch 523/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0292 - accuracy: 0.9902 - val_loss: 0.0706 - val_accuracy: 0.9846\n",
            "Epoch 524/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0285 - accuracy: 0.9905 - val_loss: 0.0817 - val_accuracy: 0.9846\n",
            "Epoch 525/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0310 - accuracy: 0.9892 - val_loss: 0.0752 - val_accuracy: 0.9846\n",
            "Epoch 526/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 0.0779 - val_accuracy: 0.9831\n",
            "Epoch 527/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0285 - accuracy: 0.9910 - val_loss: 0.0700 - val_accuracy: 0.9846\n",
            "Epoch 528/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0292 - accuracy: 0.9887 - val_loss: 0.0708 - val_accuracy: 0.9846\n",
            "Epoch 529/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0299 - accuracy: 0.9895 - val_loss: 0.0813 - val_accuracy: 0.9846\n",
            "Epoch 530/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0297 - accuracy: 0.9895 - val_loss: 0.0727 - val_accuracy: 0.9854\n",
            "Epoch 531/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0278 - accuracy: 0.9910 - val_loss: 0.0738 - val_accuracy: 0.9854\n",
            "Epoch 532/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0281 - accuracy: 0.9902 - val_loss: 0.0704 - val_accuracy: 0.9846\n",
            "Epoch 533/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0308 - accuracy: 0.9900 - val_loss: 0.0701 - val_accuracy: 0.9846\n",
            "Epoch 534/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0310 - accuracy: 0.9879 - val_loss: 0.0705 - val_accuracy: 0.9854\n",
            "Epoch 535/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.0726 - val_accuracy: 0.9854\n",
            "Epoch 536/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0291 - accuracy: 0.9902 - val_loss: 0.0856 - val_accuracy: 0.9846\n",
            "Epoch 537/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0280 - accuracy: 0.9905 - val_loss: 0.0721 - val_accuracy: 0.9854\n",
            "Epoch 538/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 0.0724 - val_accuracy: 0.9854\n",
            "Epoch 539/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0277 - accuracy: 0.9913 - val_loss: 0.0748 - val_accuracy: 0.9846\n",
            "Epoch 540/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0289 - accuracy: 0.9902 - val_loss: 0.0809 - val_accuracy: 0.9831\n",
            "Epoch 541/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0711 - val_accuracy: 0.9846\n",
            "Epoch 542/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0278 - accuracy: 0.9905 - val_loss: 0.0729 - val_accuracy: 0.9854\n",
            "Epoch 543/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0276 - accuracy: 0.9923 - val_loss: 0.0770 - val_accuracy: 0.9846\n",
            "Epoch 544/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0283 - accuracy: 0.9918 - val_loss: 0.0738 - val_accuracy: 0.9846\n",
            "Epoch 545/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0276 - accuracy: 0.9918 - val_loss: 0.0729 - val_accuracy: 0.9846\n",
            "Epoch 546/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0276 - accuracy: 0.9905 - val_loss: 0.0877 - val_accuracy: 0.9846\n",
            "Epoch 547/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0327 - accuracy: 0.9897 - val_loss: 0.0865 - val_accuracy: 0.9846\n",
            "Epoch 548/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 0.0775 - val_accuracy: 0.9846\n",
            "Epoch 549/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0330 - accuracy: 0.9897 - val_loss: 0.0779 - val_accuracy: 0.9854\n",
            "Epoch 550/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0355 - accuracy: 0.9877 - val_loss: 0.0720 - val_accuracy: 0.9854\n",
            "Epoch 551/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0314 - accuracy: 0.9892 - val_loss: 0.0827 - val_accuracy: 0.9838\n",
            "Epoch 552/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0296 - accuracy: 0.9902 - val_loss: 0.0767 - val_accuracy: 0.9854\n",
            "Epoch 553/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0276 - accuracy: 0.9908 - val_loss: 0.0717 - val_accuracy: 0.9846\n",
            "Epoch 554/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.0727 - val_accuracy: 0.9854\n",
            "Epoch 555/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 0.0720 - val_accuracy: 0.9854\n",
            "Epoch 556/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0287 - accuracy: 0.9913 - val_loss: 0.0724 - val_accuracy: 0.9854\n",
            "Epoch 557/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0310 - accuracy: 0.9890 - val_loss: 0.0724 - val_accuracy: 0.9846\n",
            "Epoch 558/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0301 - accuracy: 0.9902 - val_loss: 0.0743 - val_accuracy: 0.9854\n",
            "Epoch 559/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0271 - accuracy: 0.9915 - val_loss: 0.0734 - val_accuracy: 0.9854\n",
            "Epoch 560/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0274 - accuracy: 0.9910 - val_loss: 0.0815 - val_accuracy: 0.9831\n",
            "Epoch 561/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0288 - accuracy: 0.9910 - val_loss: 0.0725 - val_accuracy: 0.9862\n",
            "Epoch 562/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0281 - accuracy: 0.9900 - val_loss: 0.0748 - val_accuracy: 0.9854\n",
            "Epoch 563/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0274 - accuracy: 0.9905 - val_loss: 0.0765 - val_accuracy: 0.9854\n",
            "Epoch 564/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0277 - accuracy: 0.9905 - val_loss: 0.0775 - val_accuracy: 0.9854\n",
            "Epoch 565/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0301 - accuracy: 0.9895 - val_loss: 0.0771 - val_accuracy: 0.9854\n",
            "Epoch 566/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0311 - accuracy: 0.9885 - val_loss: 0.0723 - val_accuracy: 0.9846\n",
            "Epoch 567/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0283 - accuracy: 0.9908 - val_loss: 0.0760 - val_accuracy: 0.9846\n",
            "Epoch 568/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.0782 - val_accuracy: 0.9846\n",
            "Epoch 569/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0289 - accuracy: 0.9897 - val_loss: 0.0753 - val_accuracy: 0.9854\n",
            "Epoch 570/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0287 - accuracy: 0.9900 - val_loss: 0.0735 - val_accuracy: 0.9846\n",
            "Epoch 571/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0291 - accuracy: 0.9902 - val_loss: 0.0733 - val_accuracy: 0.9862\n",
            "Epoch 572/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0315 - accuracy: 0.9895 - val_loss: 0.0737 - val_accuracy: 0.9854\n",
            "Epoch 573/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0284 - accuracy: 0.9895 - val_loss: 0.0848 - val_accuracy: 0.9846\n",
            "Epoch 574/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0282 - accuracy: 0.9908 - val_loss: 0.0765 - val_accuracy: 0.9854\n",
            "Epoch 575/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 0.0734 - val_accuracy: 0.9846\n",
            "Epoch 576/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0276 - accuracy: 0.9900 - val_loss: 0.0729 - val_accuracy: 0.9846\n",
            "Epoch 577/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0271 - accuracy: 0.9920 - val_loss: 0.0880 - val_accuracy: 0.9838\n",
            "Epoch 578/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0322 - accuracy: 0.9892 - val_loss: 0.0798 - val_accuracy: 0.9854\n",
            "Epoch 579/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0311 - accuracy: 0.9892 - val_loss: 0.0766 - val_accuracy: 0.9854\n",
            "Epoch 580/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0283 - accuracy: 0.9913 - val_loss: 0.0728 - val_accuracy: 0.9854\n",
            "Epoch 581/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0268 - accuracy: 0.9918 - val_loss: 0.0816 - val_accuracy: 0.9854\n",
            "Epoch 582/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0272 - accuracy: 0.9900 - val_loss: 0.0747 - val_accuracy: 0.9846\n",
            "Epoch 583/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0275 - accuracy: 0.9908 - val_loss: 0.0743 - val_accuracy: 0.9854\n",
            "Epoch 584/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0292 - accuracy: 0.9913 - val_loss: 0.0798 - val_accuracy: 0.9854\n",
            "Epoch 585/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0272 - accuracy: 0.9928 - val_loss: 0.0805 - val_accuracy: 0.9862\n",
            "Epoch 586/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0279 - accuracy: 0.9918 - val_loss: 0.0746 - val_accuracy: 0.9838\n",
            "Epoch 587/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0282 - accuracy: 0.9908 - val_loss: 0.0733 - val_accuracy: 0.9854\n",
            "Epoch 588/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0289 - accuracy: 0.9910 - val_loss: 0.0759 - val_accuracy: 0.9846\n",
            "Epoch 589/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0279 - accuracy: 0.9915 - val_loss: 0.0767 - val_accuracy: 0.9854\n",
            "Epoch 590/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0306 - accuracy: 0.9905 - val_loss: 0.0950 - val_accuracy: 0.9838\n",
            "Epoch 591/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0316 - accuracy: 0.9892 - val_loss: 0.0807 - val_accuracy: 0.9862\n",
            "Epoch 592/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0279 - accuracy: 0.9920 - val_loss: 0.0754 - val_accuracy: 0.9846\n",
            "Epoch 593/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0282 - accuracy: 0.9905 - val_loss: 0.0736 - val_accuracy: 0.9862\n",
            "Epoch 594/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0269 - accuracy: 0.9913 - val_loss: 0.0843 - val_accuracy: 0.9838\n",
            "Epoch 595/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0295 - accuracy: 0.9913 - val_loss: 0.0817 - val_accuracy: 0.9854\n",
            "Epoch 596/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0308 - accuracy: 0.9902 - val_loss: 0.0736 - val_accuracy: 0.9869\n",
            "Epoch 597/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.0741 - val_accuracy: 0.9862\n",
            "Epoch 598/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 0.9920 - val_loss: 0.0815 - val_accuracy: 0.9854\n",
            "Epoch 599/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0289 - accuracy: 0.9908 - val_loss: 0.0794 - val_accuracy: 0.9862\n",
            "Epoch 600/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 0.9913 - val_loss: 0.0723 - val_accuracy: 0.9862\n",
            "Epoch 601/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0287 - accuracy: 0.9905 - val_loss: 0.0727 - val_accuracy: 0.9862\n",
            "Epoch 602/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0290 - accuracy: 0.9908 - val_loss: 0.0810 - val_accuracy: 0.9854\n",
            "Epoch 603/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0266 - accuracy: 0.9908 - val_loss: 0.0767 - val_accuracy: 0.9862\n",
            "Epoch 604/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0268 - accuracy: 0.9908 - val_loss: 0.0732 - val_accuracy: 0.9862\n",
            "Epoch 605/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0262 - accuracy: 0.9920 - val_loss: 0.0762 - val_accuracy: 0.9854\n",
            "Epoch 606/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 0.0736 - val_accuracy: 0.9877\n",
            "Epoch 607/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.0723 - val_accuracy: 0.9862\n",
            "Epoch 608/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0267 - accuracy: 0.9905 - val_loss: 0.0752 - val_accuracy: 0.9869\n",
            "Epoch 609/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0255 - accuracy: 0.9913 - val_loss: 0.0725 - val_accuracy: 0.9869\n",
            "Epoch 610/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0267 - accuracy: 0.9908 - val_loss: 0.0800 - val_accuracy: 0.9862\n",
            "Epoch 611/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0263 - accuracy: 0.9902 - val_loss: 0.0787 - val_accuracy: 0.9862\n",
            "Epoch 612/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0265 - accuracy: 0.9910 - val_loss: 0.0731 - val_accuracy: 0.9869\n",
            "Epoch 613/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0269 - accuracy: 0.9900 - val_loss: 0.0723 - val_accuracy: 0.9862\n",
            "Epoch 614/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0255 - accuracy: 0.9926 - val_loss: 0.0755 - val_accuracy: 0.9862\n",
            "Epoch 615/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.0734 - val_accuracy: 0.9877\n",
            "Epoch 616/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9920 - val_loss: 0.0722 - val_accuracy: 0.9869\n",
            "Epoch 617/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0267 - accuracy: 0.9910 - val_loss: 0.0744 - val_accuracy: 0.9862\n",
            "Epoch 618/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0263 - accuracy: 0.9910 - val_loss: 0.0750 - val_accuracy: 0.9869\n",
            "Epoch 619/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0252 - accuracy: 0.9918 - val_loss: 0.0723 - val_accuracy: 0.9869\n",
            "Epoch 620/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0250 - accuracy: 0.9926 - val_loss: 0.0770 - val_accuracy: 0.9862\n",
            "Epoch 621/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.0748 - val_accuracy: 0.9869\n",
            "Epoch 622/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0257 - accuracy: 0.9920 - val_loss: 0.0733 - val_accuracy: 0.9877\n",
            "Epoch 623/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0253 - accuracy: 0.9928 - val_loss: 0.0744 - val_accuracy: 0.9869\n",
            "Epoch 624/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.0767 - val_accuracy: 0.9862\n",
            "Epoch 625/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0253 - accuracy: 0.9923 - val_loss: 0.0749 - val_accuracy: 0.9862\n",
            "Epoch 626/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9926 - val_loss: 0.0773 - val_accuracy: 0.9862\n",
            "Epoch 627/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0257 - accuracy: 0.9913 - val_loss: 0.0788 - val_accuracy: 0.9862\n",
            "Epoch 628/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.0760 - val_accuracy: 0.9869\n",
            "Epoch 629/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0248 - accuracy: 0.9931 - val_loss: 0.0741 - val_accuracy: 0.9877\n",
            "Epoch 630/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0251 - accuracy: 0.9923 - val_loss: 0.0737 - val_accuracy: 0.9877\n",
            "Epoch 631/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0256 - accuracy: 0.9920 - val_loss: 0.0729 - val_accuracy: 0.9877\n",
            "Epoch 632/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0275 - accuracy: 0.9897 - val_loss: 0.0768 - val_accuracy: 0.9862\n",
            "Epoch 633/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0260 - accuracy: 0.9926 - val_loss: 0.0777 - val_accuracy: 0.9862\n",
            "Epoch 634/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0267 - accuracy: 0.9913 - val_loss: 0.0816 - val_accuracy: 0.9854\n",
            "Epoch 635/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0303 - accuracy: 0.9897 - val_loss: 0.0729 - val_accuracy: 0.9854\n",
            "Epoch 636/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0287 - accuracy: 0.9895 - val_loss: 0.0741 - val_accuracy: 0.9854\n",
            "Epoch 637/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0288 - accuracy: 0.9897 - val_loss: 0.0829 - val_accuracy: 0.9854\n",
            "Epoch 638/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0258 - accuracy: 0.9920 - val_loss: 0.0794 - val_accuracy: 0.9862\n",
            "Epoch 639/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.0721 - val_accuracy: 0.9877\n",
            "Epoch 640/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0272 - accuracy: 0.9900 - val_loss: 0.0804 - val_accuracy: 0.9862\n",
            "Epoch 641/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0277 - accuracy: 0.9902 - val_loss: 0.0960 - val_accuracy: 0.9831\n",
            "Epoch 642/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0312 - accuracy: 0.9892 - val_loss: 0.0778 - val_accuracy: 0.9877\n",
            "Epoch 643/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 0.0750 - val_accuracy: 0.9854\n",
            "Epoch 644/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0293 - accuracy: 0.9908 - val_loss: 0.0859 - val_accuracy: 0.9846\n",
            "Epoch 645/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0265 - accuracy: 0.9902 - val_loss: 0.0771 - val_accuracy: 0.9862\n",
            "Epoch 646/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 0.9915 - val_loss: 0.0742 - val_accuracy: 0.9885\n",
            "Epoch 647/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0256 - accuracy: 0.9918 - val_loss: 0.0757 - val_accuracy: 0.9877\n",
            "Epoch 648/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0246 - accuracy: 0.9928 - val_loss: 0.0746 - val_accuracy: 0.9877\n",
            "Epoch 649/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0263 - accuracy: 0.9913 - val_loss: 0.0765 - val_accuracy: 0.9869\n",
            "Epoch 650/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9915 - val_loss: 0.0783 - val_accuracy: 0.9862\n",
            "Epoch 651/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 0.0777 - val_accuracy: 0.9862\n",
            "Epoch 652/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0246 - accuracy: 0.9928 - val_loss: 0.0766 - val_accuracy: 0.9862\n",
            "Epoch 653/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 0.0780 - val_accuracy: 0.9862\n",
            "Epoch 654/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0247 - accuracy: 0.9928 - val_loss: 0.0810 - val_accuracy: 0.9862\n",
            "Epoch 655/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0261 - accuracy: 0.9913 - val_loss: 0.0779 - val_accuracy: 0.9869\n",
            "Epoch 656/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0275 - accuracy: 0.9908 - val_loss: 0.0730 - val_accuracy: 0.9877\n",
            "Epoch 657/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0285 - accuracy: 0.9890 - val_loss: 0.0731 - val_accuracy: 0.9869\n",
            "Epoch 658/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0272 - accuracy: 0.9923 - val_loss: 0.0775 - val_accuracy: 0.9862\n",
            "Epoch 659/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0264 - accuracy: 0.9908 - val_loss: 0.0794 - val_accuracy: 0.9862\n",
            "Epoch 660/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0250 - accuracy: 0.9926 - val_loss: 0.0831 - val_accuracy: 0.9846\n",
            "Epoch 661/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 0.0757 - val_accuracy: 0.9877\n",
            "Epoch 662/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.0825 - val_accuracy: 0.9854\n",
            "Epoch 663/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0249 - accuracy: 0.9923 - val_loss: 0.0764 - val_accuracy: 0.9877\n",
            "Epoch 664/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0244 - accuracy: 0.9926 - val_loss: 0.0771 - val_accuracy: 0.9877\n",
            "Epoch 665/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0250 - accuracy: 0.9910 - val_loss: 0.0735 - val_accuracy: 0.9885\n",
            "Epoch 666/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0249 - accuracy: 0.9918 - val_loss: 0.0756 - val_accuracy: 0.9877\n",
            "Epoch 667/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0253 - accuracy: 0.9926 - val_loss: 0.0754 - val_accuracy: 0.9869\n",
            "Epoch 668/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 0.9910 - val_loss: 0.0743 - val_accuracy: 0.9877\n",
            "Epoch 669/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0749 - val_accuracy: 0.9885\n",
            "Epoch 670/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0250 - accuracy: 0.9908 - val_loss: 0.0793 - val_accuracy: 0.9862\n",
            "Epoch 671/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 0.0758 - val_accuracy: 0.9877\n",
            "Epoch 672/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0244 - accuracy: 0.9926 - val_loss: 0.0845 - val_accuracy: 0.9846\n",
            "Epoch 673/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0284 - accuracy: 0.9913 - val_loss: 0.0980 - val_accuracy: 0.9831\n",
            "Epoch 674/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0372 - accuracy: 0.9877 - val_loss: 0.0806 - val_accuracy: 0.9854\n",
            "Epoch 675/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0320 - accuracy: 0.9897 - val_loss: 0.0754 - val_accuracy: 0.9854\n",
            "Epoch 676/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.0779 - val_accuracy: 0.9877\n",
            "Epoch 677/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 0.0829 - val_accuracy: 0.9846\n",
            "Epoch 678/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 0.0786 - val_accuracy: 0.9862\n",
            "Epoch 679/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 0.0819 - val_accuracy: 0.9862\n",
            "Epoch 680/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0256 - accuracy: 0.9913 - val_loss: 0.0809 - val_accuracy: 0.9862\n",
            "Epoch 681/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.0777 - val_accuracy: 0.9877\n",
            "Epoch 682/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0247 - accuracy: 0.9926 - val_loss: 0.0780 - val_accuracy: 0.9862\n",
            "Epoch 683/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.0745 - val_accuracy: 0.9877\n",
            "Epoch 684/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0256 - accuracy: 0.9905 - val_loss: 0.0753 - val_accuracy: 0.9885\n",
            "Epoch 685/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0250 - accuracy: 0.9918 - val_loss: 0.0743 - val_accuracy: 0.9877\n",
            "Epoch 686/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9915 - val_loss: 0.0793 - val_accuracy: 0.9862\n",
            "Epoch 687/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 0.0809 - val_accuracy: 0.9862\n",
            "Epoch 688/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9915 - val_loss: 0.0811 - val_accuracy: 0.9862\n",
            "Epoch 689/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.0792 - val_accuracy: 0.9862\n",
            "Epoch 690/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 0.0755 - val_accuracy: 0.9877\n",
            "Epoch 691/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 0.0777 - val_accuracy: 0.9869\n",
            "Epoch 692/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.9923 - val_loss: 0.0778 - val_accuracy: 0.9862\n",
            "Epoch 693/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0785 - val_accuracy: 0.9869\n",
            "Epoch 694/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 0.0770 - val_accuracy: 0.9869\n",
            "Epoch 695/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 0.0794 - val_accuracy: 0.9862\n",
            "Epoch 696/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 0.0768 - val_accuracy: 0.9877\n",
            "Epoch 697/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0246 - accuracy: 0.9928 - val_loss: 0.0758 - val_accuracy: 0.9885\n",
            "Epoch 698/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0256 - accuracy: 0.9897 - val_loss: 0.0752 - val_accuracy: 0.9877\n",
            "Epoch 699/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.0771 - val_accuracy: 0.9869\n",
            "Epoch 700/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 0.0799 - val_accuracy: 0.9862\n",
            "Epoch 701/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 0.0809 - val_accuracy: 0.9862\n",
            "Epoch 702/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.0816 - val_accuracy: 0.9862\n",
            "Epoch 703/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9938 - val_loss: 0.0770 - val_accuracy: 0.9885\n",
            "Epoch 704/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.0763 - val_accuracy: 0.9885\n",
            "Epoch 705/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9928 - val_loss: 0.0758 - val_accuracy: 0.9877\n",
            "Epoch 706/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0736 - val_accuracy: 0.9877\n",
            "Epoch 707/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0250 - accuracy: 0.9910 - val_loss: 0.0865 - val_accuracy: 0.9838\n",
            "Epoch 708/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0252 - accuracy: 0.9908 - val_loss: 0.0770 - val_accuracy: 0.9877\n",
            "Epoch 709/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 0.0749 - val_accuracy: 0.9885\n",
            "Epoch 710/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.0772 - val_accuracy: 0.9869\n",
            "Epoch 711/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.0821 - val_accuracy: 0.9862\n",
            "Epoch 712/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 0.0773 - val_accuracy: 0.9877\n",
            "Epoch 713/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.0742 - val_accuracy: 0.9885\n",
            "Epoch 714/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 0.0810 - val_accuracy: 0.9869\n",
            "Epoch 715/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 0.0774 - val_accuracy: 0.9869\n",
            "Epoch 716/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0234 - accuracy: 0.9931 - val_loss: 0.0795 - val_accuracy: 0.9862\n",
            "Epoch 717/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.0811 - val_accuracy: 0.9862\n",
            "Epoch 718/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 0.0775 - val_accuracy: 0.9877\n",
            "Epoch 719/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.0831 - val_accuracy: 0.9846\n",
            "Epoch 720/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9910 - val_loss: 0.0780 - val_accuracy: 0.9869\n",
            "Epoch 721/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0269 - accuracy: 0.9905 - val_loss: 0.0775 - val_accuracy: 0.9877\n",
            "Epoch 722/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0241 - accuracy: 0.9918 - val_loss: 0.0745 - val_accuracy: 0.9877\n",
            "Epoch 723/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9910 - val_loss: 0.0760 - val_accuracy: 0.9877\n",
            "Epoch 724/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0240 - accuracy: 0.9908 - val_loss: 0.0809 - val_accuracy: 0.9862\n",
            "Epoch 725/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0772 - val_accuracy: 0.9877\n",
            "Epoch 726/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9931 - val_loss: 0.0780 - val_accuracy: 0.9877\n",
            "Epoch 727/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 0.0816 - val_accuracy: 0.9862\n",
            "Epoch 728/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0235 - accuracy: 0.9936 - val_loss: 0.0784 - val_accuracy: 0.9885\n",
            "Epoch 729/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.0746 - val_accuracy: 0.9885\n",
            "Epoch 730/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.0783 - val_accuracy: 0.9877\n",
            "Epoch 731/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0264 - accuracy: 0.9913 - val_loss: 0.0762 - val_accuracy: 0.9877\n",
            "Epoch 732/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0794 - val_accuracy: 0.9877\n",
            "Epoch 733/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0765 - val_accuracy: 0.9885\n",
            "Epoch 734/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0243 - accuracy: 0.9913 - val_loss: 0.0781 - val_accuracy: 0.9869\n",
            "Epoch 735/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.0758 - val_accuracy: 0.9877\n",
            "Epoch 736/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0296 - accuracy: 0.9890 - val_loss: 0.0867 - val_accuracy: 0.9862\n",
            "Epoch 737/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0294 - accuracy: 0.9902 - val_loss: 0.1139 - val_accuracy: 0.9808\n",
            "Epoch 738/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0392 - accuracy: 0.9872 - val_loss: 0.0800 - val_accuracy: 0.9877\n",
            "Epoch 739/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0370 - accuracy: 0.9867 - val_loss: 0.0825 - val_accuracy: 0.9862\n",
            "Epoch 740/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0294 - accuracy: 0.9902 - val_loss: 0.0835 - val_accuracy: 0.9854\n",
            "Epoch 741/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0276 - accuracy: 0.9897 - val_loss: 0.0878 - val_accuracy: 0.9854\n",
            "Epoch 742/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 0.0817 - val_accuracy: 0.9862\n",
            "Epoch 743/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 0.0754 - val_accuracy: 0.9885\n",
            "Epoch 744/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.0794 - val_accuracy: 0.9877\n",
            "Epoch 745/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 0.0785 - val_accuracy: 0.9877\n",
            "Epoch 746/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0239 - accuracy: 0.9931 - val_loss: 0.0777 - val_accuracy: 0.9885\n",
            "Epoch 747/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.9910 - val_loss: 0.0750 - val_accuracy: 0.9885\n",
            "Epoch 748/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0255 - accuracy: 0.9910 - val_loss: 0.0765 - val_accuracy: 0.9885\n",
            "Epoch 749/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9920 - val_loss: 0.0820 - val_accuracy: 0.9862\n",
            "Epoch 750/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9915 - val_loss: 0.0823 - val_accuracy: 0.9862\n",
            "Epoch 751/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0240 - accuracy: 0.9910 - val_loss: 0.0836 - val_accuracy: 0.9862\n",
            "Epoch 752/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 0.0794 - val_accuracy: 0.9877\n",
            "Epoch 753/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0231 - accuracy: 0.9926 - val_loss: 0.0773 - val_accuracy: 0.9885\n",
            "Epoch 754/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0238 - accuracy: 0.9918 - val_loss: 0.0763 - val_accuracy: 0.9885\n",
            "Epoch 755/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9918 - val_loss: 0.0828 - val_accuracy: 0.9862\n",
            "Epoch 756/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.0786 - val_accuracy: 0.9877\n",
            "Epoch 757/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 0.0805 - val_accuracy: 0.9869\n",
            "Epoch 758/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.0759 - val_accuracy: 0.9885\n",
            "Epoch 759/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0248 - accuracy: 0.9913 - val_loss: 0.0769 - val_accuracy: 0.9862\n",
            "Epoch 760/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0268 - accuracy: 0.9908 - val_loss: 0.0854 - val_accuracy: 0.9862\n",
            "Epoch 761/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 0.0903 - val_accuracy: 0.9838\n",
            "Epoch 762/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 0.0765 - val_accuracy: 0.9877\n",
            "Epoch 763/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 0.0797 - val_accuracy: 0.9877\n",
            "Epoch 764/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 0.0802 - val_accuracy: 0.9862\n",
            "Epoch 765/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.0839 - val_accuracy: 0.9862\n",
            "Epoch 766/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 0.9910 - val_loss: 0.0813 - val_accuracy: 0.9869\n",
            "Epoch 767/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0274 - accuracy: 0.9908 - val_loss: 0.0779 - val_accuracy: 0.9862\n",
            "Epoch 768/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0290 - accuracy: 0.9892 - val_loss: 0.0777 - val_accuracy: 0.9877\n",
            "Epoch 769/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0259 - accuracy: 0.9920 - val_loss: 0.0890 - val_accuracy: 0.9846\n",
            "Epoch 770/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0248 - accuracy: 0.9902 - val_loss: 0.0825 - val_accuracy: 0.9862\n",
            "Epoch 771/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.0806 - val_accuracy: 0.9869\n",
            "Epoch 772/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.0790 - val_accuracy: 0.9885\n",
            "Epoch 773/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0762 - val_accuracy: 0.9877\n",
            "Epoch 774/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 0.0957 - val_accuracy: 0.9831\n",
            "Epoch 775/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0252 - accuracy: 0.9910 - val_loss: 0.0801 - val_accuracy: 0.9869\n",
            "Epoch 776/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.0766 - val_accuracy: 0.9877\n",
            "Epoch 777/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9915 - val_loss: 0.0786 - val_accuracy: 0.9877\n",
            "Epoch 778/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 0.9923 - val_loss: 0.0785 - val_accuracy: 0.9877\n",
            "Epoch 779/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.0842 - val_accuracy: 0.9862\n",
            "Epoch 780/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 0.0774 - val_accuracy: 0.9869\n",
            "Epoch 781/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0287 - accuracy: 0.9905 - val_loss: 0.0785 - val_accuracy: 0.9869\n",
            "Epoch 782/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0330 - accuracy: 0.9892 - val_loss: 0.0925 - val_accuracy: 0.9838\n",
            "Epoch 783/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0272 - accuracy: 0.9910 - val_loss: 0.0884 - val_accuracy: 0.9846\n",
            "Epoch 784/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0253 - accuracy: 0.9908 - val_loss: 0.0848 - val_accuracy: 0.9862\n",
            "Epoch 785/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 0.0804 - val_accuracy: 0.9877\n",
            "Epoch 786/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 0.9936 - val_loss: 0.0814 - val_accuracy: 0.9885\n",
            "Epoch 787/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.0795 - val_accuracy: 0.9877\n",
            "Epoch 788/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0229 - accuracy: 0.9923 - val_loss: 0.0803 - val_accuracy: 0.9869\n",
            "Epoch 789/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0772 - val_accuracy: 0.9877\n",
            "Epoch 790/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.0791 - val_accuracy: 0.9877\n",
            "Epoch 791/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0838 - val_accuracy: 0.9862\n",
            "Epoch 792/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.0828 - val_accuracy: 0.9869\n",
            "Epoch 793/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 0.0760 - val_accuracy: 0.9877\n",
            "Epoch 794/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 0.0823 - val_accuracy: 0.9869\n",
            "Epoch 795/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.0875 - val_accuracy: 0.9854\n",
            "Epoch 796/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 0.0783 - val_accuracy: 0.9877\n",
            "Epoch 797/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.0783 - val_accuracy: 0.9877\n",
            "Epoch 798/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0264 - accuracy: 0.9910 - val_loss: 0.0766 - val_accuracy: 0.9877\n",
            "Epoch 799/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0244 - accuracy: 0.9913 - val_loss: 0.0884 - val_accuracy: 0.9854\n",
            "Epoch 800/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0236 - accuracy: 0.9910 - val_loss: 0.0799 - val_accuracy: 0.9869\n",
            "Epoch 801/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0230 - accuracy: 0.9918 - val_loss: 0.0795 - val_accuracy: 0.9877\n",
            "Epoch 802/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 0.0784 - val_accuracy: 0.9885\n",
            "Epoch 803/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0231 - accuracy: 0.9920 - val_loss: 0.0794 - val_accuracy: 0.9885\n",
            "Epoch 804/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.0772 - val_accuracy: 0.9885\n",
            "Epoch 805/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0223 - accuracy: 0.9928 - val_loss: 0.0816 - val_accuracy: 0.9869\n",
            "Epoch 806/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0226 - accuracy: 0.9920 - val_loss: 0.0813 - val_accuracy: 0.9869\n",
            "Epoch 807/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.0824 - val_accuracy: 0.9877\n",
            "Epoch 808/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0230 - accuracy: 0.9941 - val_loss: 0.0828 - val_accuracy: 0.9869\n",
            "Epoch 809/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0815 - val_accuracy: 0.9869\n",
            "Epoch 810/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0239 - accuracy: 0.9910 - val_loss: 0.0832 - val_accuracy: 0.9869\n",
            "Epoch 811/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0230 - accuracy: 0.9915 - val_loss: 0.0821 - val_accuracy: 0.9869\n",
            "Epoch 812/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 0.0872 - val_accuracy: 0.9862\n",
            "Epoch 813/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0258 - accuracy: 0.9902 - val_loss: 0.0824 - val_accuracy: 0.9869\n",
            "Epoch 814/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0242 - accuracy: 0.9913 - val_loss: 0.0783 - val_accuracy: 0.9869\n",
            "Epoch 815/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0246 - accuracy: 0.9920 - val_loss: 0.0806 - val_accuracy: 0.9877\n",
            "Epoch 816/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0228 - accuracy: 0.9910 - val_loss: 0.0931 - val_accuracy: 0.9831\n",
            "Epoch 817/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 0.0788 - val_accuracy: 0.9877\n",
            "Epoch 818/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0233 - accuracy: 0.9908 - val_loss: 0.0802 - val_accuracy: 0.9869\n",
            "Epoch 819/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9915 - val_loss: 0.0782 - val_accuracy: 0.9877\n",
            "Epoch 820/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0223 - accuracy: 0.9928 - val_loss: 0.0879 - val_accuracy: 0.9862\n",
            "Epoch 821/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0241 - accuracy: 0.9908 - val_loss: 0.0850 - val_accuracy: 0.9862\n",
            "Epoch 822/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.0780 - val_accuracy: 0.9877\n",
            "Epoch 823/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9928 - val_loss: 0.0785 - val_accuracy: 0.9885\n",
            "Epoch 824/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0221 - accuracy: 0.9938 - val_loss: 0.0838 - val_accuracy: 0.9869\n",
            "Epoch 825/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 0.0810 - val_accuracy: 0.9877\n",
            "Epoch 826/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.0824 - val_accuracy: 0.9869\n",
            "Epoch 827/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 0.9923 - val_loss: 0.0775 - val_accuracy: 0.9885\n",
            "Epoch 828/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0236 - accuracy: 0.9918 - val_loss: 0.0788 - val_accuracy: 0.9885\n",
            "Epoch 829/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0227 - accuracy: 0.9923 - val_loss: 0.0777 - val_accuracy: 0.9877\n",
            "Epoch 830/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 0.0782 - val_accuracy: 0.9869\n",
            "Epoch 831/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.0785 - val_accuracy: 0.9877\n",
            "Epoch 832/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0237 - accuracy: 0.9910 - val_loss: 0.0841 - val_accuracy: 0.9869\n",
            "Epoch 833/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.0833 - val_accuracy: 0.9862\n",
            "Epoch 834/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0218 - accuracy: 0.9918 - val_loss: 0.0790 - val_accuracy: 0.9877\n",
            "Epoch 835/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.0882 - val_accuracy: 0.9862\n",
            "Epoch 836/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0221 - accuracy: 0.9931 - val_loss: 0.0796 - val_accuracy: 0.9869\n",
            "Epoch 837/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.0844 - val_accuracy: 0.9862\n",
            "Epoch 838/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0223 - accuracy: 0.9928 - val_loss: 0.0809 - val_accuracy: 0.9869\n",
            "Epoch 839/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 0.0789 - val_accuracy: 0.9877\n",
            "Epoch 840/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0238 - accuracy: 0.9915 - val_loss: 0.0811 - val_accuracy: 0.9869\n",
            "Epoch 841/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.0883 - val_accuracy: 0.9854\n",
            "Epoch 842/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0231 - accuracy: 0.9923 - val_loss: 0.0837 - val_accuracy: 0.9862\n",
            "Epoch 843/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9923 - val_loss: 0.0796 - val_accuracy: 0.9877\n",
            "Epoch 844/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.0829 - val_accuracy: 0.9869\n",
            "Epoch 845/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0230 - accuracy: 0.9918 - val_loss: 0.0897 - val_accuracy: 0.9846\n",
            "Epoch 846/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0247 - accuracy: 0.9913 - val_loss: 0.0881 - val_accuracy: 0.9869\n",
            "Epoch 847/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.0865 - val_accuracy: 0.9862\n",
            "Epoch 848/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0227 - accuracy: 0.9918 - val_loss: 0.0837 - val_accuracy: 0.9869\n",
            "Epoch 849/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.0809 - val_accuracy: 0.9869\n",
            "Epoch 850/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0276 - accuracy: 0.9908 - val_loss: 0.0795 - val_accuracy: 0.9877\n",
            "Epoch 851/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0271 - accuracy: 0.9908 - val_loss: 0.1000 - val_accuracy: 0.9831\n",
            "Epoch 852/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0269 - accuracy: 0.9910 - val_loss: 0.1004 - val_accuracy: 0.9831\n",
            "Epoch 853/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0286 - accuracy: 0.9900 - val_loss: 0.0837 - val_accuracy: 0.9862\n",
            "Epoch 854/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0277 - accuracy: 0.9918 - val_loss: 0.0821 - val_accuracy: 0.9877\n",
            "Epoch 855/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 0.0786 - val_accuracy: 0.9877\n",
            "Epoch 856/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0256 - accuracy: 0.9905 - val_loss: 0.0795 - val_accuracy: 0.9877\n",
            "Epoch 857/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.9913 - val_loss: 0.0876 - val_accuracy: 0.9862\n",
            "Epoch 858/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 0.0861 - val_accuracy: 0.9854\n",
            "Epoch 859/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0242 - accuracy: 0.9910 - val_loss: 0.0909 - val_accuracy: 0.9854\n",
            "Epoch 860/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9926 - val_loss: 0.0802 - val_accuracy: 0.9877\n",
            "Epoch 861/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0230 - accuracy: 0.9920 - val_loss: 0.0808 - val_accuracy: 0.9877\n",
            "Epoch 862/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0278 - accuracy: 0.9908 - val_loss: 0.0877 - val_accuracy: 0.9854\n",
            "Epoch 863/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0257 - accuracy: 0.9928 - val_loss: 0.0877 - val_accuracy: 0.9854\n",
            "Epoch 864/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0236 - accuracy: 0.9918 - val_loss: 0.0830 - val_accuracy: 0.9877\n",
            "Epoch 865/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0243 - accuracy: 0.9931 - val_loss: 0.0796 - val_accuracy: 0.9877\n",
            "Epoch 866/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.0810 - val_accuracy: 0.9877\n",
            "Epoch 867/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.0835 - val_accuracy: 0.9869\n",
            "Epoch 868/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 0.0931 - val_accuracy: 0.9846\n",
            "Epoch 869/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.0872 - val_accuracy: 0.9862\n",
            "Epoch 870/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.0810 - val_accuracy: 0.9877\n",
            "Epoch 871/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.0802 - val_accuracy: 0.9877\n",
            "Epoch 872/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 0.0823 - val_accuracy: 0.9869\n",
            "Epoch 873/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 0.0872 - val_accuracy: 0.9854\n",
            "Epoch 874/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 0.0843 - val_accuracy: 0.9877\n",
            "Epoch 875/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.0813 - val_accuracy: 0.9885\n",
            "Epoch 876/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0237 - accuracy: 0.9910 - val_loss: 0.0823 - val_accuracy: 0.9869\n",
            "Epoch 877/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.0820 - val_accuracy: 0.9862\n",
            "Epoch 878/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9913 - val_loss: 0.0853 - val_accuracy: 0.9869\n",
            "Epoch 879/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0219 - accuracy: 0.9918 - val_loss: 0.0853 - val_accuracy: 0.9862\n",
            "Epoch 880/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.0911 - val_accuracy: 0.9846\n",
            "Epoch 881/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0231 - accuracy: 0.9923 - val_loss: 0.0835 - val_accuracy: 0.9869\n",
            "Epoch 882/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.0826 - val_accuracy: 0.9877\n",
            "Epoch 883/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0215 - accuracy: 0.9931 - val_loss: 0.0830 - val_accuracy: 0.9877\n",
            "Epoch 884/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.0809 - val_accuracy: 0.9877\n",
            "Epoch 885/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9931 - val_loss: 0.0827 - val_accuracy: 0.9877\n",
            "Epoch 886/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0216 - accuracy: 0.9923 - val_loss: 0.0854 - val_accuracy: 0.9862\n",
            "Epoch 887/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0224 - accuracy: 0.9920 - val_loss: 0.0809 - val_accuracy: 0.9869\n",
            "Epoch 888/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0223 - accuracy: 0.9923 - val_loss: 0.0804 - val_accuracy: 0.9877\n",
            "Epoch 889/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9908 - val_loss: 0.0825 - val_accuracy: 0.9877\n",
            "Epoch 890/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.0857 - val_accuracy: 0.9854\n",
            "Epoch 891/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0223 - accuracy: 0.9923 - val_loss: 0.0938 - val_accuracy: 0.9846\n",
            "Epoch 892/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0811 - val_accuracy: 0.9869\n",
            "Epoch 893/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.9936 - val_loss: 0.0823 - val_accuracy: 0.9877\n",
            "Epoch 894/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0225 - accuracy: 0.9920 - val_loss: 0.0918 - val_accuracy: 0.9854\n",
            "Epoch 895/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 0.9918 - val_loss: 0.0846 - val_accuracy: 0.9869\n",
            "Epoch 896/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 0.9928 - val_loss: 0.0813 - val_accuracy: 0.9877\n",
            "Epoch 897/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0838 - val_accuracy: 0.9869\n",
            "Epoch 898/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0209 - accuracy: 0.9928 - val_loss: 0.0824 - val_accuracy: 0.9885\n",
            "Epoch 899/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.0825 - val_accuracy: 0.9885\n",
            "Epoch 900/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0217 - accuracy: 0.9920 - val_loss: 0.0818 - val_accuracy: 0.9885\n",
            "Epoch 901/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0215 - accuracy: 0.9931 - val_loss: 0.0826 - val_accuracy: 0.9885\n",
            "Epoch 902/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 0.9928 - val_loss: 0.0833 - val_accuracy: 0.9877\n",
            "Epoch 903/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9923 - val_loss: 0.0897 - val_accuracy: 0.9862\n",
            "Epoch 904/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9920 - val_loss: 0.0856 - val_accuracy: 0.9869\n",
            "Epoch 905/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9923 - val_loss: 0.0829 - val_accuracy: 0.9877\n",
            "Epoch 906/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.0890 - val_accuracy: 0.9862\n",
            "Epoch 907/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 0.0821 - val_accuracy: 0.9877\n",
            "Epoch 908/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.0813 - val_accuracy: 0.9877\n",
            "Epoch 909/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9928 - val_loss: 0.0908 - val_accuracy: 0.9862\n",
            "Epoch 910/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0232 - accuracy: 0.9915 - val_loss: 0.0922 - val_accuracy: 0.9846\n",
            "Epoch 911/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0268 - accuracy: 0.9905 - val_loss: 0.1058 - val_accuracy: 0.9831\n",
            "Epoch 912/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0275 - accuracy: 0.9897 - val_loss: 0.0897 - val_accuracy: 0.9854\n",
            "Epoch 913/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.0829 - val_accuracy: 0.9877\n",
            "Epoch 914/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 0.0863 - val_accuracy: 0.9869\n",
            "Epoch 915/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.0830 - val_accuracy: 0.9885\n",
            "Epoch 916/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9928 - val_loss: 0.0818 - val_accuracy: 0.9877\n",
            "Epoch 917/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0229 - accuracy: 0.9913 - val_loss: 0.0834 - val_accuracy: 0.9877\n",
            "Epoch 918/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 0.0879 - val_accuracy: 0.9862\n",
            "Epoch 919/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0209 - accuracy: 0.9923 - val_loss: 0.0836 - val_accuracy: 0.9877\n",
            "Epoch 920/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9920 - val_loss: 0.0838 - val_accuracy: 0.9885\n",
            "Epoch 921/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0865 - val_accuracy: 0.9869\n",
            "Epoch 922/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 0.0858 - val_accuracy: 0.9854\n",
            "Epoch 923/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0875 - val_accuracy: 0.9862\n",
            "Epoch 924/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.0824 - val_accuracy: 0.9877\n",
            "Epoch 925/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9908 - val_loss: 0.0828 - val_accuracy: 0.9885\n",
            "Epoch 926/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0247 - accuracy: 0.9900 - val_loss: 0.0833 - val_accuracy: 0.9869\n",
            "Epoch 927/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.0843 - val_accuracy: 0.9869\n",
            "Epoch 928/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0243 - accuracy: 0.9918 - val_loss: 0.0955 - val_accuracy: 0.9838\n",
            "Epoch 929/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9941 - val_loss: 0.0842 - val_accuracy: 0.9877\n",
            "Epoch 930/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0255 - accuracy: 0.9895 - val_loss: 0.0847 - val_accuracy: 0.9877\n",
            "Epoch 931/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9908 - val_loss: 0.0892 - val_accuracy: 0.9854\n",
            "Epoch 932/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0229 - accuracy: 0.9915 - val_loss: 0.0922 - val_accuracy: 0.9854\n",
            "Epoch 933/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0219 - accuracy: 0.9915 - val_loss: 0.0883 - val_accuracy: 0.9862\n",
            "Epoch 934/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 0.9928 - val_loss: 0.0841 - val_accuracy: 0.9885\n",
            "Epoch 935/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 0.0870 - val_accuracy: 0.9869\n",
            "Epoch 936/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.0918 - val_accuracy: 0.9854\n",
            "Epoch 937/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 0.0904 - val_accuracy: 0.9862\n",
            "Epoch 938/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 0.0852 - val_accuracy: 0.9877\n",
            "Epoch 939/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0868 - val_accuracy: 0.9869\n",
            "Epoch 940/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9928 - val_loss: 0.0853 - val_accuracy: 0.9885\n",
            "Epoch 941/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9928 - val_loss: 0.0828 - val_accuracy: 0.9877\n",
            "Epoch 942/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0242 - accuracy: 0.9910 - val_loss: 0.0841 - val_accuracy: 0.9862\n",
            "Epoch 943/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0249 - accuracy: 0.9897 - val_loss: 0.0875 - val_accuracy: 0.9877\n",
            "Epoch 944/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0234 - accuracy: 0.9923 - val_loss: 0.0946 - val_accuracy: 0.9862\n",
            "Epoch 945/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 0.9928 - val_loss: 0.0900 - val_accuracy: 0.9862\n",
            "Epoch 946/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.0859 - val_accuracy: 0.9877\n",
            "Epoch 947/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.0884 - val_accuracy: 0.9869\n",
            "Epoch 948/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.0837 - val_accuracy: 0.9877\n",
            "Epoch 949/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0216 - accuracy: 0.9918 - val_loss: 0.0879 - val_accuracy: 0.9862\n",
            "Epoch 950/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0213 - accuracy: 0.9926 - val_loss: 0.0854 - val_accuracy: 0.9877\n",
            "Epoch 951/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0209 - accuracy: 0.9928 - val_loss: 0.0878 - val_accuracy: 0.9869\n",
            "Epoch 952/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0220 - accuracy: 0.9938 - val_loss: 0.0851 - val_accuracy: 0.9885\n",
            "Epoch 953/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0212 - accuracy: 0.9923 - val_loss: 0.0869 - val_accuracy: 0.9885\n",
            "Epoch 954/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.0877 - val_accuracy: 0.9869\n",
            "Epoch 955/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.0896 - val_accuracy: 0.9854\n",
            "Epoch 956/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.0865 - val_accuracy: 0.9869\n",
            "Epoch 957/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.0842 - val_accuracy: 0.9885\n",
            "Epoch 958/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0232 - accuracy: 0.9915 - val_loss: 0.0863 - val_accuracy: 0.9869\n",
            "Epoch 959/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0866 - val_accuracy: 0.9877\n",
            "Epoch 960/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.0858 - val_accuracy: 0.9885\n",
            "Epoch 961/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 0.0966 - val_accuracy: 0.9838\n",
            "Epoch 962/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0240 - accuracy: 0.9931 - val_loss: 0.0950 - val_accuracy: 0.9846\n",
            "Epoch 963/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0229 - accuracy: 0.9915 - val_loss: 0.0870 - val_accuracy: 0.9869\n",
            "Epoch 964/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.0879 - val_accuracy: 0.9885\n",
            "Epoch 965/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.0874 - val_accuracy: 0.9877\n",
            "Epoch 966/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.1054 - val_accuracy: 0.9831\n",
            "Epoch 967/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0246 - accuracy: 0.9913 - val_loss: 0.0918 - val_accuracy: 0.9862\n",
            "Epoch 968/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0211 - accuracy: 0.9923 - val_loss: 0.0907 - val_accuracy: 0.9854\n",
            "Epoch 969/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0212 - accuracy: 0.9936 - val_loss: 0.0890 - val_accuracy: 0.9862\n",
            "Epoch 970/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 0.0957 - val_accuracy: 0.9846\n",
            "Epoch 971/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0229 - accuracy: 0.9944 - val_loss: 0.0951 - val_accuracy: 0.9862\n",
            "Epoch 972/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0251 - accuracy: 0.9915 - val_loss: 0.0984 - val_accuracy: 0.9838\n",
            "Epoch 973/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0242 - accuracy: 0.9918 - val_loss: 0.0847 - val_accuracy: 0.9869\n",
            "Epoch 974/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0880 - val_accuracy: 0.9869\n",
            "Epoch 975/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9923 - val_loss: 0.0858 - val_accuracy: 0.9885\n",
            "Epoch 976/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.0847 - val_accuracy: 0.9892\n",
            "Epoch 977/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0210 - accuracy: 0.9926 - val_loss: 0.0886 - val_accuracy: 0.9869\n",
            "Epoch 978/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.0873 - val_accuracy: 0.9877\n",
            "Epoch 979/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.0886 - val_accuracy: 0.9869\n",
            "Epoch 980/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0208 - accuracy: 0.9936 - val_loss: 0.0875 - val_accuracy: 0.9869\n",
            "Epoch 981/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 0.0881 - val_accuracy: 0.9885\n",
            "Epoch 982/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9931 - val_loss: 0.0883 - val_accuracy: 0.9877\n",
            "Epoch 983/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0215 - accuracy: 0.9918 - val_loss: 0.0888 - val_accuracy: 0.9862\n",
            "Epoch 984/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0236 - accuracy: 0.9908 - val_loss: 0.0880 - val_accuracy: 0.9862\n",
            "Epoch 985/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.9920 - val_loss: 0.0853 - val_accuracy: 0.9885\n",
            "Epoch 986/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0208 - accuracy: 0.9928 - val_loss: 0.0930 - val_accuracy: 0.9854\n",
            "Epoch 987/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 0.9928 - val_loss: 0.0867 - val_accuracy: 0.9885\n",
            "Epoch 988/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 0.0948 - val_accuracy: 0.9854\n",
            "Epoch 989/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0215 - accuracy: 0.9936 - val_loss: 0.0910 - val_accuracy: 0.9862\n",
            "Epoch 990/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 0.9928 - val_loss: 0.0920 - val_accuracy: 0.9862\n",
            "Epoch 991/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0205 - accuracy: 0.9928 - val_loss: 0.0857 - val_accuracy: 0.9877\n",
            "Epoch 992/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9926 - val_loss: 0.0870 - val_accuracy: 0.9862\n",
            "Epoch 993/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9915 - val_loss: 0.0900 - val_accuracy: 0.9854\n",
            "Epoch 994/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0205 - accuracy: 0.9931 - val_loss: 0.0884 - val_accuracy: 0.9877\n",
            "Epoch 995/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0199 - accuracy: 0.9941 - val_loss: 0.0852 - val_accuracy: 0.9877\n",
            "Epoch 996/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.0878 - val_accuracy: 0.9877\n",
            "Epoch 997/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.0916 - val_accuracy: 0.9862\n",
            "Epoch 998/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9928 - val_loss: 0.0862 - val_accuracy: 0.9885\n",
            "Epoch 999/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0267 - accuracy: 0.9897 - val_loss: 0.0911 - val_accuracy: 0.9862\n",
            "Epoch 1000/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0249 - accuracy: 0.9923 - val_loss: 0.0920 - val_accuracy: 0.9869\n",
            "Epoch 1001/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0243 - accuracy: 0.9915 - val_loss: 0.0995 - val_accuracy: 0.9838\n",
            "Epoch 1002/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 0.9923 - val_loss: 0.0885 - val_accuracy: 0.9877\n",
            "Epoch 1003/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0212 - accuracy: 0.9928 - val_loss: 0.0875 - val_accuracy: 0.9877\n",
            "Epoch 1004/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0208 - accuracy: 0.9928 - val_loss: 0.0866 - val_accuracy: 0.9877\n",
            "Epoch 1005/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9920 - val_loss: 0.0867 - val_accuracy: 0.9869\n",
            "Epoch 1006/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0207 - accuracy: 0.9923 - val_loss: 0.0869 - val_accuracy: 0.9877\n",
            "Epoch 1007/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.0896 - val_accuracy: 0.9877\n",
            "Epoch 1008/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.0876 - val_accuracy: 0.9877\n",
            "Epoch 1009/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.0882 - val_accuracy: 0.9877\n",
            "Epoch 1010/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.0964 - val_accuracy: 0.9854\n",
            "Epoch 1011/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0243 - accuracy: 0.9915 - val_loss: 0.0897 - val_accuracy: 0.9877\n",
            "Epoch 1012/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0261 - accuracy: 0.9913 - val_loss: 0.0881 - val_accuracy: 0.9892\n",
            "Epoch 1013/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0239 - accuracy: 0.9923 - val_loss: 0.0876 - val_accuracy: 0.9862\n",
            "Epoch 1014/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.0879 - val_accuracy: 0.9862\n",
            "Epoch 1015/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0223 - accuracy: 0.9920 - val_loss: 0.0914 - val_accuracy: 0.9862\n",
            "Epoch 1016/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.0886 - val_accuracy: 0.9885\n",
            "Epoch 1017/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0201 - accuracy: 0.9938 - val_loss: 0.0908 - val_accuracy: 0.9877\n",
            "Epoch 1018/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.0891 - val_accuracy: 0.9885\n",
            "Epoch 1019/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0202 - accuracy: 0.9931 - val_loss: 0.0872 - val_accuracy: 0.9877\n",
            "Epoch 1020/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0231 - accuracy: 0.9923 - val_loss: 0.0902 - val_accuracy: 0.9862\n",
            "Epoch 1021/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 0.9928 - val_loss: 0.1011 - val_accuracy: 0.9831\n",
            "Epoch 1022/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 0.0906 - val_accuracy: 0.9854\n",
            "Epoch 1023/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0216 - accuracy: 0.9923 - val_loss: 0.0859 - val_accuracy: 0.9877\n",
            "Epoch 1024/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.0955 - val_accuracy: 0.9862\n",
            "Epoch 1025/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.9928 - val_loss: 0.0915 - val_accuracy: 0.9869\n",
            "Epoch 1026/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.0883 - val_accuracy: 0.9885\n",
            "Epoch 1027/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0197 - accuracy: 0.9946 - val_loss: 0.0876 - val_accuracy: 0.9885\n",
            "Epoch 1028/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0214 - accuracy: 0.9920 - val_loss: 0.0895 - val_accuracy: 0.9885\n",
            "Epoch 1029/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.0907 - val_accuracy: 0.9854\n",
            "Epoch 1030/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.0894 - val_accuracy: 0.9877\n",
            "Epoch 1031/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.0888 - val_accuracy: 0.9885\n",
            "Epoch 1032/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.0903 - val_accuracy: 0.9877\n",
            "Epoch 1033/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0194 - accuracy: 0.9931 - val_loss: 0.0882 - val_accuracy: 0.9885\n",
            "Epoch 1034/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9923 - val_loss: 0.0897 - val_accuracy: 0.9877\n",
            "Epoch 1035/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 0.9954 - val_loss: 0.0917 - val_accuracy: 0.9877\n",
            "Epoch 1036/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0205 - accuracy: 0.9946 - val_loss: 0.0934 - val_accuracy: 0.9846\n",
            "Epoch 1037/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0927 - val_accuracy: 0.9869\n",
            "Epoch 1038/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.0893 - val_accuracy: 0.9854\n",
            "Epoch 1039/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.0922 - val_accuracy: 0.9862\n",
            "Epoch 1040/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 0.0946 - val_accuracy: 0.9854\n",
            "Epoch 1041/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 0.9936 - val_loss: 0.0903 - val_accuracy: 0.9885\n",
            "Epoch 1042/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.0877 - val_accuracy: 0.9885\n",
            "Epoch 1043/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0193 - accuracy: 0.9941 - val_loss: 0.0922 - val_accuracy: 0.9869\n",
            "Epoch 1044/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0199 - accuracy: 0.9944 - val_loss: 0.0880 - val_accuracy: 0.9877\n",
            "Epoch 1045/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0222 - accuracy: 0.9920 - val_loss: 0.0882 - val_accuracy: 0.9885\n",
            "Epoch 1046/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0217 - accuracy: 0.9936 - val_loss: 0.0936 - val_accuracy: 0.9854\n",
            "Epoch 1047/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 0.0989 - val_accuracy: 0.9854\n",
            "Epoch 1048/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0928 - val_accuracy: 0.9862\n",
            "Epoch 1049/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9941 - val_loss: 0.0877 - val_accuracy: 0.9885\n",
            "Epoch 1050/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 0.0909 - val_accuracy: 0.9869\n",
            "Epoch 1051/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9936 - val_loss: 0.0880 - val_accuracy: 0.9877\n",
            "Epoch 1052/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 0.0916 - val_accuracy: 0.9862\n",
            "Epoch 1053/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0215 - accuracy: 0.9938 - val_loss: 0.0913 - val_accuracy: 0.9862\n",
            "Epoch 1054/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.0902 - val_accuracy: 0.9885\n",
            "Epoch 1055/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.0880 - val_accuracy: 0.9877\n",
            "Epoch 1056/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0916 - val_accuracy: 0.9877\n",
            "Epoch 1057/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 0.0903 - val_accuracy: 0.9885\n",
            "Epoch 1058/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.0906 - val_accuracy: 0.9869\n",
            "Epoch 1059/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.0986 - val_accuracy: 0.9854\n",
            "Epoch 1060/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.0901 - val_accuracy: 0.9877\n",
            "Epoch 1061/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.0888 - val_accuracy: 0.9877\n",
            "Epoch 1062/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.0928 - val_accuracy: 0.9869\n",
            "Epoch 1063/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.0991 - val_accuracy: 0.9846\n",
            "Epoch 1064/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 0.0900 - val_accuracy: 0.9885\n",
            "Epoch 1065/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0218 - accuracy: 0.9936 - val_loss: 0.0891 - val_accuracy: 0.9885\n",
            "Epoch 1066/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0259 - accuracy: 0.9900 - val_loss: 0.0933 - val_accuracy: 0.9854\n",
            "Epoch 1067/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0251 - accuracy: 0.9910 - val_loss: 0.1027 - val_accuracy: 0.9846\n",
            "Epoch 1068/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.0932 - val_accuracy: 0.9862\n",
            "Epoch 1069/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 0.1051 - val_accuracy: 0.9831\n",
            "Epoch 1070/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0276 - accuracy: 0.9900 - val_loss: 0.0935 - val_accuracy: 0.9877\n",
            "Epoch 1071/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0276 - accuracy: 0.9890 - val_loss: 0.0917 - val_accuracy: 0.9877\n",
            "Epoch 1072/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9905 - val_loss: 0.0913 - val_accuracy: 0.9862\n",
            "Epoch 1073/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.0962 - val_accuracy: 0.9862\n",
            "Epoch 1074/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.0956 - val_accuracy: 0.9862\n",
            "Epoch 1075/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0207 - accuracy: 0.9944 - val_loss: 0.0908 - val_accuracy: 0.9877\n",
            "Epoch 1076/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.0887 - val_accuracy: 0.9877\n",
            "Epoch 1077/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0933 - val_accuracy: 0.9869\n",
            "Epoch 1078/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9936 - val_loss: 0.1098 - val_accuracy: 0.9831\n",
            "Epoch 1079/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0249 - accuracy: 0.9920 - val_loss: 0.0903 - val_accuracy: 0.9862\n",
            "Epoch 1080/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0223 - accuracy: 0.9923 - val_loss: 0.0901 - val_accuracy: 0.9885\n",
            "Epoch 1081/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0218 - accuracy: 0.9920 - val_loss: 0.0953 - val_accuracy: 0.9846\n",
            "Epoch 1082/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.0901 - val_accuracy: 0.9877\n",
            "Epoch 1083/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0196 - accuracy: 0.9944 - val_loss: 0.0900 - val_accuracy: 0.9877\n",
            "Epoch 1084/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.0940 - val_accuracy: 0.9869\n",
            "Epoch 1085/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.0899 - val_accuracy: 0.9885\n",
            "Epoch 1086/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0211 - accuracy: 0.9926 - val_loss: 0.0953 - val_accuracy: 0.9862\n",
            "Epoch 1087/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 0.0971 - val_accuracy: 0.9846\n",
            "Epoch 1088/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0215 - accuracy: 0.9936 - val_loss: 0.0919 - val_accuracy: 0.9885\n",
            "Epoch 1089/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0198 - accuracy: 0.9944 - val_loss: 0.0905 - val_accuracy: 0.9869\n",
            "Epoch 1090/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0192 - accuracy: 0.9928 - val_loss: 0.0915 - val_accuracy: 0.9885\n",
            "Epoch 1091/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 0.0948 - val_accuracy: 0.9869\n",
            "Epoch 1092/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0980 - val_accuracy: 0.9869\n",
            "Epoch 1093/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.0943 - val_accuracy: 0.9862\n",
            "Epoch 1094/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.1012 - val_accuracy: 0.9846\n",
            "Epoch 1095/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.0934 - val_accuracy: 0.9869\n",
            "Epoch 1096/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0899 - val_accuracy: 0.9877\n",
            "Epoch 1097/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0222 - accuracy: 0.9938 - val_loss: 0.0952 - val_accuracy: 0.9869\n",
            "Epoch 1098/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0227 - accuracy: 0.9920 - val_loss: 0.0981 - val_accuracy: 0.9854\n",
            "Epoch 1099/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.0941 - val_accuracy: 0.9862\n",
            "Epoch 1100/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.0907 - val_accuracy: 0.9877\n",
            "Epoch 1101/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 0.0908 - val_accuracy: 0.9877\n",
            "Epoch 1102/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.0952 - val_accuracy: 0.9869\n",
            "Epoch 1103/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.0909 - val_accuracy: 0.9885\n",
            "Epoch 1104/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0196 - accuracy: 0.9944 - val_loss: 0.0908 - val_accuracy: 0.9877\n",
            "Epoch 1105/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.0920 - val_accuracy: 0.9877\n",
            "Epoch 1106/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0218 - accuracy: 0.9923 - val_loss: 0.0957 - val_accuracy: 0.9869\n",
            "Epoch 1107/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0223 - accuracy: 0.9915 - val_loss: 0.0969 - val_accuracy: 0.9854\n",
            "Epoch 1108/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 0.0904 - val_accuracy: 0.9885\n",
            "Epoch 1109/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.0935 - val_accuracy: 0.9869\n",
            "Epoch 1110/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0185 - accuracy: 0.9938 - val_loss: 0.0911 - val_accuracy: 0.9877\n",
            "Epoch 1111/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.0911 - val_accuracy: 0.9877\n",
            "Epoch 1112/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.0969 - val_accuracy: 0.9862\n",
            "Epoch 1113/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.0977 - val_accuracy: 0.9862\n",
            "Epoch 1114/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0264 - accuracy: 0.9902 - val_loss: 0.0911 - val_accuracy: 0.9877\n",
            "Epoch 1115/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0222 - accuracy: 0.9928 - val_loss: 0.0921 - val_accuracy: 0.9877\n",
            "Epoch 1116/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 0.0928 - val_accuracy: 0.9869\n",
            "Epoch 1117/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0219 - accuracy: 0.9938 - val_loss: 0.0999 - val_accuracy: 0.9854\n",
            "Epoch 1118/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0199 - accuracy: 0.9946 - val_loss: 0.0927 - val_accuracy: 0.9885\n",
            "Epoch 1119/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0196 - accuracy: 0.9944 - val_loss: 0.0911 - val_accuracy: 0.9885\n",
            "Epoch 1120/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 0.0915 - val_accuracy: 0.9885\n",
            "Epoch 1121/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0215 - accuracy: 0.9918 - val_loss: 0.0934 - val_accuracy: 0.9877\n",
            "Epoch 1122/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.0940 - val_accuracy: 0.9877\n",
            "Epoch 1123/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.0909 - val_accuracy: 0.9885\n",
            "Epoch 1124/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.0980 - val_accuracy: 0.9869\n",
            "Epoch 1125/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0203 - accuracy: 0.9928 - val_loss: 0.0912 - val_accuracy: 0.9877\n",
            "Epoch 1126/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9938 - val_loss: 0.0907 - val_accuracy: 0.9877\n",
            "Epoch 1127/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.0924 - val_accuracy: 0.9869\n",
            "Epoch 1128/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.0954 - val_accuracy: 0.9885\n",
            "Epoch 1129/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0188 - accuracy: 0.9944 - val_loss: 0.0972 - val_accuracy: 0.9869\n",
            "Epoch 1130/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 0.0954 - val_accuracy: 0.9877\n",
            "Epoch 1131/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.0917 - val_accuracy: 0.9877\n",
            "Epoch 1132/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0212 - accuracy: 0.9936 - val_loss: 0.0914 - val_accuracy: 0.9885\n",
            "Epoch 1133/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0192 - accuracy: 0.9949 - val_loss: 0.0945 - val_accuracy: 0.9877\n",
            "Epoch 1134/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0197 - accuracy: 0.9928 - val_loss: 0.0962 - val_accuracy: 0.9877\n",
            "Epoch 1135/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0196 - accuracy: 0.9931 - val_loss: 0.0921 - val_accuracy: 0.9885\n",
            "Epoch 1136/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.0962 - val_accuracy: 0.9869\n",
            "Epoch 1137/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.0948 - val_accuracy: 0.9869\n",
            "Epoch 1138/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.0920 - val_accuracy: 0.9877\n",
            "Epoch 1139/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0207 - accuracy: 0.9941 - val_loss: 0.0923 - val_accuracy: 0.9877\n",
            "Epoch 1140/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0265 - accuracy: 0.9913 - val_loss: 0.0933 - val_accuracy: 0.9885\n",
            "Epoch 1141/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0267 - accuracy: 0.9900 - val_loss: 0.1146 - val_accuracy: 0.9838\n",
            "Epoch 1142/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.1014 - val_accuracy: 0.9854\n",
            "Epoch 1143/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0218 - accuracy: 0.9920 - val_loss: 0.0913 - val_accuracy: 0.9885\n",
            "Epoch 1144/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.0933 - val_accuracy: 0.9877\n",
            "Epoch 1145/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 0.9926 - val_loss: 0.1063 - val_accuracy: 0.9846\n",
            "Epoch 1146/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.0951 - val_accuracy: 0.9869\n",
            "Epoch 1147/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.0938 - val_accuracy: 0.9885\n",
            "Epoch 1148/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 0.0931 - val_accuracy: 0.9877\n",
            "Epoch 1149/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9946 - val_loss: 0.0939 - val_accuracy: 0.9877\n",
            "Epoch 1150/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0190 - accuracy: 0.9931 - val_loss: 0.0928 - val_accuracy: 0.9885\n",
            "Epoch 1151/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 0.1016 - val_accuracy: 0.9846\n",
            "Epoch 1152/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.0939 - val_accuracy: 0.9877\n",
            "Epoch 1153/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.0985 - val_accuracy: 0.9869\n",
            "Epoch 1154/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0188 - accuracy: 0.9938 - val_loss: 0.0941 - val_accuracy: 0.9885\n",
            "Epoch 1155/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 0.9936 - val_loss: 0.0931 - val_accuracy: 0.9877\n",
            "Epoch 1156/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9956 - val_loss: 0.1012 - val_accuracy: 0.9862\n",
            "Epoch 1157/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0227 - accuracy: 0.9918 - val_loss: 0.1122 - val_accuracy: 0.9823\n",
            "Epoch 1158/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0246 - accuracy: 0.9910 - val_loss: 0.1082 - val_accuracy: 0.9838\n",
            "Epoch 1159/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0291 - accuracy: 0.9892 - val_loss: 0.0958 - val_accuracy: 0.9877\n",
            "Epoch 1160/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.0948 - val_accuracy: 0.9885\n",
            "Epoch 1161/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0230 - accuracy: 0.9910 - val_loss: 0.0993 - val_accuracy: 0.9862\n",
            "Epoch 1162/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0227 - accuracy: 0.9920 - val_loss: 0.1089 - val_accuracy: 0.9846\n",
            "Epoch 1163/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 0.0937 - val_accuracy: 0.9877\n",
            "Epoch 1164/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 0.0920 - val_accuracy: 0.9885\n",
            "Epoch 1165/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 0.0999 - val_accuracy: 0.9869\n",
            "Epoch 1166/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0182 - accuracy: 0.9936 - val_loss: 0.0930 - val_accuracy: 0.9885\n",
            "Epoch 1167/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0194 - accuracy: 0.9946 - val_loss: 0.0985 - val_accuracy: 0.9869\n",
            "Epoch 1168/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9944 - val_loss: 0.1007 - val_accuracy: 0.9854\n",
            "Epoch 1169/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 0.0934 - val_accuracy: 0.9877\n",
            "Epoch 1170/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.0941 - val_accuracy: 0.9877\n",
            "Epoch 1171/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.0928 - val_accuracy: 0.9885\n",
            "Epoch 1172/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9949 - val_loss: 0.0937 - val_accuracy: 0.9877\n",
            "Epoch 1173/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0199 - accuracy: 0.9944 - val_loss: 0.0927 - val_accuracy: 0.9877\n",
            "Epoch 1174/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0190 - accuracy: 0.9949 - val_loss: 0.1003 - val_accuracy: 0.9862\n",
            "Epoch 1175/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0209 - accuracy: 0.9923 - val_loss: 0.1008 - val_accuracy: 0.9869\n",
            "Epoch 1176/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0216 - accuracy: 0.9928 - val_loss: 0.1003 - val_accuracy: 0.9846\n",
            "Epoch 1177/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0196 - accuracy: 0.9949 - val_loss: 0.0987 - val_accuracy: 0.9862\n",
            "Epoch 1178/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.0957 - val_accuracy: 0.9877\n",
            "Epoch 1179/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9938 - val_loss: 0.0982 - val_accuracy: 0.9877\n",
            "Epoch 1180/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9938 - val_loss: 0.0976 - val_accuracy: 0.9869\n",
            "Epoch 1181/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9949 - val_loss: 0.0940 - val_accuracy: 0.9877\n",
            "Epoch 1182/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9949 - val_loss: 0.0971 - val_accuracy: 0.9877\n",
            "Epoch 1183/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.0944 - val_accuracy: 0.9885\n",
            "Epoch 1184/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0976 - val_accuracy: 0.9877\n",
            "Epoch 1185/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 0.9946 - val_loss: 0.0960 - val_accuracy: 0.9877\n",
            "Epoch 1186/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.0995 - val_accuracy: 0.9862\n",
            "Epoch 1187/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0947 - val_accuracy: 0.9877\n",
            "Epoch 1188/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.0950 - val_accuracy: 0.9877\n",
            "Epoch 1189/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9954 - val_loss: 0.0934 - val_accuracy: 0.9877\n",
            "Epoch 1190/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.0944 - val_accuracy: 0.9877\n",
            "Epoch 1191/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9949 - val_loss: 0.0978 - val_accuracy: 0.9869\n",
            "Epoch 1192/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 0.0969 - val_accuracy: 0.9885\n",
            "Epoch 1193/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.0935 - val_accuracy: 0.9877\n",
            "Epoch 1194/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 0.0962 - val_accuracy: 0.9877\n",
            "Epoch 1195/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.0955 - val_accuracy: 0.9877\n",
            "Epoch 1196/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 0.0958 - val_accuracy: 0.9877\n",
            "Epoch 1197/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9936 - val_loss: 0.0941 - val_accuracy: 0.9877\n",
            "Epoch 1198/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9946 - val_loss: 0.0969 - val_accuracy: 0.9877\n",
            "Epoch 1199/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0181 - accuracy: 0.9941 - val_loss: 0.0957 - val_accuracy: 0.9877\n",
            "Epoch 1200/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 0.0940 - val_accuracy: 0.9877\n",
            "Epoch 1201/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.0954 - val_accuracy: 0.9877\n",
            "Epoch 1202/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0195 - accuracy: 0.9936 - val_loss: 0.0955 - val_accuracy: 0.9877\n",
            "Epoch 1203/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0186 - accuracy: 0.9931 - val_loss: 0.0983 - val_accuracy: 0.9869\n",
            "Epoch 1204/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0189 - accuracy: 0.9946 - val_loss: 0.0955 - val_accuracy: 0.9877\n",
            "Epoch 1205/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0184 - accuracy: 0.9949 - val_loss: 0.0967 - val_accuracy: 0.9877\n",
            "Epoch 1206/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9936 - val_loss: 0.0969 - val_accuracy: 0.9877\n",
            "Epoch 1207/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0184 - accuracy: 0.9931 - val_loss: 0.1017 - val_accuracy: 0.9869\n",
            "Epoch 1208/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0192 - accuracy: 0.9946 - val_loss: 0.1014 - val_accuracy: 0.9869\n",
            "Epoch 1209/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0191 - accuracy: 0.9931 - val_loss: 0.0977 - val_accuracy: 0.9877\n",
            "Epoch 1210/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.0969 - val_accuracy: 0.9877\n",
            "Epoch 1211/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0184 - accuracy: 0.9946 - val_loss: 0.0996 - val_accuracy: 0.9877\n",
            "Epoch 1212/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 0.0949 - val_accuracy: 0.9877\n",
            "Epoch 1213/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9944 - val_loss: 0.0956 - val_accuracy: 0.9885\n",
            "Epoch 1214/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9920 - val_loss: 0.1050 - val_accuracy: 0.9846\n",
            "Epoch 1215/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.0957 - val_accuracy: 0.9877\n",
            "Epoch 1216/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0182 - accuracy: 0.9933 - val_loss: 0.0945 - val_accuracy: 0.9877\n",
            "Epoch 1217/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0182 - accuracy: 0.9946 - val_loss: 0.0974 - val_accuracy: 0.9877\n",
            "Epoch 1218/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.0971 - val_accuracy: 0.9877\n",
            "Epoch 1219/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 0.0964 - val_accuracy: 0.9877\n",
            "Epoch 1220/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 0.0954 - val_accuracy: 0.9877\n",
            "Epoch 1221/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9946 - val_loss: 0.0943 - val_accuracy: 0.9885\n",
            "Epoch 1222/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9938 - val_loss: 0.0958 - val_accuracy: 0.9885\n",
            "Epoch 1223/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 0.9946 - val_loss: 0.1026 - val_accuracy: 0.9862\n",
            "Epoch 1224/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 0.9946 - val_loss: 0.0966 - val_accuracy: 0.9885\n",
            "Epoch 1225/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.0989 - val_accuracy: 0.9869\n",
            "Epoch 1226/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.0991 - val_accuracy: 0.9869\n",
            "Epoch 1227/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0185 - accuracy: 0.9931 - val_loss: 0.0987 - val_accuracy: 0.9885\n",
            "Epoch 1228/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0236 - accuracy: 0.9913 - val_loss: 0.0983 - val_accuracy: 0.9877\n",
            "Epoch 1229/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 0.0982 - val_accuracy: 0.9869\n",
            "Epoch 1230/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.0981 - val_accuracy: 0.9885\n",
            "Epoch 1231/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0186 - accuracy: 0.9946 - val_loss: 0.0986 - val_accuracy: 0.9885\n",
            "Epoch 1232/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0182 - accuracy: 0.9938 - val_loss: 0.1008 - val_accuracy: 0.9869\n",
            "Epoch 1233/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 0.0969 - val_accuracy: 0.9877\n",
            "Epoch 1234/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.0977 - val_accuracy: 0.9885\n",
            "Epoch 1235/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0196 - accuracy: 0.9941 - val_loss: 0.0971 - val_accuracy: 0.9877\n",
            "Epoch 1236/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.0975 - val_accuracy: 0.9885\n",
            "Epoch 1237/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9936 - val_loss: 0.0958 - val_accuracy: 0.9869\n",
            "Epoch 1238/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0200 - accuracy: 0.9928 - val_loss: 0.0966 - val_accuracy: 0.9885\n",
            "Epoch 1239/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0956 - val_accuracy: 0.9877\n",
            "Epoch 1240/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0181 - accuracy: 0.9946 - val_loss: 0.0966 - val_accuracy: 0.9885\n",
            "Epoch 1241/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0181 - accuracy: 0.9949 - val_loss: 0.1157 - val_accuracy: 0.9823\n",
            "Epoch 1242/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0264 - accuracy: 0.9892 - val_loss: 0.1155 - val_accuracy: 0.9831\n",
            "Epoch 1243/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.1037 - val_accuracy: 0.9854\n",
            "Epoch 1244/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0208 - accuracy: 0.9936 - val_loss: 0.0985 - val_accuracy: 0.9877\n",
            "Epoch 1245/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.0957 - val_accuracy: 0.9877\n",
            "Epoch 1246/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 0.0947 - val_accuracy: 0.9877\n",
            "Epoch 1247/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 0.1000 - val_accuracy: 0.9877\n",
            "Epoch 1248/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.0996 - val_accuracy: 0.9877\n",
            "Epoch 1249/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.0972 - val_accuracy: 0.9885\n",
            "Epoch 1250/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.1017 - val_accuracy: 0.9854\n",
            "Epoch 1251/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0975 - val_accuracy: 0.9877\n",
            "Epoch 1252/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0209 - accuracy: 0.9944 - val_loss: 0.0971 - val_accuracy: 0.9885\n",
            "Epoch 1253/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0185 - accuracy: 0.9949 - val_loss: 0.0973 - val_accuracy: 0.9885\n",
            "Epoch 1254/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.0972 - val_accuracy: 0.9877\n",
            "Epoch 1255/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.0975 - val_accuracy: 0.9885\n",
            "Epoch 1256/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0181 - accuracy: 0.9946 - val_loss: 0.1025 - val_accuracy: 0.9862\n",
            "Epoch 1257/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 0.1013 - val_accuracy: 0.9869\n",
            "Epoch 1258/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0239 - accuracy: 0.9923 - val_loss: 0.0981 - val_accuracy: 0.9877\n",
            "Epoch 1259/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0213 - accuracy: 0.9923 - val_loss: 0.0985 - val_accuracy: 0.9885\n",
            "Epoch 1260/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0236 - accuracy: 0.9915 - val_loss: 0.0965 - val_accuracy: 0.9885\n",
            "Epoch 1261/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0187 - accuracy: 0.9951 - val_loss: 0.1019 - val_accuracy: 0.9869\n",
            "Epoch 1262/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.1019 - val_accuracy: 0.9869\n",
            "Epoch 1263/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.0965 - val_accuracy: 0.9885\n",
            "Epoch 1264/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.0977 - val_accuracy: 0.9877\n",
            "Epoch 1265/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0178 - accuracy: 0.9954 - val_loss: 0.1046 - val_accuracy: 0.9862\n",
            "Epoch 1266/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9938 - val_loss: 0.0991 - val_accuracy: 0.9877\n",
            "Epoch 1267/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9954 - val_loss: 0.0969 - val_accuracy: 0.9877\n",
            "Epoch 1268/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.0981 - val_accuracy: 0.9885\n",
            "Epoch 1269/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0187 - accuracy: 0.9946 - val_loss: 0.0986 - val_accuracy: 0.9885\n",
            "Epoch 1270/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0197 - accuracy: 0.9941 - val_loss: 0.1085 - val_accuracy: 0.9838\n",
            "Epoch 1271/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9923 - val_loss: 0.1094 - val_accuracy: 0.9854\n",
            "Epoch 1272/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 0.1032 - val_accuracy: 0.9862\n",
            "Epoch 1273/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 0.0990 - val_accuracy: 0.9869\n",
            "Epoch 1274/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.1087 - val_accuracy: 0.9846\n",
            "Epoch 1275/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.0980 - val_accuracy: 0.9885\n",
            "Epoch 1276/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.0997 - val_accuracy: 0.9877\n",
            "Epoch 1277/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.1019 - val_accuracy: 0.9862\n",
            "Epoch 1278/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.1088 - val_accuracy: 0.9846\n",
            "Epoch 1279/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.1040 - val_accuracy: 0.9869\n",
            "Epoch 1280/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9949 - val_loss: 0.1080 - val_accuracy: 0.9846\n",
            "Epoch 1281/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 0.9920 - val_loss: 0.0981 - val_accuracy: 0.9885\n",
            "Epoch 1282/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0994 - val_accuracy: 0.9885\n",
            "Epoch 1283/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 0.1028 - val_accuracy: 0.9869\n",
            "Epoch 1284/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0215 - accuracy: 0.9928 - val_loss: 0.1041 - val_accuracy: 0.9862\n",
            "Epoch 1285/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0196 - accuracy: 0.9944 - val_loss: 0.0999 - val_accuracy: 0.9877\n",
            "Epoch 1286/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9949 - val_loss: 0.0960 - val_accuracy: 0.9885\n",
            "Epoch 1287/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0204 - accuracy: 0.9951 - val_loss: 0.0972 - val_accuracy: 0.9885\n",
            "Epoch 1288/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.1003 - val_accuracy: 0.9885\n",
            "Epoch 1289/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0185 - accuracy: 0.9946 - val_loss: 0.0993 - val_accuracy: 0.9885\n",
            "Epoch 1290/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.1017 - val_accuracy: 0.9869\n",
            "Epoch 1291/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.1017 - val_accuracy: 0.9885\n",
            "Epoch 1292/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.0994 - val_accuracy: 0.9885\n",
            "Epoch 1293/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 0.1011 - val_accuracy: 0.9877\n",
            "Epoch 1294/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 0.1019 - val_accuracy: 0.9869\n",
            "Epoch 1295/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.0979 - val_accuracy: 0.9885\n",
            "Epoch 1296/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0233 - accuracy: 0.9920 - val_loss: 0.1013 - val_accuracy: 0.9877\n",
            "Epoch 1297/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0266 - accuracy: 0.9902 - val_loss: 0.1002 - val_accuracy: 0.9885\n",
            "Epoch 1298/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.1037 - val_accuracy: 0.9869\n",
            "Epoch 1299/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1029 - val_accuracy: 0.9877\n",
            "Epoch 1300/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.0990 - val_accuracy: 0.9885\n",
            "Epoch 1301/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 0.1065 - val_accuracy: 0.9869\n",
            "Epoch 1302/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 0.0992 - val_accuracy: 0.9885\n",
            "Epoch 1303/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0994 - val_accuracy: 0.9877\n",
            "Epoch 1304/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0210 - accuracy: 0.9920 - val_loss: 0.0978 - val_accuracy: 0.9877\n",
            "Epoch 1305/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.1041 - val_accuracy: 0.9862\n",
            "Epoch 1306/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0189 - accuracy: 0.9944 - val_loss: 0.1049 - val_accuracy: 0.9862\n",
            "Epoch 1307/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 0.9949 - val_loss: 0.1067 - val_accuracy: 0.9862\n",
            "Epoch 1308/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.1013 - val_accuracy: 0.9892\n",
            "Epoch 1309/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.1033 - val_accuracy: 0.9877\n",
            "Epoch 1310/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.1018 - val_accuracy: 0.9885\n",
            "Epoch 1311/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0174 - accuracy: 0.9956 - val_loss: 0.0994 - val_accuracy: 0.9885\n",
            "Epoch 1312/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 0.1014 - val_accuracy: 0.9885\n",
            "Epoch 1313/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 0.0990 - val_accuracy: 0.9885\n",
            "Epoch 1314/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.1007 - val_accuracy: 0.9885\n",
            "Epoch 1315/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 0.1046 - val_accuracy: 0.9869\n",
            "Epoch 1316/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.1131 - val_accuracy: 0.9838\n",
            "Epoch 1317/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0236 - accuracy: 0.9931 - val_loss: 0.1245 - val_accuracy: 0.9823\n",
            "Epoch 1318/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0273 - accuracy: 0.9892 - val_loss: 0.1089 - val_accuracy: 0.9862\n",
            "Epoch 1319/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.1054 - val_accuracy: 0.9862\n",
            "Epoch 1320/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.0977 - val_accuracy: 0.9885\n",
            "Epoch 1321/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 0.0996 - val_accuracy: 0.9885\n",
            "Epoch 1322/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.1032 - val_accuracy: 0.9877\n",
            "Epoch 1323/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.1132 - val_accuracy: 0.9831\n",
            "Epoch 1324/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 0.1062 - val_accuracy: 0.9862\n",
            "Epoch 1325/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9928 - val_loss: 0.1011 - val_accuracy: 0.9885\n",
            "Epoch 1326/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.1004 - val_accuracy: 0.9877\n",
            "Epoch 1327/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.1041 - val_accuracy: 0.9869\n",
            "Epoch 1328/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.1027 - val_accuracy: 0.9877\n",
            "Epoch 1329/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0181 - accuracy: 0.9949 - val_loss: 0.1011 - val_accuracy: 0.9885\n",
            "Epoch 1330/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0171 - accuracy: 0.9956 - val_loss: 0.1016 - val_accuracy: 0.9877\n",
            "Epoch 1331/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.1024 - val_accuracy: 0.9877\n",
            "Epoch 1332/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.1021 - val_accuracy: 0.9885\n",
            "Epoch 1333/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9949 - val_loss: 0.1023 - val_accuracy: 0.9877\n",
            "Epoch 1334/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.1048 - val_accuracy: 0.9877\n",
            "Epoch 1335/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.1010 - val_accuracy: 0.9885\n",
            "Epoch 1336/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 0.9959 - val_loss: 0.1010 - val_accuracy: 0.9885\n",
            "Epoch 1337/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.9962 - val_loss: 0.1047 - val_accuracy: 0.9877\n",
            "Epoch 1338/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.1000 - val_accuracy: 0.9885\n",
            "Epoch 1339/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0175 - accuracy: 0.9956 - val_loss: 0.1005 - val_accuracy: 0.9885\n",
            "Epoch 1340/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 0.1027 - val_accuracy: 0.9885\n",
            "Epoch 1341/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0188 - accuracy: 0.9946 - val_loss: 0.1003 - val_accuracy: 0.9869\n",
            "Epoch 1342/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.1035 - val_accuracy: 0.9869\n",
            "Epoch 1343/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9931 - val_loss: 0.1116 - val_accuracy: 0.9846\n",
            "Epoch 1344/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0187 - accuracy: 0.9951 - val_loss: 0.1012 - val_accuracy: 0.9877\n",
            "Epoch 1345/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9936 - val_loss: 0.1035 - val_accuracy: 0.9877\n",
            "Epoch 1346/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0166 - accuracy: 0.9959 - val_loss: 0.1009 - val_accuracy: 0.9877\n",
            "Epoch 1347/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.1027 - val_accuracy: 0.9877\n",
            "Epoch 1348/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.0992 - val_accuracy: 0.9885\n",
            "Epoch 1349/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.9944 - val_loss: 0.1017 - val_accuracy: 0.9877\n",
            "Epoch 1350/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 0.9944 - val_loss: 0.1015 - val_accuracy: 0.9869\n",
            "Epoch 1351/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9923 - val_loss: 0.1029 - val_accuracy: 0.9885\n",
            "Epoch 1352/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 0.1039 - val_accuracy: 0.9885\n",
            "Epoch 1353/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.1098 - val_accuracy: 0.9854\n",
            "Epoch 1354/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.1167 - val_accuracy: 0.9846\n",
            "Epoch 1355/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0198 - accuracy: 0.9944 - val_loss: 0.1016 - val_accuracy: 0.9885\n",
            "Epoch 1356/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.1047 - val_accuracy: 0.9877\n",
            "Epoch 1357/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.1016 - val_accuracy: 0.9885\n",
            "Epoch 1358/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0174 - accuracy: 0.9954 - val_loss: 0.1016 - val_accuracy: 0.9885\n",
            "Epoch 1359/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0171 - accuracy: 0.9956 - val_loss: 0.1037 - val_accuracy: 0.9885\n",
            "Epoch 1360/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.1031 - val_accuracy: 0.9885\n",
            "Epoch 1361/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.1052 - val_accuracy: 0.9869\n",
            "Epoch 1362/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0165 - accuracy: 0.9956 - val_loss: 0.1013 - val_accuracy: 0.9885\n",
            "Epoch 1363/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.1013 - val_accuracy: 0.9885\n",
            "Epoch 1364/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.1020 - val_accuracy: 0.9885\n",
            "Epoch 1365/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.1023 - val_accuracy: 0.9885\n",
            "Epoch 1366/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0182 - accuracy: 0.9936 - val_loss: 0.1066 - val_accuracy: 0.9869\n",
            "Epoch 1367/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0185 - accuracy: 0.9936 - val_loss: 0.1049 - val_accuracy: 0.9869\n",
            "Epoch 1368/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.1032 - val_accuracy: 0.9885\n",
            "Epoch 1369/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.0999 - val_accuracy: 0.9885\n",
            "Epoch 1370/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.1016 - val_accuracy: 0.9885\n",
            "Epoch 1371/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0206 - accuracy: 0.9938 - val_loss: 0.1219 - val_accuracy: 0.9838\n",
            "Epoch 1372/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0216 - accuracy: 0.9923 - val_loss: 0.1085 - val_accuracy: 0.9862\n",
            "Epoch 1373/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.1042 - val_accuracy: 0.9885\n",
            "Epoch 1374/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.1016 - val_accuracy: 0.9885\n",
            "Epoch 1375/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.1010 - val_accuracy: 0.9885\n",
            "Epoch 1376/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.1089 - val_accuracy: 0.9869\n",
            "Epoch 1377/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 0.1023 - val_accuracy: 0.9885\n",
            "Epoch 1378/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.1014 - val_accuracy: 0.9869\n",
            "Epoch 1379/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.1120 - val_accuracy: 0.9862\n",
            "Epoch 1380/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.1093 - val_accuracy: 0.9854\n",
            "Epoch 1381/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.1053 - val_accuracy: 0.9862\n",
            "Epoch 1382/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.1007 - val_accuracy: 0.9885\n",
            "Epoch 1383/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.1021 - val_accuracy: 0.9885\n",
            "Epoch 1384/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0179 - accuracy: 0.9949 - val_loss: 0.1023 - val_accuracy: 0.9877\n",
            "Epoch 1385/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.9902 - val_loss: 0.1049 - val_accuracy: 0.9885\n",
            "Epoch 1386/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0213 - accuracy: 0.9931 - val_loss: 0.1124 - val_accuracy: 0.9862\n",
            "Epoch 1387/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0207 - accuracy: 0.9946 - val_loss: 0.1102 - val_accuracy: 0.9846\n",
            "Epoch 1388/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0215 - accuracy: 0.9931 - val_loss: 0.1167 - val_accuracy: 0.9838\n",
            "Epoch 1389/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0204 - accuracy: 0.9938 - val_loss: 0.1070 - val_accuracy: 0.9877\n",
            "Epoch 1390/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.1038 - val_accuracy: 0.9892\n",
            "Epoch 1391/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0166 - accuracy: 0.9954 - val_loss: 0.1017 - val_accuracy: 0.9885\n",
            "Epoch 1392/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0167 - accuracy: 0.9954 - val_loss: 0.1042 - val_accuracy: 0.9892\n",
            "Epoch 1393/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.1027 - val_accuracy: 0.9885\n",
            "Epoch 1394/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0172 - accuracy: 0.9956 - val_loss: 0.1009 - val_accuracy: 0.9885\n",
            "Epoch 1395/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.1037 - val_accuracy: 0.9885\n",
            "Epoch 1396/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.1053 - val_accuracy: 0.9885\n",
            "Epoch 1397/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.1027 - val_accuracy: 0.9885\n",
            "Epoch 1398/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.1037 - val_accuracy: 0.9885\n",
            "Epoch 1399/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0165 - accuracy: 0.9962 - val_loss: 0.1032 - val_accuracy: 0.9877\n",
            "Epoch 1400/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.1015 - val_accuracy: 0.9885\n",
            "Epoch 1401/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0169 - accuracy: 0.9956 - val_loss: 0.1064 - val_accuracy: 0.9869\n",
            "Epoch 1402/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 0.1025 - val_accuracy: 0.9885\n",
            "Epoch 1403/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.1106 - val_accuracy: 0.9869\n",
            "Epoch 1404/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0182 - accuracy: 0.9949 - val_loss: 0.1098 - val_accuracy: 0.9869\n",
            "Epoch 1405/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0185 - accuracy: 0.9949 - val_loss: 0.1070 - val_accuracy: 0.9869\n",
            "Epoch 1406/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0177 - accuracy: 0.9956 - val_loss: 0.1029 - val_accuracy: 0.9885\n",
            "Epoch 1407/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.1038 - val_accuracy: 0.9885\n",
            "Epoch 1408/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.1033 - val_accuracy: 0.9885\n",
            "Epoch 1409/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.1059 - val_accuracy: 0.9877\n",
            "Epoch 1410/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.1063 - val_accuracy: 0.9885\n",
            "Epoch 1411/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0184 - accuracy: 0.9949 - val_loss: 0.1010 - val_accuracy: 0.9869\n",
            "Epoch 1412/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 0.1056 - val_accuracy: 0.9892\n",
            "Epoch 1413/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 0.1041 - val_accuracy: 0.9885\n",
            "Epoch 1414/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.1027 - val_accuracy: 0.9869\n",
            "Epoch 1415/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 0.9931 - val_loss: 0.1043 - val_accuracy: 0.9885\n",
            "Epoch 1416/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0228 - accuracy: 0.9928 - val_loss: 0.1067 - val_accuracy: 0.9869\n",
            "Epoch 1417/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.1104 - val_accuracy: 0.9854\n",
            "Epoch 1418/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.1045 - val_accuracy: 0.9877\n",
            "Epoch 1419/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9946 - val_loss: 0.1061 - val_accuracy: 0.9877\n",
            "Epoch 1420/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.1036 - val_accuracy: 0.9877\n",
            "Epoch 1421/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0218 - accuracy: 0.9918 - val_loss: 0.1117 - val_accuracy: 0.9846\n",
            "Epoch 1422/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0335 - accuracy: 0.9885 - val_loss: 0.1075 - val_accuracy: 0.9877\n",
            "Epoch 1423/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9941 - val_loss: 0.1089 - val_accuracy: 0.9869\n",
            "Epoch 1424/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9946 - val_loss: 0.1112 - val_accuracy: 0.9854\n",
            "Epoch 1425/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.1019 - val_accuracy: 0.9869\n",
            "Epoch 1426/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.1056 - val_accuracy: 0.9885\n",
            "Epoch 1427/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.1055 - val_accuracy: 0.9877\n",
            "Epoch 1428/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0178 - accuracy: 0.9949 - val_loss: 0.1077 - val_accuracy: 0.9885\n",
            "Epoch 1429/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.1081 - val_accuracy: 0.9862\n",
            "Epoch 1430/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.1080 - val_accuracy: 0.9862\n",
            "Epoch 1431/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9949 - val_loss: 0.1113 - val_accuracy: 0.9862\n",
            "Epoch 1432/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0180 - accuracy: 0.9946 - val_loss: 0.1060 - val_accuracy: 0.9892\n",
            "Epoch 1433/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 0.9949 - val_loss: 0.1059 - val_accuracy: 0.9885\n",
            "Epoch 1434/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9938 - val_loss: 0.1042 - val_accuracy: 0.9892\n",
            "Epoch 1435/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.1039 - val_accuracy: 0.9877\n",
            "Epoch 1436/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9956 - val_loss: 0.1052 - val_accuracy: 0.9885\n",
            "Epoch 1437/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.1047 - val_accuracy: 0.9885\n",
            "Epoch 1438/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0212 - accuracy: 0.9920 - val_loss: 0.1056 - val_accuracy: 0.9892\n",
            "Epoch 1439/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.1143 - val_accuracy: 0.9862\n",
            "Epoch 1440/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 0.9941 - val_loss: 0.1184 - val_accuracy: 0.9846\n",
            "Epoch 1441/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0208 - accuracy: 0.9926 - val_loss: 0.1093 - val_accuracy: 0.9862\n",
            "Epoch 1442/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0208 - accuracy: 0.9938 - val_loss: 0.1040 - val_accuracy: 0.9885\n",
            "Epoch 1443/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.1042 - val_accuracy: 0.9892\n",
            "Epoch 1444/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9959 - val_loss: 0.1122 - val_accuracy: 0.9862\n",
            "Epoch 1445/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9936 - val_loss: 0.1052 - val_accuracy: 0.9885\n",
            "Epoch 1446/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.1060 - val_accuracy: 0.9862\n",
            "Epoch 1447/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.1134 - val_accuracy: 0.9862\n",
            "Epoch 1448/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.1054 - val_accuracy: 0.9892\n",
            "Epoch 1449/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 0.1013 - val_accuracy: 0.9877\n",
            "Epoch 1450/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.1099 - val_accuracy: 0.9854\n",
            "Epoch 1451/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.1135 - val_accuracy: 0.9862\n",
            "Epoch 1452/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9949 - val_loss: 0.1075 - val_accuracy: 0.9885\n",
            "Epoch 1453/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0196 - accuracy: 0.9941 - val_loss: 0.1187 - val_accuracy: 0.9831\n",
            "Epoch 1454/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.1040 - val_accuracy: 0.9877\n",
            "Epoch 1455/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0162 - accuracy: 0.9964 - val_loss: 0.1085 - val_accuracy: 0.9877\n",
            "Epoch 1456/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.1064 - val_accuracy: 0.9885\n",
            "Epoch 1457/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9956 - val_loss: 0.1044 - val_accuracy: 0.9885\n",
            "Epoch 1458/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.1051 - val_accuracy: 0.9885\n",
            "Epoch 1459/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0162 - accuracy: 0.9974 - val_loss: 0.1045 - val_accuracy: 0.9885\n",
            "Epoch 1460/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9959 - val_loss: 0.1071 - val_accuracy: 0.9885\n",
            "Epoch 1461/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.1043 - val_accuracy: 0.9885\n",
            "Epoch 1462/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9967 - val_loss: 0.1040 - val_accuracy: 0.9885\n",
            "Epoch 1463/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.1051 - val_accuracy: 0.9877\n",
            "Epoch 1464/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0175 - accuracy: 0.9954 - val_loss: 0.1094 - val_accuracy: 0.9877\n",
            "Epoch 1465/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.9959 - val_loss: 0.1063 - val_accuracy: 0.9885\n",
            "Epoch 1466/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0163 - accuracy: 0.9964 - val_loss: 0.1098 - val_accuracy: 0.9862\n",
            "Epoch 1467/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0180 - accuracy: 0.9949 - val_loss: 0.1074 - val_accuracy: 0.9892\n",
            "Epoch 1468/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.1060 - val_accuracy: 0.9877\n",
            "Epoch 1469/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0167 - accuracy: 0.9956 - val_loss: 0.1114 - val_accuracy: 0.9862\n",
            "Epoch 1470/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.1059 - val_accuracy: 0.9885\n",
            "Epoch 1471/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.1064 - val_accuracy: 0.9885\n",
            "Epoch 1472/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9941 - val_loss: 0.1048 - val_accuracy: 0.9885\n",
            "Epoch 1473/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9959 - val_loss: 0.1074 - val_accuracy: 0.9877\n",
            "Epoch 1474/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0161 - accuracy: 0.9964 - val_loss: 0.1084 - val_accuracy: 0.9885\n",
            "Epoch 1475/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.1059 - val_accuracy: 0.9885\n",
            "Epoch 1476/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.1060 - val_accuracy: 0.9885\n",
            "Epoch 1477/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.1090 - val_accuracy: 0.9885\n",
            "Epoch 1478/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9962 - val_loss: 0.1064 - val_accuracy: 0.9885\n",
            "Epoch 1479/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9964 - val_loss: 0.1102 - val_accuracy: 0.9862\n",
            "Epoch 1480/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0178 - accuracy: 0.9938 - val_loss: 0.1069 - val_accuracy: 0.9877\n",
            "Epoch 1481/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.1052 - val_accuracy: 0.9869\n",
            "Epoch 1482/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9956 - val_loss: 0.1170 - val_accuracy: 0.9862\n",
            "Epoch 1483/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.1079 - val_accuracy: 0.9885\n",
            "Epoch 1484/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.1085 - val_accuracy: 0.9877\n",
            "Epoch 1485/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 0.1058 - val_accuracy: 0.9885\n",
            "Epoch 1486/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0161 - accuracy: 0.9959 - val_loss: 0.1069 - val_accuracy: 0.9877\n",
            "Epoch 1487/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9959 - val_loss: 0.1057 - val_accuracy: 0.9885\n",
            "Epoch 1488/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 0.1104 - val_accuracy: 0.9877\n",
            "Epoch 1489/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.1050 - val_accuracy: 0.9885\n",
            "Epoch 1490/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 0.1042 - val_accuracy: 0.9877\n",
            "Epoch 1491/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0181 - accuracy: 0.9941 - val_loss: 0.1063 - val_accuracy: 0.9885\n",
            "Epoch 1492/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.1090 - val_accuracy: 0.9885\n",
            "Epoch 1493/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 0.1114 - val_accuracy: 0.9877\n",
            "Epoch 1494/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.1058 - val_accuracy: 0.9885\n",
            "Epoch 1495/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.1049 - val_accuracy: 0.9877\n",
            "Epoch 1496/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.1096 - val_accuracy: 0.9885\n",
            "Epoch 1497/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9962 - val_loss: 0.1095 - val_accuracy: 0.9885\n",
            "Epoch 1498/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 0.9941 - val_loss: 0.1127 - val_accuracy: 0.9854\n",
            "Epoch 1499/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0174 - accuracy: 0.9964 - val_loss: 0.1063 - val_accuracy: 0.9885\n",
            "Epoch 1500/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0186 - accuracy: 0.9949 - val_loss: 0.1176 - val_accuracy: 0.9831\n",
            "Epoch 1501/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.1235 - val_accuracy: 0.9838\n",
            "Epoch 1502/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 0.1087 - val_accuracy: 0.9885\n",
            "Epoch 1503/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1061 - val_accuracy: 0.9885\n",
            "Epoch 1504/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.1107 - val_accuracy: 0.9877\n",
            "Epoch 1505/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0167 - accuracy: 0.9956 - val_loss: 0.1140 - val_accuracy: 0.9869\n",
            "Epoch 1506/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9944 - val_loss: 0.1057 - val_accuracy: 0.9877\n",
            "Epoch 1507/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.1069 - val_accuracy: 0.9885\n",
            "Epoch 1508/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9951 - val_loss: 0.1089 - val_accuracy: 0.9885\n",
            "Epoch 1509/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.1108 - val_accuracy: 0.9877\n",
            "Epoch 1510/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.1108 - val_accuracy: 0.9869\n",
            "Epoch 1511/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.9959 - val_loss: 0.1059 - val_accuracy: 0.9877\n",
            "Epoch 1512/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.9959 - val_loss: 0.1060 - val_accuracy: 0.9885\n",
            "Epoch 1513/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0165 - accuracy: 0.9956 - val_loss: 0.1191 - val_accuracy: 0.9854\n",
            "Epoch 1514/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.1125 - val_accuracy: 0.9869\n",
            "Epoch 1515/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.1078 - val_accuracy: 0.9885\n",
            "Epoch 1516/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 0.1101 - val_accuracy: 0.9885\n",
            "Epoch 1517/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0177 - accuracy: 0.9954 - val_loss: 0.1088 - val_accuracy: 0.9885\n",
            "Epoch 1518/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.1051 - val_accuracy: 0.9885\n",
            "Epoch 1519/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.1092 - val_accuracy: 0.9885\n",
            "Epoch 1520/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.1075 - val_accuracy: 0.9885\n",
            "Epoch 1521/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0160 - accuracy: 0.9967 - val_loss: 0.1078 - val_accuracy: 0.9885\n",
            "Epoch 1522/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0171 - accuracy: 0.9967 - val_loss: 0.1067 - val_accuracy: 0.9885\n",
            "Epoch 1523/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.1090 - val_accuracy: 0.9885\n",
            "Epoch 1524/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0164 - accuracy: 0.9959 - val_loss: 0.1081 - val_accuracy: 0.9869\n",
            "Epoch 1525/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9936 - val_loss: 0.1066 - val_accuracy: 0.9877\n",
            "Epoch 1526/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0189 - accuracy: 0.9949 - val_loss: 0.1102 - val_accuracy: 0.9877\n",
            "Epoch 1527/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0175 - accuracy: 0.9951 - val_loss: 0.1091 - val_accuracy: 0.9877\n",
            "Epoch 1528/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0157 - accuracy: 0.9959 - val_loss: 0.1095 - val_accuracy: 0.9885\n",
            "Epoch 1529/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.1106 - val_accuracy: 0.9885\n",
            "Epoch 1530/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0162 - accuracy: 0.9962 - val_loss: 0.1088 - val_accuracy: 0.9885\n",
            "Epoch 1531/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0169 - accuracy: 0.9956 - val_loss: 0.1055 - val_accuracy: 0.9869\n",
            "Epoch 1532/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.1094 - val_accuracy: 0.9885\n",
            "Epoch 1533/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0160 - accuracy: 0.9962 - val_loss: 0.1110 - val_accuracy: 0.9885\n",
            "Epoch 1534/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 0.1082 - val_accuracy: 0.9885\n",
            "Epoch 1535/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0158 - accuracy: 0.9959 - val_loss: 0.1108 - val_accuracy: 0.9877\n",
            "Epoch 1536/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0165 - accuracy: 0.9959 - val_loss: 0.1088 - val_accuracy: 0.9892\n",
            "Epoch 1537/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.1102 - val_accuracy: 0.9877\n",
            "Epoch 1538/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0167 - accuracy: 0.9954 - val_loss: 0.1117 - val_accuracy: 0.9892\n",
            "Epoch 1539/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0155 - accuracy: 0.9964 - val_loss: 0.1071 - val_accuracy: 0.9885\n",
            "Epoch 1540/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.1073 - val_accuracy: 0.9885\n",
            "Epoch 1541/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0181 - accuracy: 0.9949 - val_loss: 0.1069 - val_accuracy: 0.9877\n",
            "Epoch 1542/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 0.9967 - val_loss: 0.1128 - val_accuracy: 0.9885\n",
            "Epoch 1543/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.1110 - val_accuracy: 0.9885\n",
            "Epoch 1544/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.1121 - val_accuracy: 0.9885\n",
            "Epoch 1545/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 0.1087 - val_accuracy: 0.9885\n",
            "Epoch 1546/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0174 - accuracy: 0.9956 - val_loss: 0.1082 - val_accuracy: 0.9877\n",
            "Epoch 1547/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.1112 - val_accuracy: 0.9885\n",
            "Epoch 1548/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0177 - accuracy: 0.9949 - val_loss: 0.1074 - val_accuracy: 0.9877\n",
            "Epoch 1549/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0172 - accuracy: 0.9938 - val_loss: 0.1050 - val_accuracy: 0.9877\n",
            "Epoch 1550/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.1075 - val_accuracy: 0.9892\n",
            "Epoch 1551/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0178 - accuracy: 0.9962 - val_loss: 0.1075 - val_accuracy: 0.9885\n",
            "Epoch 1552/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.1143 - val_accuracy: 0.9869\n",
            "Epoch 1553/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.1091 - val_accuracy: 0.9892\n",
            "Epoch 1554/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.1079 - val_accuracy: 0.9885\n",
            "Epoch 1555/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 0.1074 - val_accuracy: 0.9885\n",
            "Epoch 1556/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.1073 - val_accuracy: 0.9892\n",
            "Epoch 1557/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 0.9949 - val_loss: 0.1071 - val_accuracy: 0.9877\n",
            "Epoch 1558/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0182 - accuracy: 0.9946 - val_loss: 0.1068 - val_accuracy: 0.9877\n",
            "Epoch 1559/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 0.1101 - val_accuracy: 0.9885\n",
            "Epoch 1560/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.1134 - val_accuracy: 0.9862\n",
            "Epoch 1561/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0182 - accuracy: 0.9946 - val_loss: 0.1101 - val_accuracy: 0.9877\n",
            "Epoch 1562/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.1147 - val_accuracy: 0.9877\n",
            "Epoch 1563/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0160 - accuracy: 0.9962 - val_loss: 0.1071 - val_accuracy: 0.9885\n",
            "Epoch 1564/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.1047 - val_accuracy: 0.9869\n",
            "Epoch 1565/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0180 - accuracy: 0.9956 - val_loss: 0.1110 - val_accuracy: 0.9885\n",
            "Epoch 1566/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0202 - accuracy: 0.9944 - val_loss: 0.1161 - val_accuracy: 0.9862\n",
            "Epoch 1567/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.1189 - val_accuracy: 0.9854\n",
            "Epoch 1568/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.1053 - val_accuracy: 0.9877\n",
            "Epoch 1569/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0177 - accuracy: 0.9949 - val_loss: 0.1088 - val_accuracy: 0.9885\n",
            "Epoch 1570/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0162 - accuracy: 0.9959 - val_loss: 0.1078 - val_accuracy: 0.9885\n",
            "Epoch 1571/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0173 - accuracy: 0.9962 - val_loss: 0.1081 - val_accuracy: 0.9877\n",
            "Epoch 1572/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0166 - accuracy: 0.9962 - val_loss: 0.1117 - val_accuracy: 0.9885\n",
            "Epoch 1573/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0171 - accuracy: 0.9956 - val_loss: 0.1094 - val_accuracy: 0.9885\n",
            "Epoch 1574/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0160 - accuracy: 0.9962 - val_loss: 0.1108 - val_accuracy: 0.9885\n",
            "Epoch 1575/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9962 - val_loss: 0.1089 - val_accuracy: 0.9885\n",
            "Epoch 1576/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9959 - val_loss: 0.1058 - val_accuracy: 0.9877\n",
            "Epoch 1577/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 0.1079 - val_accuracy: 0.9877\n",
            "Epoch 1578/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0160 - accuracy: 0.9962 - val_loss: 0.1132 - val_accuracy: 0.9885\n",
            "Epoch 1579/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0157 - accuracy: 0.9967 - val_loss: 0.1084 - val_accuracy: 0.9885\n",
            "Epoch 1580/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9956 - val_loss: 0.1092 - val_accuracy: 0.9885\n",
            "Epoch 1581/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 0.1132 - val_accuracy: 0.9877\n",
            "Epoch 1582/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.1149 - val_accuracy: 0.9862\n",
            "Epoch 1583/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.1093 - val_accuracy: 0.9877\n",
            "Epoch 1584/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.1103 - val_accuracy: 0.9885\n",
            "Epoch 1585/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.1087 - val_accuracy: 0.9885\n",
            "Epoch 1586/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0215 - accuracy: 0.9920 - val_loss: 0.1068 - val_accuracy: 0.9877\n",
            "Epoch 1587/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 0.9936 - val_loss: 0.1098 - val_accuracy: 0.9877\n",
            "Epoch 1588/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0226 - accuracy: 0.9928 - val_loss: 0.1215 - val_accuracy: 0.9831\n",
            "Epoch 1589/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.1096 - val_accuracy: 0.9892\n",
            "Epoch 1590/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9962 - val_loss: 0.1085 - val_accuracy: 0.9885\n",
            "Epoch 1591/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.1074 - val_accuracy: 0.9877\n",
            "Epoch 1592/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.1118 - val_accuracy: 0.9877\n",
            "Epoch 1593/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 0.9956 - val_loss: 0.1111 - val_accuracy: 0.9885\n",
            "Epoch 1594/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9946 - val_loss: 0.1274 - val_accuracy: 0.9838\n",
            "Epoch 1595/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0209 - accuracy: 0.9941 - val_loss: 0.1097 - val_accuracy: 0.9885\n",
            "Epoch 1596/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0158 - accuracy: 0.9959 - val_loss: 0.1082 - val_accuracy: 0.9877\n",
            "Epoch 1597/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.1088 - val_accuracy: 0.9885\n",
            "Epoch 1598/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.1138 - val_accuracy: 0.9862\n",
            "Epoch 1599/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0161 - accuracy: 0.9962 - val_loss: 0.1086 - val_accuracy: 0.9892\n",
            "Epoch 1600/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 0.1079 - val_accuracy: 0.9877\n",
            "Epoch 1601/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 0.9959 - val_loss: 0.1147 - val_accuracy: 0.9885\n",
            "Epoch 1602/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.1104 - val_accuracy: 0.9885\n",
            "Epoch 1603/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.1110 - val_accuracy: 0.9885\n",
            "Epoch 1604/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 0.1089 - val_accuracy: 0.9885\n",
            "Epoch 1605/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9951 - val_loss: 0.1091 - val_accuracy: 0.9885\n",
            "Epoch 1606/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9949 - val_loss: 0.1103 - val_accuracy: 0.9885\n",
            "Epoch 1607/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.1112 - val_accuracy: 0.9885\n",
            "Epoch 1608/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 0.1077 - val_accuracy: 0.9885\n",
            "Epoch 1609/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0158 - accuracy: 0.9959 - val_loss: 0.1120 - val_accuracy: 0.9885\n",
            "Epoch 1610/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.1289 - val_accuracy: 0.9831\n",
            "Epoch 1611/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0255 - accuracy: 0.9900 - val_loss: 0.1183 - val_accuracy: 0.9862\n",
            "Epoch 1612/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0215 - accuracy: 0.9938 - val_loss: 0.1119 - val_accuracy: 0.9885\n",
            "Epoch 1613/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.1099 - val_accuracy: 0.9885\n",
            "Epoch 1614/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0207 - accuracy: 0.9923 - val_loss: 0.1140 - val_accuracy: 0.9877\n",
            "Epoch 1615/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.9959 - val_loss: 0.1152 - val_accuracy: 0.9869\n",
            "Epoch 1616/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.1117 - val_accuracy: 0.9885\n",
            "Epoch 1617/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0172 - accuracy: 0.9954 - val_loss: 0.1070 - val_accuracy: 0.9885\n",
            "Epoch 1618/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.1061 - val_accuracy: 0.9885\n",
            "Epoch 1619/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0158 - accuracy: 0.9959 - val_loss: 0.1083 - val_accuracy: 0.9885\n",
            "Epoch 1620/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9956 - val_loss: 0.1215 - val_accuracy: 0.9838\n",
            "Epoch 1621/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9926 - val_loss: 0.1161 - val_accuracy: 0.9885\n",
            "Epoch 1622/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9949 - val_loss: 0.1102 - val_accuracy: 0.9877\n",
            "Epoch 1623/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 0.1106 - val_accuracy: 0.9885\n",
            "Epoch 1624/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 0.1108 - val_accuracy: 0.9885\n",
            "Epoch 1625/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.1222 - val_accuracy: 0.9862\n",
            "Epoch 1626/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1169 - val_accuracy: 0.9869\n",
            "Epoch 1627/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0188 - accuracy: 0.9956 - val_loss: 0.1096 - val_accuracy: 0.9892\n",
            "Epoch 1628/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 0.1112 - val_accuracy: 0.9885\n",
            "Epoch 1629/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0167 - accuracy: 0.9946 - val_loss: 0.1109 - val_accuracy: 0.9885\n",
            "Epoch 1630/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9949 - val_loss: 0.1140 - val_accuracy: 0.9862\n",
            "Epoch 1631/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9928 - val_loss: 0.1319 - val_accuracy: 0.9831\n",
            "Epoch 1632/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.1195 - val_accuracy: 0.9854\n",
            "Epoch 1633/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9928 - val_loss: 0.1110 - val_accuracy: 0.9877\n",
            "Epoch 1634/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0166 - accuracy: 0.9964 - val_loss: 0.1108 - val_accuracy: 0.9885\n",
            "Epoch 1635/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 0.1114 - val_accuracy: 0.9877\n",
            "Epoch 1636/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9962 - val_loss: 0.1107 - val_accuracy: 0.9885\n",
            "Epoch 1637/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.1109 - val_accuracy: 0.9885\n",
            "Epoch 1638/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0159 - accuracy: 0.9962 - val_loss: 0.1086 - val_accuracy: 0.9877\n",
            "Epoch 1639/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0155 - accuracy: 0.9967 - val_loss: 0.1093 - val_accuracy: 0.9892\n",
            "Epoch 1640/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0153 - accuracy: 0.9964 - val_loss: 0.1092 - val_accuracy: 0.9885\n",
            "Epoch 1641/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.1129 - val_accuracy: 0.9877\n",
            "Epoch 1642/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0164 - accuracy: 0.9964 - val_loss: 0.1099 - val_accuracy: 0.9877\n",
            "Epoch 1643/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0153 - accuracy: 0.9959 - val_loss: 0.1156 - val_accuracy: 0.9877\n",
            "Epoch 1644/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0158 - accuracy: 0.9964 - val_loss: 0.1162 - val_accuracy: 0.9869\n",
            "Epoch 1645/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.1093 - val_accuracy: 0.9885\n",
            "Epoch 1646/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0149 - accuracy: 0.9967 - val_loss: 0.1116 - val_accuracy: 0.9892\n",
            "Epoch 1647/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 0.9967 - val_loss: 0.1107 - val_accuracy: 0.9885\n",
            "Epoch 1648/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0156 - accuracy: 0.9959 - val_loss: 0.1143 - val_accuracy: 0.9885\n",
            "Epoch 1649/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 0.1095 - val_accuracy: 0.9885\n",
            "Epoch 1650/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0151 - accuracy: 0.9967 - val_loss: 0.1096 - val_accuracy: 0.9885\n",
            "Epoch 1651/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.1128 - val_accuracy: 0.9877\n",
            "Epoch 1652/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.1152 - val_accuracy: 0.9877\n",
            "Epoch 1653/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0208 - accuracy: 0.9941 - val_loss: 0.1192 - val_accuracy: 0.9869\n",
            "Epoch 1654/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.1117 - val_accuracy: 0.9885\n",
            "Epoch 1655/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9954 - val_loss: 0.1163 - val_accuracy: 0.9885\n",
            "Epoch 1656/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.1145 - val_accuracy: 0.9885\n",
            "Epoch 1657/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9964 - val_loss: 0.1074 - val_accuracy: 0.9877\n",
            "Epoch 1658/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0158 - accuracy: 0.9959 - val_loss: 0.1078 - val_accuracy: 0.9877\n",
            "Epoch 1659/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 0.9964 - val_loss: 0.1132 - val_accuracy: 0.9885\n",
            "Epoch 1660/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0152 - accuracy: 0.9959 - val_loss: 0.1133 - val_accuracy: 0.9885\n",
            "Epoch 1661/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.1095 - val_accuracy: 0.9877\n",
            "Epoch 1662/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.1083 - val_accuracy: 0.9885\n",
            "Epoch 1663/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9967 - val_loss: 0.1107 - val_accuracy: 0.9885\n",
            "Epoch 1664/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.1110 - val_accuracy: 0.9885\n",
            "Epoch 1665/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0157 - accuracy: 0.9962 - val_loss: 0.1153 - val_accuracy: 0.9885\n",
            "Epoch 1666/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 0.9962 - val_loss: 0.1073 - val_accuracy: 0.9877\n",
            "Epoch 1667/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9967 - val_loss: 0.1089 - val_accuracy: 0.9885\n",
            "Epoch 1668/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 0.9938 - val_loss: 0.1107 - val_accuracy: 0.9885\n",
            "Epoch 1669/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.1247 - val_accuracy: 0.9838\n",
            "Epoch 1670/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 0.1233 - val_accuracy: 0.9862\n",
            "Epoch 1671/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 0.1139 - val_accuracy: 0.9877\n",
            "Epoch 1672/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9959 - val_loss: 0.1080 - val_accuracy: 0.9877\n",
            "Epoch 1673/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.1106 - val_accuracy: 0.9885\n",
            "Epoch 1674/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.1098 - val_accuracy: 0.9885\n",
            "Epoch 1675/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0157 - accuracy: 0.9959 - val_loss: 0.1101 - val_accuracy: 0.9877\n",
            "Epoch 1676/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9962 - val_loss: 0.1111 - val_accuracy: 0.9877\n",
            "Epoch 1677/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.1098 - val_accuracy: 0.9885\n",
            "Epoch 1678/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0158 - accuracy: 0.9959 - val_loss: 0.1091 - val_accuracy: 0.9877\n",
            "Epoch 1679/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0166 - accuracy: 0.9956 - val_loss: 0.1122 - val_accuracy: 0.9877\n",
            "Epoch 1680/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.1099 - val_accuracy: 0.9892\n",
            "Epoch 1681/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9956 - val_loss: 0.1110 - val_accuracy: 0.9885\n",
            "Epoch 1682/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 0.1139 - val_accuracy: 0.9892\n",
            "Epoch 1683/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.1109 - val_accuracy: 0.9877\n",
            "Epoch 1684/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.1178 - val_accuracy: 0.9862\n",
            "Epoch 1685/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0183 - accuracy: 0.9931 - val_loss: 0.1260 - val_accuracy: 0.9854\n",
            "Epoch 1686/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9954 - val_loss: 0.1109 - val_accuracy: 0.9877\n",
            "Epoch 1687/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0169 - accuracy: 0.9962 - val_loss: 0.1092 - val_accuracy: 0.9877\n",
            "Epoch 1688/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0157 - accuracy: 0.9959 - val_loss: 0.1123 - val_accuracy: 0.9885\n",
            "Epoch 1689/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 0.9959 - val_loss: 0.1117 - val_accuracy: 0.9892\n",
            "Epoch 1690/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 0.1112 - val_accuracy: 0.9885\n",
            "Epoch 1691/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0152 - accuracy: 0.9962 - val_loss: 0.1151 - val_accuracy: 0.9885\n",
            "Epoch 1692/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.1149 - val_accuracy: 0.9877\n",
            "Epoch 1693/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.1111 - val_accuracy: 0.9885\n",
            "Epoch 1694/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.1124 - val_accuracy: 0.9892\n",
            "Epoch 1695/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0162 - accuracy: 0.9956 - val_loss: 0.1074 - val_accuracy: 0.9877\n",
            "Epoch 1696/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.1162 - val_accuracy: 0.9869\n",
            "Epoch 1697/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.1159 - val_accuracy: 0.9877\n",
            "Epoch 1698/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0161 - accuracy: 0.9962 - val_loss: 0.1197 - val_accuracy: 0.9869\n",
            "Epoch 1699/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.1129 - val_accuracy: 0.9892\n",
            "Epoch 1700/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0160 - accuracy: 0.9964 - val_loss: 0.1109 - val_accuracy: 0.9877\n",
            "Epoch 1701/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 0.1111 - val_accuracy: 0.9885\n",
            "Epoch 1702/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0154 - accuracy: 0.9964 - val_loss: 0.1115 - val_accuracy: 0.9885\n",
            "Epoch 1703/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.1139 - val_accuracy: 0.9885\n",
            "Epoch 1704/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 0.1168 - val_accuracy: 0.9877\n",
            "Epoch 1705/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0159 - accuracy: 0.9962 - val_loss: 0.1143 - val_accuracy: 0.9885\n",
            "Epoch 1706/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0163 - accuracy: 0.9959 - val_loss: 0.1107 - val_accuracy: 0.9877\n",
            "Epoch 1707/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0179 - accuracy: 0.9956 - val_loss: 0.1110 - val_accuracy: 0.9877\n",
            "Epoch 1708/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0175 - accuracy: 0.9941 - val_loss: 0.1086 - val_accuracy: 0.9869\n",
            "Epoch 1709/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.1129 - val_accuracy: 0.9885\n",
            "Epoch 1710/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0190 - accuracy: 0.9946 - val_loss: 0.1146 - val_accuracy: 0.9885\n",
            "Epoch 1711/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0177 - accuracy: 0.9956 - val_loss: 0.1096 - val_accuracy: 0.9877\n",
            "Epoch 1712/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.1148 - val_accuracy: 0.9885\n",
            "Epoch 1713/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0161 - accuracy: 0.9962 - val_loss: 0.1132 - val_accuracy: 0.9892\n",
            "Epoch 1714/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0149 - accuracy: 0.9964 - val_loss: 0.1137 - val_accuracy: 0.9885\n",
            "Epoch 1715/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.1109 - val_accuracy: 0.9877\n",
            "Epoch 1716/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.1121 - val_accuracy: 0.9877\n",
            "Epoch 1717/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0160 - accuracy: 0.9959 - val_loss: 0.1199 - val_accuracy: 0.9877\n",
            "Epoch 1718/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9959 - val_loss: 0.1134 - val_accuracy: 0.9892\n",
            "Epoch 1719/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 0.1133 - val_accuracy: 0.9885\n",
            "Epoch 1720/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.1133 - val_accuracy: 0.9892\n",
            "Epoch 1721/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 0.1121 - val_accuracy: 0.9885\n",
            "Epoch 1722/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.9967 - val_loss: 0.1158 - val_accuracy: 0.9877\n",
            "Epoch 1723/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0152 - accuracy: 0.9959 - val_loss: 0.1133 - val_accuracy: 0.9885\n",
            "Epoch 1724/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9962 - val_loss: 0.1120 - val_accuracy: 0.9885\n",
            "Epoch 1725/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.1156 - val_accuracy: 0.9885\n",
            "Epoch 1726/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0154 - accuracy: 0.9959 - val_loss: 0.1141 - val_accuracy: 0.9892\n",
            "Epoch 1727/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.1146 - val_accuracy: 0.9885\n",
            "Epoch 1728/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0150 - accuracy: 0.9962 - val_loss: 0.1116 - val_accuracy: 0.9885\n",
            "Epoch 1729/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0147 - accuracy: 0.9972 - val_loss: 0.1112 - val_accuracy: 0.9885\n",
            "Epoch 1730/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.1150 - val_accuracy: 0.9885\n",
            "Epoch 1731/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0196 - accuracy: 0.9944 - val_loss: 0.1106 - val_accuracy: 0.9869\n",
            "Epoch 1732/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 0.1206 - val_accuracy: 0.9869\n",
            "Epoch 1733/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9923 - val_loss: 0.1111 - val_accuracy: 0.9869\n",
            "Epoch 1734/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9962 - val_loss: 0.1316 - val_accuracy: 0.9831\n",
            "Epoch 1735/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 0.9920 - val_loss: 0.1177 - val_accuracy: 0.9892\n",
            "Epoch 1736/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0181 - accuracy: 0.9933 - val_loss: 0.1106 - val_accuracy: 0.9885\n",
            "Epoch 1737/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0192 - accuracy: 0.9931 - val_loss: 0.1128 - val_accuracy: 0.9877\n",
            "Epoch 1738/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0184 - accuracy: 0.9946 - val_loss: 0.1116 - val_accuracy: 0.9885\n",
            "Epoch 1739/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0195 - accuracy: 0.9926 - val_loss: 0.1123 - val_accuracy: 0.9892\n",
            "Epoch 1740/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0177 - accuracy: 0.9949 - val_loss: 0.1169 - val_accuracy: 0.9877\n",
            "Epoch 1741/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.1183 - val_accuracy: 0.9877\n",
            "Epoch 1742/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0174 - accuracy: 0.9959 - val_loss: 0.1161 - val_accuracy: 0.9877\n",
            "Epoch 1743/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.1141 - val_accuracy: 0.9885\n",
            "Epoch 1744/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0157 - accuracy: 0.9962 - val_loss: 0.1123 - val_accuracy: 0.9885\n",
            "Epoch 1745/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0150 - accuracy: 0.9967 - val_loss: 0.1109 - val_accuracy: 0.9877\n",
            "Epoch 1746/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9964 - val_loss: 0.1159 - val_accuracy: 0.9892\n",
            "Epoch 1747/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.1158 - val_accuracy: 0.9892\n",
            "Epoch 1748/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0158 - accuracy: 0.9974 - val_loss: 0.1117 - val_accuracy: 0.9892\n",
            "Epoch 1749/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0151 - accuracy: 0.9964 - val_loss: 0.1121 - val_accuracy: 0.9885\n",
            "Epoch 1750/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0150 - accuracy: 0.9967 - val_loss: 0.1134 - val_accuracy: 0.9885\n",
            "Epoch 1751/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.1118 - val_accuracy: 0.9877\n",
            "Epoch 1752/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9938 - val_loss: 0.1121 - val_accuracy: 0.9877\n",
            "Epoch 1753/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9959 - val_loss: 0.1171 - val_accuracy: 0.9869\n",
            "Epoch 1754/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0162 - accuracy: 0.9956 - val_loss: 0.1179 - val_accuracy: 0.9869\n",
            "Epoch 1755/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0158 - accuracy: 0.9962 - val_loss: 0.1172 - val_accuracy: 0.9885\n",
            "Epoch 1756/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9959 - val_loss: 0.1133 - val_accuracy: 0.9892\n",
            "Epoch 1757/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9967 - val_loss: 0.1133 - val_accuracy: 0.9885\n",
            "Epoch 1758/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9956 - val_loss: 0.1146 - val_accuracy: 0.9885\n",
            "Epoch 1759/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 0.1112 - val_accuracy: 0.9877\n",
            "Epoch 1760/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0150 - accuracy: 0.9962 - val_loss: 0.1160 - val_accuracy: 0.9892\n",
            "Epoch 1761/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0151 - accuracy: 0.9967 - val_loss: 0.1122 - val_accuracy: 0.9877\n",
            "Epoch 1762/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9956 - val_loss: 0.1175 - val_accuracy: 0.9877\n",
            "Epoch 1763/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9959 - val_loss: 0.1169 - val_accuracy: 0.9885\n",
            "Epoch 1764/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0154 - accuracy: 0.9967 - val_loss: 0.1151 - val_accuracy: 0.9877\n",
            "Epoch 1765/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9969 - val_loss: 0.1212 - val_accuracy: 0.9862\n",
            "Epoch 1766/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0155 - accuracy: 0.9964 - val_loss: 0.1149 - val_accuracy: 0.9885\n",
            "Epoch 1767/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9959 - val_loss: 0.1134 - val_accuracy: 0.9885\n",
            "Epoch 1768/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 0.9959 - val_loss: 0.1167 - val_accuracy: 0.9885\n",
            "Epoch 1769/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.1112 - val_accuracy: 0.9877\n",
            "Epoch 1770/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0151 - accuracy: 0.9964 - val_loss: 0.1147 - val_accuracy: 0.9885\n",
            "Epoch 1771/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9972 - val_loss: 0.1157 - val_accuracy: 0.9885\n",
            "Epoch 1772/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9974 - val_loss: 0.1184 - val_accuracy: 0.9885\n",
            "Epoch 1773/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.9964 - val_loss: 0.1184 - val_accuracy: 0.9885\n",
            "Epoch 1774/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9964 - val_loss: 0.1188 - val_accuracy: 0.9877\n",
            "Epoch 1775/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.1171 - val_accuracy: 0.9885\n",
            "Epoch 1776/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 0.9964 - val_loss: 0.1171 - val_accuracy: 0.9885\n",
            "Epoch 1777/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0150 - accuracy: 0.9962 - val_loss: 0.1135 - val_accuracy: 0.9892\n",
            "Epoch 1778/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9954 - val_loss: 0.1168 - val_accuracy: 0.9885\n",
            "Epoch 1779/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.1137 - val_accuracy: 0.9877\n",
            "Epoch 1780/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 0.9959 - val_loss: 0.1164 - val_accuracy: 0.9885\n",
            "Epoch 1781/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9964 - val_loss: 0.1142 - val_accuracy: 0.9885\n",
            "Epoch 1782/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.1115 - val_accuracy: 0.9885\n",
            "Epoch 1783/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.1134 - val_accuracy: 0.9885\n",
            "Epoch 1784/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 0.9928 - val_loss: 0.1187 - val_accuracy: 0.9885\n",
            "Epoch 1785/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0183 - accuracy: 0.9954 - val_loss: 0.1163 - val_accuracy: 0.9877\n",
            "Epoch 1786/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0154 - accuracy: 0.9964 - val_loss: 0.1132 - val_accuracy: 0.9877\n",
            "Epoch 1787/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0154 - accuracy: 0.9959 - val_loss: 0.1217 - val_accuracy: 0.9854\n",
            "Epoch 1788/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9959 - val_loss: 0.1160 - val_accuracy: 0.9885\n",
            "Epoch 1789/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.1146 - val_accuracy: 0.9869\n",
            "Epoch 1790/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 0.1124 - val_accuracy: 0.9877\n",
            "Epoch 1791/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 0.1148 - val_accuracy: 0.9885\n",
            "Epoch 1792/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9964 - val_loss: 0.1137 - val_accuracy: 0.9885\n",
            "Epoch 1793/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0175 - accuracy: 0.9959 - val_loss: 0.1147 - val_accuracy: 0.9885\n",
            "Epoch 1794/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 0.9954 - val_loss: 0.1233 - val_accuracy: 0.9854\n",
            "Epoch 1795/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0233 - accuracy: 0.9905 - val_loss: 0.1390 - val_accuracy: 0.9823\n",
            "Epoch 1796/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9918 - val_loss: 0.1223 - val_accuracy: 0.9869\n",
            "Epoch 1797/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.1189 - val_accuracy: 0.9877\n",
            "Epoch 1798/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9949 - val_loss: 0.1173 - val_accuracy: 0.9877\n",
            "Epoch 1799/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0158 - accuracy: 0.9964 - val_loss: 0.1138 - val_accuracy: 0.9885\n",
            "Epoch 1800/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0179 - accuracy: 0.9956 - val_loss: 0.1146 - val_accuracy: 0.9877\n",
            "Epoch 1801/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.1277 - val_accuracy: 0.9862\n",
            "Epoch 1802/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9944 - val_loss: 0.1250 - val_accuracy: 0.9854\n",
            "Epoch 1803/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.1165 - val_accuracy: 0.9885\n",
            "Epoch 1804/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 0.9959 - val_loss: 0.1158 - val_accuracy: 0.9892\n",
            "Epoch 1805/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0154 - accuracy: 0.9969 - val_loss: 0.1130 - val_accuracy: 0.9885\n",
            "Epoch 1806/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.1154 - val_accuracy: 0.9885\n",
            "Epoch 1807/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9959 - val_loss: 0.1173 - val_accuracy: 0.9892\n",
            "Epoch 1808/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0155 - accuracy: 0.9956 - val_loss: 0.1189 - val_accuracy: 0.9885\n",
            "Epoch 1809/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0163 - accuracy: 0.9964 - val_loss: 0.1148 - val_accuracy: 0.9885\n",
            "Epoch 1810/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.1146 - val_accuracy: 0.9885\n",
            "Epoch 1811/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0157 - accuracy: 0.9967 - val_loss: 0.1174 - val_accuracy: 0.9885\n",
            "Epoch 1812/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0147 - accuracy: 0.9967 - val_loss: 0.1204 - val_accuracy: 0.9877\n",
            "Epoch 1813/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0148 - accuracy: 0.9967 - val_loss: 0.1128 - val_accuracy: 0.9877\n",
            "Epoch 1814/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9964 - val_loss: 0.1218 - val_accuracy: 0.9877\n",
            "Epoch 1815/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0156 - accuracy: 0.9964 - val_loss: 0.1159 - val_accuracy: 0.9892\n",
            "Epoch 1816/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0156 - accuracy: 0.9959 - val_loss: 0.1178 - val_accuracy: 0.9885\n",
            "Epoch 1817/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 0.9949 - val_loss: 0.1182 - val_accuracy: 0.9892\n",
            "Epoch 1818/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.1156 - val_accuracy: 0.9877\n",
            "Epoch 1819/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0144 - accuracy: 0.9962 - val_loss: 0.1213 - val_accuracy: 0.9877\n",
            "Epoch 1820/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.1170 - val_accuracy: 0.9885\n",
            "Epoch 1821/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0161 - accuracy: 0.9959 - val_loss: 0.1150 - val_accuracy: 0.9885\n",
            "Epoch 1822/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0144 - accuracy: 0.9967 - val_loss: 0.1148 - val_accuracy: 0.9877\n",
            "Epoch 1823/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.1130 - val_accuracy: 0.9892\n",
            "Epoch 1824/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 0.1148 - val_accuracy: 0.9892\n",
            "Epoch 1825/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9962 - val_loss: 0.1157 - val_accuracy: 0.9885\n",
            "Epoch 1826/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.1165 - val_accuracy: 0.9885\n",
            "Epoch 1827/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0147 - accuracy: 0.9967 - val_loss: 0.1136 - val_accuracy: 0.9885\n",
            "Epoch 1828/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0145 - accuracy: 0.9972 - val_loss: 0.1137 - val_accuracy: 0.9877\n",
            "Epoch 1829/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0147 - accuracy: 0.9964 - val_loss: 0.1178 - val_accuracy: 0.9885\n",
            "Epoch 1830/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0151 - accuracy: 0.9962 - val_loss: 0.1218 - val_accuracy: 0.9877\n",
            "Epoch 1831/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.1165 - val_accuracy: 0.9877\n",
            "Epoch 1832/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0144 - accuracy: 0.9972 - val_loss: 0.1154 - val_accuracy: 0.9885\n",
            "Epoch 1833/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0144 - accuracy: 0.9962 - val_loss: 0.1150 - val_accuracy: 0.9885\n",
            "Epoch 1834/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9967 - val_loss: 0.1136 - val_accuracy: 0.9885\n",
            "Epoch 1835/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.1154 - val_accuracy: 0.9885\n",
            "Epoch 1836/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0176 - accuracy: 0.9959 - val_loss: 0.1135 - val_accuracy: 0.9877\n",
            "Epoch 1837/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.1215 - val_accuracy: 0.9877\n",
            "Epoch 1838/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0157 - accuracy: 0.9956 - val_loss: 0.1186 - val_accuracy: 0.9885\n",
            "Epoch 1839/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0145 - accuracy: 0.9967 - val_loss: 0.1197 - val_accuracy: 0.9885\n",
            "Epoch 1840/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0162 - accuracy: 0.9959 - val_loss: 0.1194 - val_accuracy: 0.9885\n",
            "Epoch 1841/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.1222 - val_accuracy: 0.9869\n",
            "Epoch 1842/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.1159 - val_accuracy: 0.9885\n",
            "Epoch 1843/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0152 - accuracy: 0.9972 - val_loss: 0.1183 - val_accuracy: 0.9885\n",
            "Epoch 1844/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.1163 - val_accuracy: 0.9885\n",
            "Epoch 1845/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0145 - accuracy: 0.9972 - val_loss: 0.1130 - val_accuracy: 0.9877\n",
            "Epoch 1846/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.1133 - val_accuracy: 0.9877\n",
            "Epoch 1847/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0147 - accuracy: 0.9967 - val_loss: 0.1167 - val_accuracy: 0.9885\n",
            "Epoch 1848/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0144 - accuracy: 0.9964 - val_loss: 0.1200 - val_accuracy: 0.9885\n",
            "Epoch 1849/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0153 - accuracy: 0.9962 - val_loss: 0.1156 - val_accuracy: 0.9877\n",
            "Epoch 1850/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9962 - val_loss: 0.1189 - val_accuracy: 0.9885\n",
            "Epoch 1851/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0153 - accuracy: 0.9962 - val_loss: 0.1154 - val_accuracy: 0.9877\n",
            "Epoch 1852/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0145 - accuracy: 0.9974 - val_loss: 0.1158 - val_accuracy: 0.9885\n",
            "Epoch 1853/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0151 - accuracy: 0.9964 - val_loss: 0.1160 - val_accuracy: 0.9877\n",
            "Epoch 1854/2000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 0.1169 - val_accuracy: 0.9885\n",
            "Epoch 1855/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0157 - accuracy: 0.9959 - val_loss: 0.1130 - val_accuracy: 0.9877\n",
            "Epoch 1856/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0179 - accuracy: 0.9949 - val_loss: 0.1180 - val_accuracy: 0.9877\n",
            "Epoch 1857/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.1154 - val_accuracy: 0.9877\n",
            "Epoch 1858/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.1256 - val_accuracy: 0.9869\n",
            "Epoch 1859/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0161 - accuracy: 0.9964 - val_loss: 0.1198 - val_accuracy: 0.9869\n",
            "Epoch 1860/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0171 - accuracy: 0.9956 - val_loss: 0.1151 - val_accuracy: 0.9885\n",
            "Epoch 1861/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.1135 - val_accuracy: 0.9877\n",
            "Epoch 1862/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9964 - val_loss: 0.1163 - val_accuracy: 0.9877\n",
            "Epoch 1863/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0142 - accuracy: 0.9967 - val_loss: 0.1170 - val_accuracy: 0.9885\n",
            "Epoch 1864/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.1190 - val_accuracy: 0.9892\n",
            "Epoch 1865/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0187 - accuracy: 0.9949 - val_loss: 0.1161 - val_accuracy: 0.9877\n",
            "Epoch 1866/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0144 - accuracy: 0.9964 - val_loss: 0.1182 - val_accuracy: 0.9877\n",
            "Epoch 1867/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0179 - accuracy: 0.9954 - val_loss: 0.1204 - val_accuracy: 0.9885\n",
            "Epoch 1868/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 0.1222 - val_accuracy: 0.9885\n",
            "Epoch 1869/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.1232 - val_accuracy: 0.9854\n",
            "Epoch 1870/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.1231 - val_accuracy: 0.9869\n",
            "Epoch 1871/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 0.1184 - val_accuracy: 0.9885\n",
            "Epoch 1872/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9967 - val_loss: 0.1155 - val_accuracy: 0.9885\n",
            "Epoch 1873/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.9967 - val_loss: 0.1150 - val_accuracy: 0.9877\n",
            "Epoch 1874/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0147 - accuracy: 0.9964 - val_loss: 0.1156 - val_accuracy: 0.9877\n",
            "Epoch 1875/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.1174 - val_accuracy: 0.9885\n",
            "Epoch 1876/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0151 - accuracy: 0.9972 - val_loss: 0.1208 - val_accuracy: 0.9885\n",
            "Epoch 1877/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 0.9962 - val_loss: 0.1227 - val_accuracy: 0.9877\n",
            "Epoch 1878/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0161 - accuracy: 0.9959 - val_loss: 0.1176 - val_accuracy: 0.9877\n",
            "Epoch 1879/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.1156 - val_accuracy: 0.9885\n",
            "Epoch 1880/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9962 - val_loss: 0.1178 - val_accuracy: 0.9885\n",
            "Epoch 1881/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.1242 - val_accuracy: 0.9862\n",
            "Epoch 1882/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.1195 - val_accuracy: 0.9885\n",
            "Epoch 1883/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0146 - accuracy: 0.9967 - val_loss: 0.1177 - val_accuracy: 0.9892\n",
            "Epoch 1884/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9967 - val_loss: 0.1172 - val_accuracy: 0.9885\n",
            "Epoch 1885/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.1192 - val_accuracy: 0.9885\n",
            "Epoch 1886/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9962 - val_loss: 0.1180 - val_accuracy: 0.9885\n",
            "Epoch 1887/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 0.1174 - val_accuracy: 0.9885\n",
            "Epoch 1888/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9967 - val_loss: 0.1201 - val_accuracy: 0.9892\n",
            "Epoch 1889/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9959 - val_loss: 0.1198 - val_accuracy: 0.9877\n",
            "Epoch 1890/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 0.9967 - val_loss: 0.1154 - val_accuracy: 0.9877\n",
            "Epoch 1891/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.1185 - val_accuracy: 0.9892\n",
            "Epoch 1892/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.1182 - val_accuracy: 0.9885\n",
            "Epoch 1893/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0143 - accuracy: 0.9967 - val_loss: 0.1225 - val_accuracy: 0.9885\n",
            "Epoch 1894/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9962 - val_loss: 0.1155 - val_accuracy: 0.9877\n",
            "Epoch 1895/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9967 - val_loss: 0.1161 - val_accuracy: 0.9885\n",
            "Epoch 1896/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.1176 - val_accuracy: 0.9877\n",
            "Epoch 1897/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.1173 - val_accuracy: 0.9885\n",
            "Epoch 1898/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0141 - accuracy: 0.9977 - val_loss: 0.1178 - val_accuracy: 0.9885\n",
            "Epoch 1899/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.1172 - val_accuracy: 0.9885\n",
            "Epoch 1900/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.1173 - val_accuracy: 0.9892\n",
            "Epoch 1901/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.1209 - val_accuracy: 0.9869\n",
            "Epoch 1902/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0216 - accuracy: 0.9923 - val_loss: 0.1212 - val_accuracy: 0.9885\n",
            "Epoch 1903/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0252 - accuracy: 0.9918 - val_loss: 0.1231 - val_accuracy: 0.9869\n",
            "Epoch 1904/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0228 - accuracy: 0.9918 - val_loss: 0.1191 - val_accuracy: 0.9892\n",
            "Epoch 1905/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.1288 - val_accuracy: 0.9846\n",
            "Epoch 1906/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0190 - accuracy: 0.9949 - val_loss: 0.1281 - val_accuracy: 0.9854\n",
            "Epoch 1907/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0175 - accuracy: 0.9951 - val_loss: 0.1173 - val_accuracy: 0.9885\n",
            "Epoch 1908/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0150 - accuracy: 0.9967 - val_loss: 0.1184 - val_accuracy: 0.9885\n",
            "Epoch 1909/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9962 - val_loss: 0.1145 - val_accuracy: 0.9885\n",
            "Epoch 1910/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.1166 - val_accuracy: 0.9885\n",
            "Epoch 1911/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9967 - val_loss: 0.1173 - val_accuracy: 0.9877\n",
            "Epoch 1912/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0144 - accuracy: 0.9964 - val_loss: 0.1167 - val_accuracy: 0.9877\n",
            "Epoch 1913/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 0.1219 - val_accuracy: 0.9869\n",
            "Epoch 1914/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 0.1248 - val_accuracy: 0.9862\n",
            "Epoch 1915/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.1178 - val_accuracy: 0.9885\n",
            "Epoch 1916/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0160 - accuracy: 0.9956 - val_loss: 0.1189 - val_accuracy: 0.9885\n",
            "Epoch 1917/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.1184 - val_accuracy: 0.9885\n",
            "Epoch 1918/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0170 - accuracy: 0.9962 - val_loss: 0.1212 - val_accuracy: 0.9877\n",
            "Epoch 1919/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0144 - accuracy: 0.9962 - val_loss: 0.1198 - val_accuracy: 0.9892\n",
            "Epoch 1920/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.1183 - val_accuracy: 0.9885\n",
            "Epoch 1921/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 0.1183 - val_accuracy: 0.9885\n",
            "Epoch 1922/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.1164 - val_accuracy: 0.9877\n",
            "Epoch 1923/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.1175 - val_accuracy: 0.9885\n",
            "Epoch 1924/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.9974 - val_loss: 0.1179 - val_accuracy: 0.9885\n",
            "Epoch 1925/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.1214 - val_accuracy: 0.9885\n",
            "Epoch 1926/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 0.1180 - val_accuracy: 0.9877\n",
            "Epoch 1927/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.1184 - val_accuracy: 0.9885\n",
            "Epoch 1928/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 0.1239 - val_accuracy: 0.9877\n",
            "Epoch 1929/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.1178 - val_accuracy: 0.9885\n",
            "Epoch 1930/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0190 - accuracy: 0.9944 - val_loss: 0.1157 - val_accuracy: 0.9885\n",
            "Epoch 1931/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9962 - val_loss: 0.1162 - val_accuracy: 0.9885\n",
            "Epoch 1932/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 0.1177 - val_accuracy: 0.9885\n",
            "Epoch 1933/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0154 - accuracy: 0.9967 - val_loss: 0.1179 - val_accuracy: 0.9877\n",
            "Epoch 1934/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 0.1169 - val_accuracy: 0.9885\n",
            "Epoch 1935/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.9964 - val_loss: 0.1181 - val_accuracy: 0.9885\n",
            "Epoch 1936/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0141 - accuracy: 0.9967 - val_loss: 0.1181 - val_accuracy: 0.9885\n",
            "Epoch 1937/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9962 - val_loss: 0.1249 - val_accuracy: 0.9877\n",
            "Epoch 1938/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.1214 - val_accuracy: 0.9869\n",
            "Epoch 1939/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9974 - val_loss: 0.1195 - val_accuracy: 0.9885\n",
            "Epoch 1940/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.1230 - val_accuracy: 0.9877\n",
            "Epoch 1941/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 0.1173 - val_accuracy: 0.9877\n",
            "Epoch 1942/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 0.9938 - val_loss: 0.1225 - val_accuracy: 0.9869\n",
            "Epoch 1943/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0187 - accuracy: 0.9931 - val_loss: 0.1169 - val_accuracy: 0.9877\n",
            "Epoch 1944/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0171 - accuracy: 0.9956 - val_loss: 0.1183 - val_accuracy: 0.9885\n",
            "Epoch 1945/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 0.1178 - val_accuracy: 0.9885\n",
            "Epoch 1946/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0139 - accuracy: 0.9967 - val_loss: 0.1237 - val_accuracy: 0.9877\n",
            "Epoch 1947/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0141 - accuracy: 0.9964 - val_loss: 0.1163 - val_accuracy: 0.9877\n",
            "Epoch 1948/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 0.1167 - val_accuracy: 0.9877\n",
            "Epoch 1949/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 0.1185 - val_accuracy: 0.9892\n",
            "Epoch 1950/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.1213 - val_accuracy: 0.9885\n",
            "Epoch 1951/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0153 - accuracy: 0.9959 - val_loss: 0.1240 - val_accuracy: 0.9885\n",
            "Epoch 1952/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0170 - accuracy: 0.9959 - val_loss: 0.1240 - val_accuracy: 0.9869\n",
            "Epoch 1953/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0163 - accuracy: 0.9959 - val_loss: 0.1179 - val_accuracy: 0.9885\n",
            "Epoch 1954/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9956 - val_loss: 0.1206 - val_accuracy: 0.9885\n",
            "Epoch 1955/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.1207 - val_accuracy: 0.9885\n",
            "Epoch 1956/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9964 - val_loss: 0.1191 - val_accuracy: 0.9885\n",
            "Epoch 1957/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0147 - accuracy: 0.9959 - val_loss: 0.1161 - val_accuracy: 0.9877\n",
            "Epoch 1958/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9967 - val_loss: 0.1223 - val_accuracy: 0.9885\n",
            "Epoch 1959/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9972 - val_loss: 0.1189 - val_accuracy: 0.9885\n",
            "Epoch 1960/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0138 - accuracy: 0.9974 - val_loss: 0.1192 - val_accuracy: 0.9877\n",
            "Epoch 1961/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.1187 - val_accuracy: 0.9885\n",
            "Epoch 1962/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.1194 - val_accuracy: 0.9885\n",
            "Epoch 1963/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0150 - accuracy: 0.9964 - val_loss: 0.1161 - val_accuracy: 0.9877\n",
            "Epoch 1964/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0168 - accuracy: 0.9964 - val_loss: 0.1248 - val_accuracy: 0.9877\n",
            "Epoch 1965/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.1208 - val_accuracy: 0.9877\n",
            "Epoch 1966/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 0.1201 - val_accuracy: 0.9885\n",
            "Epoch 1967/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.1198 - val_accuracy: 0.9885\n",
            "Epoch 1968/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0136 - accuracy: 0.9974 - val_loss: 0.1194 - val_accuracy: 0.9885\n",
            "Epoch 1969/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0148 - accuracy: 0.9959 - val_loss: 0.1170 - val_accuracy: 0.9877\n",
            "Epoch 1970/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.1196 - val_accuracy: 0.9877\n",
            "Epoch 1971/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0197 - accuracy: 0.9949 - val_loss: 0.1236 - val_accuracy: 0.9885\n",
            "Epoch 1972/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.1244 - val_accuracy: 0.9862\n",
            "Epoch 1973/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 0.9959 - val_loss: 0.1201 - val_accuracy: 0.9885\n",
            "Epoch 1974/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 0.9967 - val_loss: 0.1219 - val_accuracy: 0.9877\n",
            "Epoch 1975/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 0.1180 - val_accuracy: 0.9877\n",
            "Epoch 1976/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.1181 - val_accuracy: 0.9885\n",
            "Epoch 1977/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.1160 - val_accuracy: 0.9885\n",
            "Epoch 1978/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0189 - accuracy: 0.9944 - val_loss: 0.1177 - val_accuracy: 0.9885\n",
            "Epoch 1979/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0174 - accuracy: 0.9933 - val_loss: 0.1257 - val_accuracy: 0.9885\n",
            "Epoch 1980/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0189 - accuracy: 0.9938 - val_loss: 0.1280 - val_accuracy: 0.9862\n",
            "Epoch 1981/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0156 - accuracy: 0.9967 - val_loss: 0.1179 - val_accuracy: 0.9877\n",
            "Epoch 1982/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.1220 - val_accuracy: 0.9877\n",
            "Epoch 1983/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0147 - accuracy: 0.9974 - val_loss: 0.1184 - val_accuracy: 0.9885\n",
            "Epoch 1984/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.1170 - val_accuracy: 0.9885\n",
            "Epoch 1985/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.1167 - val_accuracy: 0.9877\n",
            "Epoch 1986/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 0.1206 - val_accuracy: 0.9885\n",
            "Epoch 1987/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.1263 - val_accuracy: 0.9869\n",
            "Epoch 1988/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0168 - accuracy: 0.9956 - val_loss: 0.1214 - val_accuracy: 0.9885\n",
            "Epoch 1989/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0159 - accuracy: 0.9959 - val_loss: 0.1199 - val_accuracy: 0.9869\n",
            "Epoch 1990/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0161 - accuracy: 0.9959 - val_loss: 0.1200 - val_accuracy: 0.9877\n",
            "Epoch 1991/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.1207 - val_accuracy: 0.9877\n",
            "Epoch 1992/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0146 - accuracy: 0.9967 - val_loss: 0.1228 - val_accuracy: 0.9885\n",
            "Epoch 1993/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0138 - accuracy: 0.9964 - val_loss: 0.1176 - val_accuracy: 0.9877\n",
            "Epoch 1994/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0142 - accuracy: 0.9964 - val_loss: 0.1168 - val_accuracy: 0.9877\n",
            "Epoch 1995/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0145 - accuracy: 0.9967 - val_loss: 0.1182 - val_accuracy: 0.9877\n",
            "Epoch 1996/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0142 - accuracy: 0.9972 - val_loss: 0.1193 - val_accuracy: 0.9885\n",
            "Epoch 1997/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.1178 - val_accuracy: 0.9885\n",
            "Epoch 1998/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0149 - accuracy: 0.9964 - val_loss: 0.1254 - val_accuracy: 0.9877\n",
            "Epoch 1999/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0142 - accuracy: 0.9964 - val_loss: 0.1224 - val_accuracy: 0.9892\n",
            "Epoch 2000/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.0150 - accuracy: 0.9964 - val_loss: 0.1209 - val_accuracy: 0.9892\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          loss  accuracy  val_loss  val_accuracy\n",
              "0     0.121598  0.954580  0.123794      0.960769\n",
              "1     0.121056  0.954580  0.122985      0.960769\n",
              "2     0.120129  0.954837  0.122932      0.960769\n",
              "3     0.119095  0.954324  0.121442      0.960769\n",
              "4     0.118578  0.955350  0.121587      0.960000\n",
              "...        ...       ...       ...           ...\n",
              "1995  0.014197  0.997177  0.119345      0.988462\n",
              "1996  0.015164  0.995124  0.117822      0.988462\n",
              "1997  0.014902  0.996408  0.125432      0.987692\n",
              "1998  0.014245  0.996408  0.122357      0.989231\n",
              "1999  0.015037  0.996408  0.120885      0.989231\n",
              "\n",
              "[2000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-6c159696-fb50-46ad-a0aa-db7a8130c029\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.121598</td>\n",
              "      <td>0.954580</td>\n",
              "      <td>0.123794</td>\n",
              "      <td>0.960769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.121056</td>\n",
              "      <td>0.954580</td>\n",
              "      <td>0.122985</td>\n",
              "      <td>0.960769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.120129</td>\n",
              "      <td>0.954837</td>\n",
              "      <td>0.122932</td>\n",
              "      <td>0.960769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.119095</td>\n",
              "      <td>0.954324</td>\n",
              "      <td>0.121442</td>\n",
              "      <td>0.960769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.118578</td>\n",
              "      <td>0.955350</td>\n",
              "      <td>0.121587</td>\n",
              "      <td>0.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>0.014197</td>\n",
              "      <td>0.997177</td>\n",
              "      <td>0.119345</td>\n",
              "      <td>0.988462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>0.015164</td>\n",
              "      <td>0.995124</td>\n",
              "      <td>0.117822</td>\n",
              "      <td>0.988462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>0.014902</td>\n",
              "      <td>0.996408</td>\n",
              "      <td>0.125432</td>\n",
              "      <td>0.987692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>0.014245</td>\n",
              "      <td>0.996408</td>\n",
              "      <td>0.122357</td>\n",
              "      <td>0.989231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>0.015037</td>\n",
              "      <td>0.996408</td>\n",
              "      <td>0.120885</td>\n",
              "      <td>0.989231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c159696-fb50-46ad-a0aa-db7a8130c029')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-e15972c1-b267-44b1-a61c-e5d3497a9faa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e15972c1-b267-44b1-a61c-e5d3497a9faa')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-e15972c1-b267-44b1-a61c-e5d3497a9faa button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c159696-fb50-46ad-a0aa-db7a8130c029 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c159696-fb50-46ad-a0aa-db7a8130c029');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# y_vloss에 검증셋의 오차를 지정\n",
        "y_vloss = hist_df['val_loss']\n",
        "#y_loss에 학습셋 오차 지정\n",
        "y_loss = hist_df['loss']\n",
        "\n",
        "# x값을 지정하고 검증셋의 오차를 빨간색, 학습셋의 오차를 파란색으로 표시\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len,y_vloss,\"o\",c='red',markersize = 2,label='Testset_loss')\n",
        "plt.plot(x_len,y_loss,'o',c='blue',markersize=2,label='Trainset_loss')\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "rai1u6GUId0W",
        "outputId": "6ffc868b-7e8b-421a-c658-085a0e5ed51a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 위 과적합 되는 상황을 방지 하기 위한 earlystopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss',patience=20)# monitor옵션은  model.fit()의 실행결과정 어떤것을 이용할지 지정  patience옵션을 통해 몇번이상 앞에서 지정된 값이 몇번이상 상향되지 않으면 종료\n",
        "modelpath = \"./data/model/all/{epoch:20d}-{val_accuracy:.4f}.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath,monitor='val_loss', verbose = 0,save_best_only = True)# 학습과정 생략 성능이 좋은 모델 하나 남기기\n",
        "history = model.fit(X_train,y_train,epochs = 2000,batch_size = 500, validation_split = 0.25,verbose = 1,callbacks=[early_stopping_callback,checkpointer])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlvZ6kEsL5-0",
        "outputId": "bbe3e9ee-caca-488c-d7ef-59f184740545"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "8/8 [==============================] - 1s 109ms/step - loss: 0.0140 - accuracy: 0.9962 - val_loss: 0.1195 - val_accuracy: 0.9885\n",
            "Epoch 2/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.1176 - val_accuracy: 0.9877\n",
            "Epoch 3/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.1171 - val_accuracy: 0.9885\n",
            "Epoch 4/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0137 - accuracy: 0.9974 - val_loss: 0.1185 - val_accuracy: 0.9885\n",
            "Epoch 5/2000\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.1185 - val_accuracy: 0.9885\n",
            "Epoch 6/2000\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.1239 - val_accuracy: 0.9885\n",
            "Epoch 7/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0148 - accuracy: 0.9964 - val_loss: 0.1232 - val_accuracy: 0.9885\n",
            "Epoch 8/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.1156 - val_accuracy: 0.9877\n",
            "Epoch 9/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.1165 - val_accuracy: 0.9885\n",
            "Epoch 10/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.1203 - val_accuracy: 0.9892\n",
            "Epoch 11/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.1206 - val_accuracy: 0.9885\n",
            "Epoch 12/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0145 - accuracy: 0.9964 - val_loss: 0.1214 - val_accuracy: 0.9885\n",
            "Epoch 13/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 0.9967 - val_loss: 0.1187 - val_accuracy: 0.9885\n",
            "Epoch 14/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0136 - accuracy: 0.9967 - val_loss: 0.1176 - val_accuracy: 0.9877\n",
            "Epoch 15/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0156 - accuracy: 0.9959 - val_loss: 0.1208 - val_accuracy: 0.9885\n",
            "Epoch 16/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.1256 - val_accuracy: 0.9869\n",
            "Epoch 17/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0147 - accuracy: 0.9967 - val_loss: 0.1171 - val_accuracy: 0.9885\n",
            "Epoch 18/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.1229 - val_accuracy: 0.9885\n",
            "Epoch 19/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.1205 - val_accuracy: 0.9885\n",
            "Epoch 20/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0146 - accuracy: 0.9967 - val_loss: 0.1172 - val_accuracy: 0.9885\n",
            "Epoch 21/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.1217 - val_accuracy: 0.9885\n",
            "Epoch 22/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.1218 - val_accuracy: 0.9885\n",
            "Epoch 23/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.1225 - val_accuracy: 0.9892\n",
            "Epoch 24/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0141 - accuracy: 0.9967 - val_loss: 0.1197 - val_accuracy: 0.9885\n",
            "Epoch 25/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0138 - accuracy: 0.9967 - val_loss: 0.1187 - val_accuracy: 0.9885\n",
            "Epoch 26/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.1219 - val_accuracy: 0.9885\n",
            "Epoch 27/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.1206 - val_accuracy: 0.9869\n",
            "Epoch 28/2000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0144 - accuracy: 0.9967 - val_loss: 0.1204 - val_accuracy: 0.9877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "28번쨰에서 실행 종료"
      ],
      "metadata": {
        "id": "k8qosVYEOEM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test,y_test)\n",
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoojMvpRNTwn",
        "outputId": "a2c513fe-fbfc-4981-c0fe-a5169c9c8b6f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.9908\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07168276607990265, 0.9907692074775696]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow\n"
      ],
      "metadata": {
        "id": "4wxOxEYxOOWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lNpPe4zZPmLy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}